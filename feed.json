{
    "version": "https://jsonfeed.org/version/1",
    "title": "jkfo-notebook",
    "subtitle": "",
    "icon": "http://example.com/images/favicon.ico",
    "description": "",
    "home_page_url": "http://example.com",
    "items": [
        {
            "id": "http://example.com/2025/05/29/Lightning/",
            "url": "http://example.com/2025/05/29/Lightning/",
            "title": "Lightning",
            "date_published": "2025-05-29T05:33:50.000Z",
            "content_html": "<h1 id=\"lightning-模板\"><a class=\"markdownIt-Anchor\" href=\"#lightning-模板\">#</a> Lightning 模板</h1>\n<h2 id=\"load-data\"><a class=\"markdownIt-Anchor\" href=\"#load-data\">#</a> Load Data</h2>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch <span class=\"keyword\">import</span> nn, optim</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch.utils.data <span class=\"keyword\">import</span> DataLoader, random_split</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch.optim.lr_scheduler <span class=\"keyword\">import</span> CosineAnnealingLR, ReduceLROnPlateau, LambdaLR</span><br><span class=\"line\"><span class=\"keyword\">import</span> pytorch_lightning <span class=\"keyword\">as</span> pl</span><br><span class=\"line\"><span class=\"keyword\">from</span> pytorch_lightning <span class=\"keyword\">import</span> Trainer, seed_everything</span><br><span class=\"line\"><span class=\"keyword\">from</span> pytorch_lightning.callbacks.early_stopping <span class=\"keyword\">import</span> EarlyStopping</span><br><span class=\"line\"><span class=\"keyword\">from</span> pytorch_lightning.callbacks <span class=\"keyword\">import</span> ModelCheckpoint</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> random</span><br><span class=\"line\"><span class=\"keyword\">import</span> logging</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">import</span> pandas <span class=\"keyword\">as</span> pd</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> pickle</span><br><span class=\"line\"><span class=\"keyword\">import</span> math</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.metrics <span class=\"keyword\">import</span> f1_score</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.model_selection <span class=\"keyword\">import</span> KFold, train_test_split</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">from</span> models.models <span class=\"keyword\">import</span> Enformer, EnformerConfig</span><br><span class=\"line\"><span class=\"keyword\">from</span> models.dataset <span class=\"keyword\">import</span> CREembeddingDataset, get_class</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># setting</span></span><br><span class=\"line\">seed_everything(<span class=\"number\">42</span>, workers=<span class=\"literal\">True</span>)</span><br><span class=\"line\">input_length = <span class=\"number\">40000</span></span><br><span class=\"line\">num_epochs = <span class=\"number\">50</span>  <span class=\"comment\"># 训练轮数</span></span><br><span class=\"line\">batch_size = <span class=\"number\">36</span>  <span class=\"comment\"># 批次大小</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># logging</span></span><br><span class=\"line\">log_pfx=<span class=\"string\">&#x27;enformer_SL4long_20k_class_all&#x27;</span></span><br><span class=\"line\">logging.basicConfig(</span><br><span class=\"line\">    filename=<span class=\"string\">f&#x27;./logs/<span class=\"subst\">&#123;log_pfx&#125;</span>.log&#x27;</span>,  <span class=\"comment\"># 日志文件名</span></span><br><span class=\"line\">    filemode=<span class=\"string\">&#x27;w&#x27;</span>,             <span class=\"comment\"># 覆盖模式</span></span><br><span class=\"line\">    <span class=\"built_in\">format</span>=<span class=\"string\">&#x27;%(asctime)s - %(levelname)s - %(message)s&#x27;</span>,  <span class=\"comment\"># 日志格式</span></span><br><span class=\"line\">    level=logging.INFO        <span class=\"comment\"># 日志级别</span></span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># load model</span></span><br><span class=\"line\">device = <span class=\"string\">&quot;cuda&quot;</span> <span class=\"keyword\">if</span> torch.cuda.is_available() <span class=\"keyword\">else</span> <span class=\"string\">&quot;cpu&quot;</span></span><br><span class=\"line\">model = Enformer.from_hparams(</span><br><span class=\"line\">    dim = <span class=\"number\">1536</span>//<span class=\"number\">2</span>,</span><br><span class=\"line\">    depth = <span class=\"number\">11</span>,</span><br><span class=\"line\">    heads = <span class=\"number\">4</span>,</span><br><span class=\"line\">    num_downsamples = <span class=\"number\">7</span>,</span><br><span class=\"line\">    dim_divisible_by = <span class=\"number\">128</span></span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 随机抽取3000个样本的索引</span></span><br><span class=\"line\"><span class=\"comment\"># 使用 train_test_split 函数将 data_df 的索引随机划分为训练集和测试集，比例为 9:1</span></span><br><span class=\"line\"><span class=\"comment\"># load data</span></span><br><span class=\"line\">data_df = pd.read_pickle(<span class=\"string\">&#x27;./data/tpm_embedding_SL4long_20k.pkl&#x27;</span>)</span><br><span class=\"line\">data_df[<span class=\"string\">&#x27;class&#x27;</span>] = get_class([np.log(x + <span class=\"number\">1</span>) <span class=\"keyword\">for</span> x <span class=\"keyword\">in</span> data_df[<span class=\"string\">&#x27;max&#x27;</span>].to_list()])</span><br><span class=\"line\">class_weights = data_df[<span class=\"string\">&#x27;class&#x27;</span>].value_counts().reindex([<span class=\"number\">0</span>,<span class=\"number\">1</span>,<span class=\"number\">2</span>], fill_value=<span class=\"number\">0</span>)</span><br><span class=\"line\">class_weights = class_weights / class_weights.<span class=\"built_in\">max</span>()</span><br><span class=\"line\">test_pickle = <span class=\"string\">&quot;./data/tpm_embedding_SL4long_20k_test_cv5.pkl&quot;</span> <span class=\"comment\"># 用于后续测试</span></span><br><span class=\"line\">embeddings = np.load(<span class=\"string\">&#x27;./data/tpm_seq_embedding_SL4long_20k.npz&#x27;</span>)[<span class=\"string\">&#x27;embeddings&#x27;</span>]</span><br><span class=\"line\">train_indices, test_indices = train_test_split(<span class=\"built_in\">range</span>(<span class=\"built_in\">len</span>(data_df)), test_size=<span class=\"number\">0.1</span>, random_state=<span class=\"number\">42</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 五折交叉验证</span></span><br><span class=\"line\">kf = KFold(n_splits=<span class=\"number\">5</span>, shuffle=<span class=\"literal\">True</span>, random_state=<span class=\"number\">42</span>)</span><br><span class=\"line\">fold_indices = []</span><br><span class=\"line\"><span class=\"keyword\">for</span> fold, (train_index, val_index) <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(kf.split(train_indices)):</span><br><span class=\"line\">    <span class=\"comment\"># 划分训练集和验证集的索引</span></span><br><span class=\"line\">    train_fold_indices = [train_indices[i] <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> train_index]</span><br><span class=\"line\">    val_fold_indices = [train_indices[i] <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> val_index]</span><br><span class=\"line\">    fold_indices.append((train_fold_indices, val_fold_indices))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 测试集的数据加载器</span></span><br><span class=\"line\">test_df = data_df.iloc[test_indices]</span><br><span class=\"line\">test_df.to_pickle(test_pickle)</span><br></pre></td></tr></table></figure>\n<h2 id=\"lightning-模板-2\"><a class=\"markdownIt-Anchor\" href=\"#lightning-模板-2\">#</a> Lightning 模板</h2>\n<blockquote>\n<p>Lightning 需要</p>\n<ul>\n<li>\n<p><code>pl.LightningDataModule</code> ，实现 dataloader 模块</p>\n</li>\n<li>\n<p><code>pl.LightningModule</code> ，加载模型</p>\n</li>\n</ul>\n<p>最少需要</p>\n<ul>\n<li>forward 定义前向传播</li>\n<li>configure_optimizers optimizer 与 scheduler</li>\n<li>training_step</li>\n<li>training_step</li>\n<li>validation_step</li>\n<li>test_step</li>\n</ul>\n<p>额外的实现，每个 epoch 开始与结束的行为</p>\n<ul>\n<li>on_train_epoch_start</li>\n<li>on_train_epoch_end</li>\n<li>on_validation_epoch_start</li>\n<li>on_validation_epoch_end</li>\n<li>on_test_epoch_start</li>\n<li>on_test_epoch_end</li>\n</ul>\n</blockquote>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br><span class=\"line\">145</span><br><span class=\"line\">146</span><br><span class=\"line\">147</span><br><span class=\"line\">148</span><br><span class=\"line\">149</span><br><span class=\"line\">150</span><br><span class=\"line\">151</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">MyDataModule</span>(pl.LightningDataModule):</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self, train_indices, val_indices, test_indices, batch_size</span>):</span><br><span class=\"line\">        <span class=\"built_in\">super</span>().__init__()</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.batch_size = batch_size</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.train_indices = train_indices</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.val_indices = val_indices</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.test_indices = test_indices</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">train_dataloader</span>(<span class=\"params\">self</span>):</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.train_dataset = CREembeddingDataset(data_df.iloc[<span class=\"variable language_\">self</span>.train_indices], embeddings, target=<span class=\"string\">&#x27;class&#x27;</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> DataLoader(<span class=\"variable language_\">self</span>.train_dataset, batch_size=<span class=\"variable language_\">self</span>.batch_size)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">val_dataloader</span>(<span class=\"params\">self</span>):</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.val_dataset = CREembeddingDataset(data_df.iloc[<span class=\"variable language_\">self</span>.val_indices], embeddings, target=<span class=\"string\">&#x27;class&#x27;</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> DataLoader(<span class=\"variable language_\">self</span>.val_dataset, batch_size=<span class=\"variable language_\">self</span>.batch_size)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">test_dataloader</span>(<span class=\"params\">self</span>):</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.test_dataset = CREembeddingDataset(data_df.iloc[<span class=\"variable language_\">self</span>.test_indices], embeddings, target=<span class=\"string\">&#x27;class&#x27;</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> DataLoader(<span class=\"variable language_\">self</span>.test_dataset, batch_size=<span class=\"variable language_\">self</span>.batch_size)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># pytorch_lightning</span></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">MyModule</span>(pl.LightningModule):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self, foldnum, model, num_epochs, batch_size=batch_size, class_weights=class_weights</span>):</span><br><span class=\"line\">        <span class=\"string\">&quot;&quot;&quot;</span></span><br><span class=\"line\"><span class=\"string\">        foldnum: 第几折</span></span><br><span class=\"line\"><span class=\"string\">        model: 模型</span></span><br><span class=\"line\"><span class=\"string\">        batch_size: 批次大小</span></span><br><span class=\"line\"><span class=\"string\">        class_weights: 类别权重</span></span><br><span class=\"line\"><span class=\"string\">        &quot;&quot;&quot;</span></span><br><span class=\"line\">        <span class=\"built_in\">super</span>().__init__()</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.mymodel = model</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.batch_size = batch_size</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.class_weights = class_weights</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"comment\"># metrics function</span></span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.loss_fn = nn.CrossEntropyLoss(weight=torch.tensor(class_weights, dtype=torch.bfloat16))</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.f1 = f1_score</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># init metric target</span></span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.init_metric_target(foldnum, num_epochs)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">init_metric_target</span>(<span class=\"params\">self, foldnum, num_epochs</span>):</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"comment\"># metrics</span></span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.val_outputs = []</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.val_targets = []</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.test_outputs = []</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.test_targets = []</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># logging</span></span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.running_loss = <span class=\"number\">0</span></span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.val_loss = <span class=\"number\">0</span></span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.test_loss = <span class=\"number\">0</span></span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.epoch = <span class=\"number\">0</span></span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.fold = foldnum</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.num_epochs = num_epochs</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, x</span>):</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"variable language_\">self</span>.mymodel(x)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">configure_optimizers</span>(<span class=\"params\">self</span>):</span><br><span class=\"line\">        <span class=\"comment\"># 定义损失函数和优化器</span></span><br><span class=\"line\">        optimizer = optim.AdamW(<span class=\"variable language_\">self</span>.mymodel.parameters(), lr=<span class=\"number\">0.0001</span>, weight_decay=<span class=\"number\">1e-3</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">        warm_up_iter = <span class=\"number\">5</span></span><br><span class=\"line\">        T_max = <span class=\"number\">50</span>\t<span class=\"comment\"># 周期</span></span><br><span class=\"line\">        lr_max = <span class=\"number\">1e-4</span>\t<span class=\"comment\"># 最大值</span></span><br><span class=\"line\">        lr_min = <span class=\"number\">0</span>\t<span class=\"comment\"># 最小值</span></span><br><span class=\"line\">        lambda0 = <span class=\"keyword\">lambda</span> cur_iter: (lr_max - lr_min)/warm_up_iter * cur_iter / <span class=\"number\">0.0001</span> <span class=\"keyword\">if</span> cur_iter &lt;= warm_up_iter <span class=\"keyword\">else</span> \\</span><br><span class=\"line\">            (lr_min + <span class=\"number\">0.5</span>*(lr_max-lr_min)*(<span class=\"number\">1.0</span>+math.cos((cur_iter-warm_up_iter)/(T_max-warm_up_iter)*math.pi))) / <span class=\"number\">0.0001</span></span><br><span class=\"line\">        scheduler = LambdaLR(optimizer, lr_lambda=lambda0)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">return</span> &#123;<span class=\"string\">&quot;optimizer&quot;</span>: optimizer, <span class=\"string\">&quot;lr_scheduler&quot;</span>: scheduler&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">training_step</span>(<span class=\"params\">self, batch, batch_idx</span>):</span><br><span class=\"line\"></span><br><span class=\"line\">        embeddings, targets = batch</span><br><span class=\"line\">        outputs = <span class=\"variable language_\">self</span>(embeddings)</span><br><span class=\"line\">        loss = <span class=\"variable language_\">self</span>.loss_fn(outputs, targets)</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.running_loss += loss.item()</span><br><span class=\"line\">        <span class=\"keyword\">if</span> batch_idx % <span class=\"number\">2</span> == <span class=\"number\">1</span>:  <span class=\"comment\"># 每2个batch记录一次训练损失和F1</span></span><br><span class=\"line\">            avg_train_batch_loss = <span class=\"variable language_\">self</span>.running_loss / (batch_idx + <span class=\"number\">1</span>)</span><br><span class=\"line\">            logging.info(<span class=\"string\">f&#x27;Fold <span class=\"subst\">&#123;self.fold+<span class=\"number\">1</span>&#125;</span>, Epoch <span class=\"subst\">&#123;self.epoch + <span class=\"number\">1</span>&#125;</span>/<span class=\"subst\">&#123;self.num_epochs&#125;</span>, Batch <span class=\"subst\">&#123;batch_idx + <span class=\"number\">1</span>&#125;</span>, Train Loss(CrossEntropy): <span class=\"subst\">&#123;avg_train_batch_loss:<span class=\"number\">.4</span>f&#125;</span>&#x27;</span>)</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"keyword\">return</span> loss</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">validation_step</span>(<span class=\"params\">self, batch, batch_idx</span>):</span><br><span class=\"line\"></span><br><span class=\"line\">        embeddings, targets = batch</span><br><span class=\"line\">        outputs = <span class=\"variable language_\">self</span>(embeddings)</span><br><span class=\"line\">        loss = <span class=\"variable language_\">self</span>.loss_fn(outputs, targets)</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.val_loss += loss.item()</span><br><span class=\"line\"></span><br><span class=\"line\">        _, preds = torch.<span class=\"built_in\">max</span>(outputs, <span class=\"number\">1</span>)</span><br><span class=\"line\">        _, decode_target = torch.<span class=\"built_in\">max</span>(targets, <span class=\"number\">1</span>) <span class=\"comment\"># 真实结果</span></span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.val_outputs.extend(preds.cpu().numpy())</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.val_targets.extend(decode_target.cpu().numpy())</span><br><span class=\"line\">        <span class=\"keyword\">return</span> loss</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">test_step</span>(<span class=\"params\">self, batch, batch_idx</span>):</span><br><span class=\"line\"></span><br><span class=\"line\">        embeddings, targets = batch</span><br><span class=\"line\">        outputs = <span class=\"variable language_\">self</span>(embeddings)</span><br><span class=\"line\">        loss = <span class=\"variable language_\">self</span>.loss_fn(outputs, targets)</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.test_loss += loss.item()</span><br><span class=\"line\"></span><br><span class=\"line\">        _, preds = torch.<span class=\"built_in\">max</span>(outputs, <span class=\"number\">1</span>)</span><br><span class=\"line\">        _, decode_target = torch.<span class=\"built_in\">max</span>(targets, <span class=\"number\">1</span>) <span class=\"comment\"># 真实结果</span></span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.test_outputs.extend(preds.cpu().numpy())</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.test_targets.extend(decode_target.cpu().numpy())</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">return</span> loss</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">on_train_epoch_start</span>(<span class=\"params\">self</span>):</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.running_loss = <span class=\"number\">0</span></span><br><span class=\"line\">        <span class=\"comment\"># 获取优化器</span></span><br><span class=\"line\">        current_lr = <span class=\"variable language_\">self</span>.configure_optimizers()[<span class=\"string\">&quot;optimizer&quot;</span>].param_groups[<span class=\"number\">0</span>][<span class=\"string\">&#x27;lr&#x27;</span>]</span><br><span class=\"line\">        logging.info(<span class=\"string\">f&#x27;Epoch <span class=\"subst\">&#123;self.epoch + <span class=\"number\">1</span>&#125;</span>/<span class=\"subst\">&#123;self.num_epochs&#125;</span>, Learning Rate: <span class=\"subst\">&#123;current_lr:<span class=\"number\">.5</span>f&#125;</span>&#x27;</span>)</span><br><span class=\"line\">        </span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">on_train_epoch_end</span>(<span class=\"params\">self</span>):</span><br><span class=\"line\">        avg_train_loss = <span class=\"variable language_\">self</span>.running_loss / <span class=\"built_in\">len</span>(<span class=\"variable language_\">self</span>.train_dataloader())</span><br><span class=\"line\">        logging.info(<span class=\"string\">f&#x27;Fold <span class=\"subst\">&#123;self.fold+<span class=\"number\">1</span>&#125;</span>, Epoch <span class=\"subst\">&#123;self.epoch+<span class=\"number\">1</span>&#125;</span>/<span class=\"subst\">&#123;self.num_epochs&#125;</span>, Train Loss(CrossEntropy): <span class=\"subst\">&#123;avg_train_loss:<span class=\"number\">.4</span>f&#125;</span>&#x27;</span>)</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.log(<span class=\"string\">&#x27;train_loss&#x27;</span>, avg_train_loss, prog_bar=<span class=\"literal\">True</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">on_validation_epoch_start</span>(<span class=\"params\">self</span>):</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.val_loss = <span class=\"number\">0</span></span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.val_outputs = []</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.val_targets = []</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">on_validation_epoch_end</span>(<span class=\"params\">self</span>):</span><br><span class=\"line\">        val_f1 = <span class=\"variable language_\">self</span>.f1(<span class=\"variable language_\">self</span>.val_targets, <span class=\"variable language_\">self</span>.val_outputs, average=<span class=\"string\">&#x27;macro&#x27;</span>)</span><br><span class=\"line\">        avg_val_loss = <span class=\"variable language_\">self</span>.val_loss / <span class=\"built_in\">len</span>(<span class=\"variable language_\">self</span>.val_targets)</span><br><span class=\"line\">        logging.info(<span class=\"string\">f&#x27;Fold <span class=\"subst\">&#123;self.fold+<span class=\"number\">1</span>&#125;</span>, Epoch <span class=\"subst\">&#123;self.epoch+<span class=\"number\">1</span>&#125;</span>/<span class=\"subst\">&#123;self.num_epochs&#125;</span>, Val Loss(CrossEntropy): <span class=\"subst\">&#123;avg_val_loss:<span class=\"number\">.4</span>f&#125;</span>, Val F1: <span class=\"subst\">&#123;val_f1:<span class=\"number\">.4</span>f&#125;</span>&#x27;</span>)</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.log(<span class=\"string\">&#x27;val_f1&#x27;</span>, val_f1, prog_bar=<span class=\"literal\">True</span>)</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.log(<span class=\"string\">&#x27;val_loss&#x27;</span>, avg_val_loss, prog_bar=<span class=\"literal\">True</span>)</span><br><span class=\"line\">        </span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">on_test_epoch_start</span>(<span class=\"params\">self</span>):</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.test_loss = <span class=\"number\">0</span></span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.test_outputs = []</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.test_targets = []</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">on_test_epoch_end</span>(<span class=\"params\">self</span>):</span><br><span class=\"line\">        test_f1 = <span class=\"variable language_\">self</span>.f1(<span class=\"variable language_\">self</span>.test_targets, <span class=\"variable language_\">self</span>.test_outputs, average=<span class=\"string\">&#x27;macro&#x27;</span>)</span><br><span class=\"line\">        avg_test_loss = <span class=\"variable language_\">self</span>.test_loss / <span class=\"built_in\">len</span>(<span class=\"variable language_\">self</span>.test_targets)</span><br><span class=\"line\">        logging.info(<span class=\"string\">f&#x27;Fold <span class=\"subst\">&#123;self.fold+<span class=\"number\">1</span>&#125;</span>, Epoch <span class=\"subst\">&#123;self.epoch+<span class=\"number\">1</span>&#125;</span>/<span class=\"subst\">&#123;self.num_epochs&#125;</span>, Test Loss(CrossEntropy): <span class=\"subst\">&#123;avg_test_loss:<span class=\"number\">.4</span>f&#125;</span>, Val F1: <span class=\"subst\">&#123;test_f1:<span class=\"number\">.4</span>f&#125;</span>&#x27;</span>)</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.log(<span class=\"string\">&#x27;test_f1&#x27;</span>, test_f1, prog_bar=<span class=\"literal\">True</span>)</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.log(<span class=\"string\">&#x27;test_loss&#x27;</span>, avg_test_loss, prog_bar=<span class=\"literal\">True</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.epoch += <span class=\"number\">1</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"lightning-training\"><a class=\"markdownIt-Anchor\" href=\"#lightning-training\">#</a> Lightning training</h2>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># training process</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> fold, (train_idx, val_idx) <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(fold_indices):</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;\\n----------- Training Fold <span class=\"subst\">&#123;fold + <span class=\"number\">1</span>&#125;</span>/5 -----------&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 初始化模型</span></span><br><span class=\"line\">    pl_model = MyModule(</span><br><span class=\"line\">        foldnum = fold,</span><br><span class=\"line\">        model = model,</span><br><span class=\"line\">        num_epochs=num_epochs,</span><br><span class=\"line\">        class_weights=class_weights,</span><br><span class=\"line\">        batch_size=batch_size</span><br><span class=\"line\">    )</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 创建数据模块</span></span><br><span class=\"line\">    dm = MyDataModule(</span><br><span class=\"line\">        train_indices=train_idx,</span><br><span class=\"line\">        val_indices=val_idx,</span><br><span class=\"line\">        test_indices=test_indices,</span><br><span class=\"line\">        batch_size=batch_size</span><br><span class=\"line\">    )</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># callback</span></span><br><span class=\"line\">    early_stop_callback = EarlyStopping(</span><br><span class=\"line\">        monitor=<span class=\"string\">&quot;val_f1&quot;</span>, min_delta=<span class=\"number\">0.00</span>, </span><br><span class=\"line\">        patience=<span class=\"number\">10</span>, verbose=<span class=\"literal\">False</span>, mode=<span class=\"string\">&quot;max&quot;</span></span><br><span class=\"line\">    )</span><br><span class=\"line\">    checkpoint_callback = ModelCheckpoint(</span><br><span class=\"line\">        monitor=<span class=\"string\">&quot;val_f1&quot;</span>,          <span class=\"comment\"># 监控指标</span></span><br><span class=\"line\">        mode=<span class=\"string\">&quot;max&quot;</span>,                 <span class=\"comment\"># 寻找最大值</span></span><br><span class=\"line\">        save_top_k=<span class=\"number\">1</span>,              <span class=\"comment\"># 只保存最好的一个模型</span></span><br><span class=\"line\">        filename=<span class=\"string\">f&quot;<span class=\"subst\">&#123;log_pfx&#125;</span>_fold<span class=\"subst\">&#123;fold&#125;</span>&quot;</span>+<span class=\"string\">&quot;-&#123;epoch&#125;-&#123;val_f1:.2f&#125;&quot;</span>,</span><br><span class=\"line\">        dirpath=<span class=\"string\">&quot;./models&quot;</span>          <span class=\"comment\"># 保存路径</span></span><br><span class=\"line\">    )</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 构建Trainer</span></span><br><span class=\"line\">    trainer = Trainer(</span><br><span class=\"line\">        precision=<span class=\"string\">&quot;bf16-mixed&quot;</span>, </span><br><span class=\"line\">        accelerator=<span class=\"string\">&quot;gpu&quot;</span>, </span><br><span class=\"line\">        devices=<span class=\"number\">1</span>,</span><br><span class=\"line\">        max_epochs=num_epochs,</span><br><span class=\"line\">        logger=pl.loggers.TensorBoardLogger(</span><br><span class=\"line\">            save_dir=<span class=\"string\">&#x27;./logs&#x27;</span>, </span><br><span class=\"line\">            name=log_pfx</span><br><span class=\"line\">            ), <span class=\"comment\"># 根据 self.log记录tensorboard的结果</span></span><br><span class=\"line\">        num_sanity_val_steps=<span class=\"number\">0</span>,</span><br><span class=\"line\">        callbacks=[</span><br><span class=\"line\">            early_stop_callback,</span><br><span class=\"line\">            checkpoint_callback</span><br><span class=\"line\">            ] <span class=\"comment\"># 早停机制根据self.log记录tensorboard的结果</span></span><br><span class=\"line\">    )</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\"># Training.....</span></span><br><span class=\"line\">    trainer.fit(pl_model, datamodule=dm) <span class=\"comment\"># 训练模型</span></span><br><span class=\"line\">    trainer.test(pl_model, datamodule=dm) <span class=\"comment\"># 测试模型</span></span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\"># 保存最佳模型</span></span><br><span class=\"line\">    torch.save(</span><br><span class=\"line\">        torch.load(checkpoint_callback.best_model_path)[<span class=\"string\">&#x27;state_dict&#x27;</span>], </span><br><span class=\"line\">        <span class=\"string\">f&quot;./models/<span class=\"subst\">&#123;log_pfx&#125;</span>_best_fold<span class=\"subst\">&#123;fold&#125;</span>.pth&quot;</span></span><br><span class=\"line\">    )</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 保存最终模型</span></span><br><span class=\"line\">torch.save(pl_model.state_dict(), <span class=\"string\">f&quot;./models/<span class=\"subst\">&#123;log_pfx&#125;</span>_final.pth&quot;</span>)</span><br></pre></td></tr></table></figure>\n",
            "tags": [
                "Mechine learning",
                "Mechine learning"
            ]
        },
        {
            "id": "http://example.com/2024/12/26/Transformers1/",
            "url": "http://example.com/2024/12/26/Transformers1/",
            "title": "Transformers1",
            "date_published": "2024-12-26T08:19:59.000Z",
            "content_html": "<h1 id=\"transformers-part1\"><a class=\"markdownIt-Anchor\" href=\"#transformers-part1\">#</a> Transformers-Part1</h1>\n<div class=\"note primary\">\n<p>Attention is All your Need</p>\n</div>\n<p>最近服务器大量跑计算，正好有时间，把这个非常出名的<strong> Transformers</strong> 好好看看，结果就发现他过于抽象，还是归因于自己对于 python 的类、实例、函数认识不清，对于 Torch 还有深度学习基础架构不熟悉。趁这个机会正好好好学习一下。主要就是首先简单记录一下 Transformers 的基础架构，再深入看看基于 Torch 的 Transformers 源码。文中肯定是有纰漏的，有缘人看到请帮忙指正…</p>\n<h1 id=\"transformers-模型架构\"><a class=\"markdownIt-Anchor\" href=\"#transformers-模型架构\">#</a> Transformers 模型架构</h1>\n<p><img data-src=\"https://raw.githubusercontent.com/jkfo002/my_PicBed/refs/heads/main/OIP.jfif\" alt=\"OIP\"></p>\n<p>乍一看这个东西挺唬人的，把它分解开来看还是较为简单。左边部分为 Encoder 层，右边则为 Decoder 层。</p>\n<p><strong>Encoder</strong> 接受数据及其位置编码（NLP 应用中），数据经过 Embedding 后则进入 Encoder 层。Encoder 层由 N 个<strong> EncoderLayers</strong> 组成，每个 layers 之间是相连的，EncoderLayers 则包括<strong>多头注意力层（Multi-Head Attention）</strong>，<strong>Add &amp; Norm</strong>，<strong>Feed Fordward</strong> 等小组件组成。</p>\n<p><strong>Decoder</strong> 接受数据及其位置编码，与 Encoder 的不同在于，<strong>Decoder 同样接受来自 Encoder 的 output</strong>。Decoder 层由 N 个<strong> DecoderLayers</strong> 组成，每个 layers 之间相互链接，其中的组件同样包括<strong>多头注意力层（Multi-Head Attention）</strong>，<strong>Add &amp; Norm</strong>，<strong>Feed Fordward</strong> 等小组件。</p>\n<p>虽然这里有一大堆让人看着就不太明白的词汇，但其实就可以发现整个 Transformers 架构是由很多小组件类似于拼积木组成。</p>\n<h1 id=\"multi-head-attention\"><a class=\"markdownIt-Anchor\" href=\"#multi-head-attention\">#</a> Multi-Head Attention</h1>\n<p>关于注意力机制的原理可以看 B 站 3blue1brown 的视频<span class=\"exturl\" data-url=\"aHR0cHM6Ly93d3cuYmlsaWJpbGkuY29tL3ZpZGVvL0JWMVRaNDIxajdLZS8/c3BtX2lkX2Zyb209MzMzLjEzODcuaG9tZXBhZ2UudmlkZW9fY2FyZC5jbGljayZhbXA7dmRfc291cmNlPTAwNjk2Njk4ZGJmZGJlYmVmNjk2MzhlOWFlYTM0MWEx\">【官方双语】直观解释注意力机制，Transformer 的核心 | 【深度学习第 6 章】_哔哩哔哩_bilibili</span>。起初的注意力机制将注意力汇聚的输出计算成为值的<span class=\"exturl\" data-url=\"aHR0cHM6Ly96aGlkYS56aGlodS5jb20vc2VhcmNoP2NvbnRlbnRfaWQ9MjI4NDQyMTc4JmFtcDtjb250ZW50X3R5cGU9QXJ0aWNsZSZhbXA7bWF0Y2hfb3JkZXI9MSZhbXA7cT0lRTUlOEElQTAlRTYlOUQlODMlRTUlOTIlOEMmYW1wO3poaWRhX3NvdXJjZT1lbnRpdHk=\">加权和</span>。许多博客也有解释，通过 Query 与 Key 的注意力汇聚（即，给定一个 Query，计算 Query 与 Key 的相关性，然后根据 Query 与 Key 的相关性去和对应的 Value 进行相乘）实现对 Value 的注意力权重分配，生成最终的输出结果。给我的感觉就是<strong> Attention 还是一种计算键值对相关性的一种形式</strong>。<strong>而当 Query，Key，Value 均来自同一个数据的时候</strong>，神奇的事情发生了，这时的 Query，Key，Value 相同，即计算自己跟自己的相关性，那么<strong>抽像的来说就是对数据自身包含的规律进行了学习</strong>，是一种将单个序列的不同位置相关联的注意力机制。</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>A</mi><mi>t</mi><mi>t</mi><mi>e</mi><mi>n</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo stretchy=\"false\">(</mo><mi>Q</mi><mo separator=\"true\">,</mo><mi>K</mi><mo separator=\"true\">,</mo><mi>V</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mi>s</mi><mi>o</mi><mi>f</mi><mi>t</mi><mi>m</mi><mi>a</mi><mi>x</mi><mo stretchy=\"false\">(</mo><mfrac><mrow><mi>Q</mi><msup><mi>K</mi><mi>T</mi></msup></mrow><msqrt><msub><mi>d</mi><mi>k</mi></msub></msqrt></mfrac><mo stretchy=\"false\">)</mo><mi>V</mi></mrow><annotation encoding=\"application/x-tex\">Attention(Q, K, V) = softmax(\\frac{QK^T}{\\sqrt{d_k}})V\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\">A</span><span class=\"mord mathnormal\">t</span><span class=\"mord mathnormal\">t</span><span class=\"mord mathnormal\">e</span><span class=\"mord mathnormal\">n</span><span class=\"mord mathnormal\">t</span><span class=\"mord mathnormal\">i</span><span class=\"mord mathnormal\">o</span><span class=\"mord mathnormal\">n</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">Q</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">V</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.448331em;vertical-align:-0.93em;\"></span><span class=\"mord mathnormal\">s</span><span class=\"mord mathnormal\">o</span><span class=\"mord mathnormal\" style=\"margin-right:0.10764em;\">f</span><span class=\"mord mathnormal\">t</span><span class=\"mord mathnormal\">m</span><span class=\"mord mathnormal\">a</span><span class=\"mord mathnormal\">x</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.5183309999999999em;\"><span style=\"top:-2.25278em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord sqrt\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.85722em;\"><span class=\"svg-align\" style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\" style=\"padding-left:0.833em;\"><span class=\"mord\"><span class=\"mord mathnormal\">d</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\">k</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-2.81722em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"hide-tail\" style=\"min-width:0.853em;height:1.08em;\"><svg width='400em' height='1.08em' viewBox='0 0 400000 1080' preserveAspectRatio='xMinYMin slice'><path d='M95,702\nc-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14\nc0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54\nc44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10\ns173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429\nc69,-144,104.5,-217.7,106.5,-221\nl0 -0\nc5.3,-9.3,12,-14,20,-14\nH400000v40H845.2724\ns-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7\nc-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z\nM834 80h400000v40h-400000z'/></svg></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.18278000000000005em;\"><span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">Q</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8413309999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.93em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mclose\">)</span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">V</span></span></span></span></span></p>\n<p>注意力机制源码，参考</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> math</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch.nn <span class=\"keyword\">as</span> nn</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">SelfAttentionV1</span>(nn.Module):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self, hidden_dim: <span class=\"built_in\">int</span> = <span class=\"number\">728</span></span>):</span><br><span class=\"line\">        <span class=\"built_in\">super</span>().__init__()</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.hidden_dim = hidden_dim</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"comment\"># linear 方法 用于定义线性变换，包括权重矩阵初始化</span></span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.query_proj = nn.Linear(hidden_dim, hidden_dim) <span class=\"comment\"># 有时加上bias=False加速运行</span></span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.key_proj = nn.Linear(hidden_dim, hidden_dim)</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.value_proj = nn.Linear(hidden_dim, hidden_dim)</span><br><span class=\"line\">        </span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, X</span>):</span><br><span class=\"line\">        <span class=\"comment\"># X shape is (batch size, seq_len, hidden_dim)</span></span><br><span class=\"line\">        Q = <span class=\"variable language_\">self</span>.query_proj(X)</span><br><span class=\"line\">        K = <span class=\"variable language_\">self</span>.key_proj(X)</span><br><span class=\"line\">        V = <span class=\"variable language_\">self</span>.value_proj(X)</span><br><span class=\"line\">        <span class=\"comment\"># Q, K, V shape (batch, seq, hidden_dim)</span></span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;Q shape: <span class=\"subst\">&#123;Q.size()&#125;</span>; K shape: <span class=\"subst\">&#123;K.size()&#125;</span>, V shape: <span class=\"subst\">&#123;V.size()&#125;</span>&quot;</span>)</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"comment\"># attention value (batch, seq, seq)</span></span><br><span class=\"line\">        attention_value = torch.matmul(</span><br><span class=\"line\">            Q, K.transpose(-<span class=\"number\">1</span>, -<span class=\"number\">2</span>) <span class=\"comment\"># -1 -2 交换位置</span></span><br><span class=\"line\">        )</span><br><span class=\"line\">        <span class=\"comment\"># (batch, seq, seq)</span></span><br><span class=\"line\">        attention_weight = torch.softmax(</span><br><span class=\"line\">            attention_value / math.sqrt(<span class=\"variable language_\">self</span>.hidden_dim),</span><br><span class=\"line\">            dim= -<span class=\"number\">1</span></span><br><span class=\"line\">        )</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;Weight shape: <span class=\"subst\">&#123;attention_weight.size()&#125;</span>&quot;</span>)</span><br><span class=\"line\">        </span><br><span class=\"line\">        output = torch.matmul(attention_weight, V)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> output</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># test</span></span><br><span class=\"line\">X = torch.rand(<span class=\"number\">3</span>, <span class=\"number\">2</span>, <span class=\"number\">4</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(X)</span><br><span class=\"line\"></span><br><span class=\"line\">self_att_net = SelfAttentionV1(<span class=\"number\">4</span>) <span class=\"comment\"># hidden layer 为4</span></span><br><span class=\"line\">self_att_net(X)</span><br></pre></td></tr></table></figure>\n<p>从源码来看就是首先对数据进行三次线性变换（<span class=\"exturl\" data-url=\"aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ0NzIyMTg5L2FydGljbGUvZGV0YWlscy8xMzUwMzUzNTE=\">Pytorch nn.Linear () 的基本用法与原理详解及全连接层简介 - CSDN 博客</span>，包括了权重 W 矩阵的初始化），生成 Query，Key，Value 三个 tensor 对象，接着根据 Attention 公式进行计算。</p>\n<p>而<strong>多头注意力机制</strong>是在自注意力机制的基础上发展起来的，是自注意力机制的变体，旨在增强模型的表达能力和泛化能力。它通过使用<strong>多个独立</strong>的注意力头，分别计算注意力权重，并将它们的结果进行拼接或加权求和，从而获得更丰富的表示。</p>\n<p><img data-src=\"https://raw.githubusercontent.com/jkfo002/my_PicBed/refs/heads/main/MHA.png\" alt=\"MHA\"></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">MutiHeadSelfAttentionFormal</span>(nn.Module):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self, dim, head_num, attentnion_dropout=<span class=\"number\">0.1</span></span>):</span><br><span class=\"line\">        <span class=\"built_in\">super</span>().__init__()</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.hidden_dim = dim</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.head_num = head_num</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.head_dim = dim // head_num <span class=\"comment\"># (head_num * head_dim = dim)</span></span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.q_proj = nn.Linear(dim, dim) <span class=\"comment\"># (dim, head_num * head_dim) 后面可以用split拆分</span></span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.k_proj = nn.Linear(dim, dim)</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.v_proj = nn.Linear(dim, dim)</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.out_proj = nn.Linear(dim, dim)</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.attentnion_dropout = nn.Dropout(attentnion_dropout)</span><br><span class=\"line\">        </span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, X, attention_mask=<span class=\"literal\">None</span></span>):</span><br><span class=\"line\">        <span class=\"comment\"># X (batch, seq, hidden_dim)</span></span><br><span class=\"line\">        batch, seq_len, _ = X.size()</span><br><span class=\"line\">        </span><br><span class=\"line\">        Q = <span class=\"variable language_\">self</span>.q_proj(X)</span><br><span class=\"line\">        K = <span class=\"variable language_\">self</span>.k_proj(X)</span><br><span class=\"line\">        V = <span class=\"variable language_\">self</span>.v_proj(X) <span class=\"comment\"># (b, s, h)</span></span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"comment\"># (b, s, h) -&gt; (b, head_num, s, head_dim) # (head_num * head_dim = h)</span></span><br><span class=\"line\">        q_state = Q.view(batch, seq_len, <span class=\"variable language_\">self</span>.head_num, <span class=\"variable language_\">self</span>.head_dim).transpose(<span class=\"number\">1</span>, <span class=\"number\">2</span>)</span><br><span class=\"line\">        k_state = K.view(batch, seq_len, <span class=\"variable language_\">self</span>.head_num, <span class=\"variable language_\">self</span>.head_dim).transpose(<span class=\"number\">1</span>, <span class=\"number\">2</span>)</span><br><span class=\"line\">        v_state = V.view(batch, seq_len, <span class=\"variable language_\">self</span>.head_num, <span class=\"variable language_\">self</span>.head_dim).transpose(<span class=\"number\">1</span>, <span class=\"number\">2</span>)</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"comment\"># (b, head_num, s, s)</span></span><br><span class=\"line\">        attention_weight = torch.matmul(</span><br><span class=\"line\">            q_state, k_state.transpose(-<span class=\"number\">1</span>, -<span class=\"number\">2</span>)</span><br><span class=\"line\">        )/math.sqrt(<span class=\"variable language_\">self</span>.head_dim)</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"keyword\">if</span> attention_mask <span class=\"keyword\">is</span> <span class=\"keyword\">not</span> <span class=\"literal\">None</span>:</span><br><span class=\"line\">            attention_weight = attention_weight.masked_fill(</span><br><span class=\"line\">                attention_mask==<span class=\"number\">0</span>, <span class=\"built_in\">float</span>(<span class=\"string\">&#x27;-1e20&#x27;</span>)</span><br><span class=\"line\">            )</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(attention_weight.shape)</span><br><span class=\"line\">        </span><br><span class=\"line\">        attention_weight = torch.softmax(attention_weight, dim=-<span class=\"number\">1</span>)</span><br><span class=\"line\">        attention_weight = <span class=\"variable language_\">self</span>.attentnion_dropout(attention_weight)</span><br><span class=\"line\">        </span><br><span class=\"line\">        output_mid = attention_weight @ v_state <span class=\"comment\"># (b, head_num, s, head_dim)</span></span><br><span class=\"line\">        </span><br><span class=\"line\">        output_mid = output_mid.transpose(<span class=\"number\">1</span>, <span class=\"number\">2</span>).contiguous() <span class=\"comment\"># 链接不同header</span></span><br><span class=\"line\">        output_mid = output_mid.view(batch, seq_len, -<span class=\"number\">1</span>)</span><br><span class=\"line\">        </span><br><span class=\"line\">        output = <span class=\"variable language_\">self</span>.out_proj(output_mid)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> output</span><br><span class=\"line\"><span class=\"comment\"># test</span></span><br><span class=\"line\">attention_mask = (</span><br><span class=\"line\">    torch.tensor(</span><br><span class=\"line\">    [</span><br><span class=\"line\">        [<span class=\"number\">0</span>, <span class=\"number\">1</span>],</span><br><span class=\"line\">        [<span class=\"number\">0</span>, <span class=\"number\">0</span>],</span><br><span class=\"line\">        [<span class=\"number\">1</span>, <span class=\"number\">0</span>]</span><br><span class=\"line\">    ])</span><br><span class=\"line\">    .unsqueeze(<span class=\"number\">1</span>)</span><br><span class=\"line\">    .unsqueeze(<span class=\"number\">2</span>)</span><br><span class=\"line\">    .expand(<span class=\"number\">3</span>, <span class=\"number\">8</span>, <span class=\"number\">2</span>, <span class=\"number\">2</span>)</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\">X = torch.rand(<span class=\"number\">3</span>, <span class=\"number\">2</span>, <span class=\"number\">128</span>)</span><br><span class=\"line\">net = MutiHeadSelfAttentionFormal(<span class=\"number\">128</span>, <span class=\"number\">8</span>)</span><br><span class=\"line\">net(X, attention_mask)</span><br></pre></td></tr></table></figure>\n<h1 id=\"transformers\"><a class=\"markdownIt-Anchor\" href=\"#transformers\">#</a> Transformers</h1>\n<p>因此 Transformers 可分块写为</p>\n<ul>\n<li>\n<p>MHA</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">import</span> math</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch.nn <span class=\"keyword\">as</span> nn</span><br><span class=\"line\"><span class=\"keyword\">import</span> copy</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 多头注意力</span></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">MutiHeadSelfAttentionFormal</span>(nn.Module):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self, dim, head_num, attentnion_dropout=<span class=\"number\">0.1</span></span>):</span><br><span class=\"line\">        <span class=\"built_in\">super</span>().__init__()</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.hidden_dim = dim</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.head_num = head_num</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.head_dim = dim // head_num <span class=\"comment\"># (head_num * head_dim = dim)</span></span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.q_proj = nn.Linear(dim, dim) <span class=\"comment\"># (dim, head_num * head_dim) 后面可以用split拆分</span></span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.k_proj = nn.Linear(dim, dim)</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.v_proj = nn.Linear(dim, dim)</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.out_proj = nn.Linear(dim, dim)</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.attentnion_dropout = nn.Dropout(attentnion_dropout)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, query, key, value, attention_mask=<span class=\"literal\">None</span>,  mask_type=<span class=\"string\">&quot;Encoder&quot;</span></span>):</span><br><span class=\"line\">        <span class=\"string\">&quot;&quot;&quot;</span></span><br><span class=\"line\"><span class=\"string\">        In Encoder: query = key = value = X;</span></span><br><span class=\"line\"><span class=\"string\">        in Decoder: query = X, key = value = m</span></span><br><span class=\"line\"><span class=\"string\">        &quot;&quot;&quot;</span></span><br><span class=\"line\">        <span class=\"comment\"># X (batch, seq, hidden_dim)</span></span><br><span class=\"line\">        batch, seq_len, _ = query.size()</span><br><span class=\"line\">        </span><br><span class=\"line\">        Q = <span class=\"variable language_\">self</span>.q_proj(query)</span><br><span class=\"line\">        K = <span class=\"variable language_\">self</span>.k_proj(key)</span><br><span class=\"line\">        V = <span class=\"variable language_\">self</span>.v_proj(value) <span class=\"comment\"># (b, s, h)</span></span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"comment\"># (b, s, h) -&gt; (b, head_num, s, head_dim) # (head_num * head_dim = h)</span></span><br><span class=\"line\">        q_state = Q.view(batch, seq_len, <span class=\"variable language_\">self</span>.head_num, <span class=\"variable language_\">self</span>.head_dim).transpose(<span class=\"number\">1</span>, <span class=\"number\">2</span>)</span><br><span class=\"line\">        k_state = K.view(batch, seq_len, <span class=\"variable language_\">self</span>.head_num, <span class=\"variable language_\">self</span>.head_dim).transpose(<span class=\"number\">1</span>, <span class=\"number\">2</span>)</span><br><span class=\"line\">        v_state = V.view(batch, seq_len, <span class=\"variable language_\">self</span>.head_num, <span class=\"variable language_\">self</span>.head_dim).transpose(<span class=\"number\">1</span>, <span class=\"number\">2</span>)</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"comment\"># (b, head_num, s, s)</span></span><br><span class=\"line\">        attention_weight = torch.matmul(</span><br><span class=\"line\">            q_state, k_state.transpose(-<span class=\"number\">1</span>, -<span class=\"number\">2</span>)</span><br><span class=\"line\">        )/math.sqrt(<span class=\"variable language_\">self</span>.head_dim)</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"keyword\">if</span> attention_mask <span class=\"keyword\">is</span> <span class=\"literal\">None</span>:</span><br><span class=\"line\">            <span class=\"keyword\">if</span> mask_type == <span class=\"string\">&quot;Encoder&quot;</span>:</span><br><span class=\"line\">                attention_mask = torch.ones_like(attention_weight) <span class=\"comment\"># 全是1的矩阵</span></span><br><span class=\"line\">            <span class=\"keyword\">elif</span> mask_type == <span class=\"string\">&quot;Decoder&quot;</span>:</span><br><span class=\"line\">                attention_mask = torch.ones_like(attention_weight).tril() <span class=\"comment\"># 全是1的矩阵构建下三角矩阵</span></span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            <span class=\"keyword\">if</span> mask_type == <span class=\"string\">&quot;Encoder&quot;</span>:</span><br><span class=\"line\">                <span class=\"keyword\">pass</span></span><br><span class=\"line\">            <span class=\"keyword\">elif</span> mask_type == <span class=\"string\">&quot;Decoder&quot;</span>:</span><br><span class=\"line\">                attention_mask = attention_mask.tril()</span><br><span class=\"line\">        attention_weight = attention_weight.masked_fill(attention_mask==<span class=\"number\">0</span>, <span class=\"built_in\">float</span>(<span class=\"string\">&#x27;-1e20&#x27;</span>))</span><br><span class=\"line\">        <span class=\"comment\"># print(attention_weight.shape)</span></span><br><span class=\"line\"></span><br><span class=\"line\">        attention_weight = torch.softmax(attention_weight, dim=-<span class=\"number\">1</span>)</span><br><span class=\"line\">        attention_weight = <span class=\"variable language_\">self</span>.attentnion_dropout(attention_weight)</span><br><span class=\"line\">        </span><br><span class=\"line\">        output_mid = attention_weight @ v_state <span class=\"comment\"># (b, head_num, s, head_dim)</span></span><br><span class=\"line\">        </span><br><span class=\"line\">        output_mid = output_mid.transpose(<span class=\"number\">1</span>, <span class=\"number\">2</span>).contiguous() <span class=\"comment\"># 链接不同header</span></span><br><span class=\"line\">        output_mid = output_mid.view(batch, seq_len, -<span class=\"number\">1</span>)</span><br><span class=\"line\">        </span><br><span class=\"line\">        output = <span class=\"variable language_\">self</span>.out_proj(output_mid)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> output</span><br></pre></td></tr></table></figure>\n</li>\n<li>\n<p>Feed-forward network 前馈神经网络（FFN）</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>F</mi><mi>F</mi><mi>N</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mi>R</mi><mi>E</mi><mi>L</mi><mi>U</mi><mo stretchy=\"false\">(</mo><mi>x</mi><msub><mi>W</mi><mn>1</mn></msub><mo>+</mo><msub><mi>b</mi><mn>1</mn></msub><mo stretchy=\"false\">)</mo><msub><mi>W</mi><mn>2</mn></msub><mo>+</mo><msub><mi>b</mi><mn>2</mn></msub></mrow><annotation encoding=\"application/x-tex\">FFN(x) = RELU(xW_1 + b_1)W_2 + b_2\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">F</span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">F</span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.00773em;\">R</span><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">E</span><span class=\"mord mathnormal\">L</span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">U</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">b</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">b</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></span></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># FFN</span></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">ffn</span>(nn.Module):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self, dim, ffn_dropout_rate=<span class=\"number\">0.1</span></span>):</span><br><span class=\"line\">        <span class=\"built_in\">super</span>().__init__()</span><br><span class=\"line\">        <span class=\"comment\"># ffn Position-wise Feed-Forward Networks（FFN） 升维 -&gt; 降维 -&gt; LayerNorm</span></span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.up_proj = nn.Linear(dim, dim*<span class=\"number\">4</span>)</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.act_fn = nn.GELU() <span class=\"comment\"># 可换用RELU</span></span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.down_proj = nn.Linear(dim*<span class=\"number\">4</span>, dim)</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.drop_ffn = nn.Dropout(ffn_dropout_rate)</span><br><span class=\"line\">        <span class=\"comment\">#self.ffn_ln = nn.LayerNorm(dim, eps=0.0000001) # smooth</span></span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, X</span>):</span><br><span class=\"line\">        <span class=\"comment\"># ffn</span></span><br><span class=\"line\">        up = <span class=\"variable language_\">self</span>.up_proj(X) <span class=\"comment\"># 升维</span></span><br><span class=\"line\">        up = <span class=\"variable language_\">self</span>.act_fn(up) <span class=\"comment\"># 激活 GELU</span></span><br><span class=\"line\">        down = <span class=\"variable language_\">self</span>.down_proj(<span class=\"variable language_\">self</span>.drop_ffn(up)) <span class=\"comment\"># 降维</span></span><br><span class=\"line\">        <span class=\"comment\">#down = self.drop_ffn(down) # drop</span></span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"comment\"># add &amp; Norm</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> down</span><br></pre></td></tr></table></figure>\n</li>\n<li>\n<p>Encoder</p>\n<p>将 Encoder 的各个组分连接起来</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Function clones modules</span></span><br><span class=\"line\"><span class=\"comment\"># useful function</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">clones</span>(<span class=\"params\">module, N</span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;Produce N identical layers.&quot;</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> nn.ModuleList([copy.deepcopy(module) <span class=\"keyword\">for</span> _ <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(N)])</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># add &amp; norm</span></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">add_and_norm</span>(nn.Module):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self, dim, add_dropout_rate=<span class=\"number\">0.1</span></span>):</span><br><span class=\"line\">        <span class=\"built_in\">super</span>().__init__()</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.norm = nn.LayerNorm(dim, eps=<span class=\"number\">0.0000001</span>)</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.add_dropout = nn.Dropout(add_dropout_rate)</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, X, sublayer</span>):</span><br><span class=\"line\">        <span class=\"keyword\">return</span> X + <span class=\"variable language_\">self</span>.add_dropout(sublayer(<span class=\"variable language_\">self</span>.norm(X)))</span><br></pre></td></tr></table></figure>\n<p>Encoder 结构</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Encoder</span></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">EncoderLayer</span>(nn.Module):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self, dim, self_attn, self_ffn</span>):</span><br><span class=\"line\">        <span class=\"built_in\">super</span>().__init__()</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.hidden_dim = dim</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.self_attn = self_attn <span class=\"comment\"># attention layer</span></span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.self_ffn = self_ffn <span class=\"comment\"># ffn layer</span></span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.add_norm_layers = clones(add_and_norm(dim), <span class=\"number\">2</span>) <span class=\"comment\"># add and norm layer</span></span><br><span class=\"line\">        </span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, X, mask</span>):</span><br><span class=\"line\">        <span class=\"comment\"># add &amp; norm结构的forward接受sublayer为函数对象</span></span><br><span class=\"line\">        <span class=\"comment\"># attention layer 则需要多个参数X于mask，因此调用了lambda构造函数</span></span><br><span class=\"line\">        s1 = <span class=\"variable language_\">self</span>.add_norm_layers[<span class=\"number\">0</span>](X, <span class=\"keyword\">lambda</span> X: <span class=\"variable language_\">self</span>.self_attn(X, X, X, mask))</span><br><span class=\"line\">        s2 = <span class=\"variable language_\">self</span>.add_norm_layers[<span class=\"number\">1</span>](s1, <span class=\"variable language_\">self</span>.self_ffn) <span class=\"comment\"># FFN</span></span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"keyword\">return</span> s2</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">Encoder</span>(nn.Module):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self, dim, self_attn, self_ffn, N=<span class=\"number\">6</span></span>):</span><br><span class=\"line\">        <span class=\"string\">&quot;&quot;&quot;</span></span><br><span class=\"line\"><span class=\"string\">        dim: input hidden dim;</span></span><br><span class=\"line\"><span class=\"string\">        self_attn: MHA object;</span></span><br><span class=\"line\"><span class=\"string\">        self_ffn: FFN object;</span></span><br><span class=\"line\"><span class=\"string\">        N: layers number</span></span><br><span class=\"line\"><span class=\"string\">        &quot;&quot;&quot;</span></span><br><span class=\"line\">        <span class=\"built_in\">super</span>().__init__()</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.layer_list = clones(EncoderLayer(dim, self_attn, self_ffn), N)</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.norm = nn.LayerNorm(dim, eps=<span class=\"number\">0.0000001</span>)</span><br><span class=\"line\">        </span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, X, mask=<span class=\"literal\">None</span></span>):</span><br><span class=\"line\">        <span class=\"string\">&quot;Pass the input (and mask) through each layer in turn.&quot;</span></span><br><span class=\"line\">        <span class=\"keyword\">for</span> m <span class=\"keyword\">in</span> <span class=\"variable language_\">self</span>.layer_list:</span><br><span class=\"line\">            X = m(X, mask) <span class=\"comment\"># 每个EncoderLayer构建模型</span></span><br><span class=\"line\">        <span class=\"built_in\">print</span>(X.shape)</span><br><span class=\"line\">        </span><br><span class=\"line\">        output = <span class=\"variable language_\">self</span>.norm(X)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> output</span><br></pre></td></tr></table></figure>\n</li>\n<li>\n<p>Decoder</p>\n<p>Decoder 跟 Encoder 的结构类似，只是组合方式不一样</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Decoder</span></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">DecoderLayer</span>(nn.Module):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self, dim, self_attn, src_attn, self_ffn</span>):</span><br><span class=\"line\">        <span class=\"built_in\">super</span>().__init__()</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.hidden_dim = dim</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.self_attn = self_attn</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.src_att = src_attn</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.self_ffn = self_ffn <span class=\"comment\"># 这里的ffn实际为 ffn + add &amp; Normal</span></span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.add_norm_layers = clones(add_and_norm(dim), <span class=\"number\">3</span>) <span class=\"comment\"># add and norm layer</span></span><br><span class=\"line\">        </span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, X, memory, src_mask=<span class=\"literal\">None</span>, tgt_mask=<span class=\"literal\">None</span></span>):</span><br><span class=\"line\">        m = memory</span><br><span class=\"line\">        <span class=\"comment\"># step1 attention</span></span><br><span class=\"line\">        s1 = <span class=\"variable language_\">self</span>.add_norm_layers[<span class=\"number\">0</span>](X, <span class=\"keyword\">lambda</span> X: <span class=\"variable language_\">self</span>.self_attn(X, X, X, src_mask))</span><br><span class=\"line\">        <span class=\"comment\"># step2 attention with memory</span></span><br><span class=\"line\">        s2 = <span class=\"variable language_\">self</span>.add_norm_layers[<span class=\"number\">1</span>](s1, <span class=\"keyword\">lambda</span> X: <span class=\"variable language_\">self</span>.self_attn(s1, m, m, tgt_mask))</span><br><span class=\"line\">        <span class=\"comment\"># ffn</span></span><br><span class=\"line\">        s3 = <span class=\"variable language_\">self</span>.add_norm_layers[<span class=\"number\">2</span>](s2, <span class=\"variable language_\">self</span>.self_ffn)</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"keyword\">return</span> s3</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">Decoder</span>(nn.Module):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self, dim, self_attn, src_attn, self_ffn, N=<span class=\"number\">6</span></span>):</span><br><span class=\"line\">        <span class=\"string\">&quot;&quot;&quot;</span></span><br><span class=\"line\"><span class=\"string\">        dim: input hidden dim;</span></span><br><span class=\"line\"><span class=\"string\">        self_attn: MHA object;</span></span><br><span class=\"line\"><span class=\"string\">        self_ffn: FFN object;</span></span><br><span class=\"line\"><span class=\"string\">        N: layers number</span></span><br><span class=\"line\"><span class=\"string\">        &quot;&quot;&quot;</span></span><br><span class=\"line\">        <span class=\"built_in\">super</span>().__init__()</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.layer_list = clones(DecoderLayer(dim, self_attn, src_attn, self_ffn), N)</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.norm = nn.LayerNorm(dim, eps=<span class=\"number\">0.0000001</span>)</span><br><span class=\"line\">        </span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, X, memory, src_mask=<span class=\"literal\">None</span>, tgt_mask=<span class=\"literal\">None</span></span>):</span><br><span class=\"line\">        <span class=\"string\">&quot;Pass the input (and mask) through each layer in turn.&quot;</span></span><br><span class=\"line\">        <span class=\"keyword\">for</span> m <span class=\"keyword\">in</span> <span class=\"variable language_\">self</span>.layer_list:</span><br><span class=\"line\">            X = m(X, memory, src_mask=<span class=\"literal\">None</span>, tgt_mask=<span class=\"literal\">None</span>) <span class=\"comment\"># 每个DecoderLayer构建模型</span></span><br><span class=\"line\">        <span class=\"built_in\">print</span>(X.shape)</span><br><span class=\"line\">        </span><br><span class=\"line\">        output = <span class=\"variable language_\">self</span>.norm(X)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> torch.softmax(output, dim=-<span class=\"number\">1</span>)</span><br></pre></td></tr></table></figure>\n</li>\n<li>\n<p>Test</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># test NB!</span></span><br><span class=\"line\">c = copy.deepcopy</span><br><span class=\"line\"></span><br><span class=\"line\">attention_mask = (</span><br><span class=\"line\">    torch.tensor(</span><br><span class=\"line\">    [</span><br><span class=\"line\">        [<span class=\"number\">0</span>, <span class=\"number\">1</span>],</span><br><span class=\"line\">        [<span class=\"number\">0</span>, <span class=\"number\">0</span>],</span><br><span class=\"line\">        [<span class=\"number\">1</span>, <span class=\"number\">0</span>]</span><br><span class=\"line\">    ])</span><br><span class=\"line\">    .unsqueeze(<span class=\"number\">1</span>)</span><br><span class=\"line\">    .unsqueeze(<span class=\"number\">2</span>)</span><br><span class=\"line\">    .expand(<span class=\"number\">3</span>, <span class=\"number\">8</span>, <span class=\"number\">2</span>, <span class=\"number\">2</span>)</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\">X = torch.rand(<span class=\"number\">3</span>, <span class=\"number\">2</span>, <span class=\"number\">128</span>)</span><br><span class=\"line\"><span class=\"comment\"># module init</span></span><br><span class=\"line\">attn_net = MutiHeadSelfAttentionFormal(<span class=\"number\">128</span>, <span class=\"number\">8</span>)</span><br><span class=\"line\">ffn_net = ffn(<span class=\"number\">128</span>)</span><br><span class=\"line\">Encoder_net = Encoder(<span class=\"number\">128</span>, c(attn_net), c(ffn_net))</span><br><span class=\"line\">Decoder_net = Decoder(<span class=\"number\">128</span>, c(attn_net), c(attn_net), c(ffn_net))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># run</span></span><br><span class=\"line\">E1 = Encoder_net(X, attention_mask)</span><br><span class=\"line\">D1 = Decoder_net(X, E1)</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<p>到此为止我们有了 Transformers 的基础架构，后面再仔细看看 Embedding 与 Training 部分</p>\n<div class=\"note danger no-icon\">\n<p>continuing</p>\n</div>\n<h1 id=\"reference\"><a class=\"markdownIt-Anchor\" href=\"#reference\">#</a> Reference</h1>\n<p><span class=\"exturl\" data-url=\"aHR0cHM6Ly9ubHAuc2Vhcy5oYXJ2YXJkLmVkdS9hbm5vdGF0ZWQtdHJhbnNmb3JtZXIvI2RlY29kZXItc2VsZi1hdHRlbnRpb24=\">The Annotated Transformer</span></p>\n<p><span class=\"exturl\" data-url=\"aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC82MzEzOTg1MjU=\">注意力机制综述（图解完整版附代码） - 知乎</span></p>\n<p><span class=\"exturl\" data-url=\"aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ0NzIyMTg5L2FydGljbGUvZGV0YWlscy8xMzUwMzUzNTE=\">Pytorch nn.Linear () 的基本用法与原理详解及全连接层简介 - CSDN 博客</span></p>\n<p><span class=\"exturl\" data-url=\"aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC8zOTgwMzkzNjY=\">Transformer 源码详解（Pytorch 版本） - 知乎</span></p>\n<p><span class=\"exturl\" data-url=\"aHR0cHM6Ly9zcGFjZS5iaWxpYmlsaS5jb20vMTI0MjA0MzI=\">chaofa 用代码打点酱油的个人空间 - chaofa 用代码打点酱油个人主页 - 哔哩哔哩视频</span></p>\n",
            "tags": [
                "Mechine learning",
                "Transformers",
                "Mechine learning",
                "Transformers"
            ]
        },
        {
            "id": "http://example.com/2024/12/24/hexo-config/",
            "url": "http://example.com/2024/12/24/hexo-config/",
            "title": "hexo-config",
            "date_published": "2024-12-24T08:44:47.000Z",
            "content_html": "<h1 id=\"hexo-github配置\"><a class=\"markdownIt-Anchor\" href=\"#hexo-github配置\">#</a> hexo + github 配置</h1>\n<p>之前用 readthedoc 感觉体验不好，又看到了 https://shoka.lostyu.me/computer-science/note/theme-shoka-doc/ 大佬的博客页面，<s>本二次元</s>跃跃欲试，就直接冲！</p>\n<h1 id=\"安装hexo\"><a class=\"markdownIt-Anchor\" href=\"#安装hexo\">#</a> 安装 hexo</h1>\n<p>hexo 基于 node.js，使用 npm 安装</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">npm install  -g hexo-cli</span><br><span class=\"line\">mkdir /path/to/hexo/root/dir/</span><br><span class=\"line\">hexo init /path/to/hexo/root/dir/ # 初始化</span><br><span class=\"line\">cd /path/to/hexo/root/dir/</span><br><span class=\"line\">npm install</span><br><span class=\"line\">npm install hexo-server --save</span><br></pre></td></tr></table></figure>\n<p>主题安装参考 https://shoka.lostyu.me/computer-science/note/theme-shoka-doc/ (注意安装插件)</p>\n<p>或者选用自己喜欢的主题</p>\n<h1 id=\"hexo-github配置-2\"><a class=\"markdownIt-Anchor\" href=\"#hexo-github配置-2\">#</a> hexo + github 配置</h1>\n<p>基于 Github pages 构建 hexo 博客</p>\n<ol>\n<li>\n<p>创建 github repositories</p>\n<p>此处名称必须为 <code>username.github.io</code> ，否则出现 404https://github.com/hexojs/hexo/issues/350</p>\n</li>\n<li>\n<p>进入 hexo root 目录</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">npm install hexo-deployer-git --save</span><br></pre></td></tr></table></figure>\n</li>\n<li>\n<p>编辑_config.yml 文件</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">deploy:</span></span><br><span class=\"line\">  <span class=\"attr\">type:</span> <span class=\"string\">&#x27;git&#x27;</span></span><br><span class=\"line\">  <span class=\"attr\">repo:</span> <span class=\"string\">https://github.com/username/username.github.io</span></span><br><span class=\"line\">  <span class=\"comment\"># https://github.com/username/username.github.io.git</span></span><br><span class=\"line\">  <span class=\"attr\">branch:</span> <span class=\"string\">main</span></span><br></pre></td></tr></table></figure>\n</li>\n<li>\n<p>设置 github repositories</p>\n<p>pages -&gt; Build and deployment -&gt; 设置 soure 为 main</p>\n<p>可通过 GitHub Pages 访问或者直接访问 <code>https://username.github.io</code></p>\n</li>\n</ol>\n<h1 id=\"hexo使用\"><a class=\"markdownIt-Anchor\" href=\"#hexo使用\">#</a> hexo 使用</h1>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">git cmd <span class=\"built_in\">command</span></span></span><br><span class=\"line\">cd /path/to/hexo/root/dir/</span><br><span class=\"line\">hexo n &quot;VAE&quot;</span><br><span class=\"line\"><span class=\"meta prompt_\"></span></span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">设置Front matter</span></span><br><span class=\"line\"><span class=\"meta prompt_\">#</span><span class=\"language-bash\">---</span></span><br><span class=\"line\"><span class=\"meta prompt_\">#</span><span class=\"language-bash\">title: VAE</span></span><br><span class=\"line\"><span class=\"meta prompt_\">#</span><span class=\"language-bash\"><span class=\"built_in\">date</span>: 2024-12-24 10:39:33</span></span><br><span class=\"line\"><span class=\"meta prompt_\">#</span><span class=\"language-bash\">tags:</span> </span><br><span class=\"line\"><span class=\"meta prompt_\">#</span><span class=\"language-bash\">- Mechine learning</span></span><br><span class=\"line\"><span class=\"meta prompt_\">#</span><span class=\"language-bash\">categories:</span></span><br><span class=\"line\"><span class=\"meta prompt_\">#</span><span class=\"language-bash\">- Mechine learning</span></span><br><span class=\"line\"><span class=\"meta prompt_\">#</span><span class=\"language-bash\">keywords:</span></span><br><span class=\"line\"><span class=\"meta prompt_\">#</span><span class=\"language-bash\">- Mechine learning</span></span><br><span class=\"line\"><span class=\"meta prompt_\">#</span><span class=\"language-bash\">- VAE</span></span><br><span class=\"line\"><span class=\"meta prompt_\">#</span><span class=\"language-bash\">math: <span class=\"literal\">true</span></span></span><br><span class=\"line\"><span class=\"meta prompt_\">#</span><span class=\"language-bash\">mermaid: <span class=\"literal\">true</span></span></span><br><span class=\"line\"><span class=\"meta prompt_\">#</span><span class=\"language-bash\">---</span></span><br><span class=\"line\"></span><br><span class=\"line\">hexo clean &amp;&amp; hexo g</span><br><span class=\"line\">hexo s #预览</span><br><span class=\"line\">hexo d #上传</span><br></pre></td></tr></table></figure>\n<h1 id=\"花里胡哨的功能\"><a class=\"markdownIt-Anchor\" href=\"#花里胡哨的功能\">#</a> 花里胡哨的功能</h1>\n<p><strong>20241224</strong></p>\n<p>可设置随机图床，D:\\0_Project\\hexo\\themes\\shoka\\config.yml</p>\n<p><code>image_server: &quot;https://api.paugram.com/wallpaper&quot;</code></p>\n<div class=\"note danger no-icon\">\n<p>Continuing</p>\n</div>\n<h1 id=\"参考\"><a class=\"markdownIt-Anchor\" href=\"#参考\">#</a> 参考</h1>\n<p><span class=\"exturl\" data-url=\"aHR0cHM6Ly9zaG9rYS5sb3N0eXUubWUvY29tcHV0ZXItc2NpZW5jZS9ub3RlL3RoZW1lLXNob2thLWRvYy8=\">https://shoka.lostyu.me/computer-science/note/theme-shoka-doc/</span></p>\n<p><span class=\"exturl\" data-url=\"aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzY1OTcyNS9hcnRpY2xlL2RldGFpbHMvMTI1MjA3Mzgz\">https://blog.csdn.net/weixin_43659725/article/details/125207383</span></p>\n<p><span class=\"exturl\" data-url=\"aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3lhb3JvbmdrZS9hcnRpY2xlL2RldGFpbHMvMTE5MDg5MTkw\">https://blog.csdn.net/yaorongke/article/details/119089190</span></p>\n",
            "tags": [
                "Tips",
                "Tips"
            ]
        },
        {
            "id": "http://example.com/2024/12/24/readthedocs/",
            "url": "http://example.com/2024/12/24/readthedocs/",
            "title": "readthedocs",
            "date_published": "2024-12-24T08:40:35.000Z",
            "content_html": "<h1 id=\"readthedocs\"><a class=\"markdownIt-Anchor\" href=\"#readthedocs\">#</a> readthedocs</h1>\n<h2 id=\"配置总结\"><a class=\"markdownIt-Anchor\" href=\"#配置总结\">#</a> 配置总结</h2>\n<ul>\n<li>\n<p>注册账号 (略)</p>\n</li>\n<li>\n<p>本地构建</p>\n<blockquote>\n<p>基于 python 3.12</p>\n</blockquote>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">安装Sphinx（必须）</span></span><br><span class=\"line\">pip3 install -U Sphinx</span><br><span class=\"line\">mkdir my_readthedocs</span><br><span class=\"line\">cd my_readthedocs</span><br><span class=\"line\">sphinx-quickstart # 直接键入命令行</span><br><span class=\"line\">make html</span><br></pre></td></tr></table></figure>\n<p>一路回车，可选项见参考</p>\n<p>更改主题（可选）</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pip3 install sphinx_rtd_theme</span><br></pre></td></tr></table></figure>\n<p>md 支持（可选）</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pip3 install recommonmark</span><br></pre></td></tr></table></figure>\n<p>配置 <code>source/conf.py</code></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Configuration file for the Sphinx documentation builder.</span></span><br><span class=\"line\"><span class=\"comment\">#</span></span><br><span class=\"line\"><span class=\"comment\"># For the full list of built-in configuration values, see the documentation:</span></span><br><span class=\"line\"><span class=\"comment\"># https://www.sphinx-doc.org/en/master/usage/configuration.html</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># -- Project information -----------------------------------------------------</span></span><br><span class=\"line\"><span class=\"comment\"># https://www.sphinx-doc.org/en/master/usage/configuration.html#project-information</span></span><br><span class=\"line\"></span><br><span class=\"line\">project = <span class=\"string\">&#x27;my_readthedocs&#x27;</span></span><br><span class=\"line\">copyright = <span class=\"string\">&#x27;2024, jkfo&#x27;</span></span><br><span class=\"line\">author = <span class=\"string\">&#x27;jkfo&#x27;</span></span><br><span class=\"line\">release = <span class=\"string\">&#x27;0.1.1&#x27;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># -- General configuration ---------------------------------------------------</span></span><br><span class=\"line\"><span class=\"comment\"># https://www.sphinx-doc.org/en/master/usage/configuration.html#general-configuration</span></span><br><span class=\"line\"></span><br><span class=\"line\">extensions = []</span><br><span class=\"line\"></span><br><span class=\"line\">templates_path = [<span class=\"string\">&#x27;_templates&#x27;</span>]</span><br><span class=\"line\">exclude_patterns = []</span><br><span class=\"line\"></span><br><span class=\"line\">language = <span class=\"string\">&#x27;zh_CN&#x27;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># -- Options for HTML output -------------------------------------------------</span></span><br><span class=\"line\"><span class=\"comment\"># https://www.sphinx-doc.org/en/master/usage/configuration.html#options-for-html-output</span></span><br><span class=\"line\"></span><br><span class=\"line\">html_theme = <span class=\"string\">&#x27;alabaster&#x27;</span></span><br><span class=\"line\">html_static_path = [<span class=\"string\">&#x27;_static&#x27;</span>]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## add</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> sphinx_rtd_theme</span><br><span class=\"line\">html_theme = <span class=\"string\">&quot;sphinx_rtd_theme&quot;</span></span><br><span class=\"line\">html_theme_path = [sphinx_rtd_theme.get_html_theme_path()]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## add</span></span><br><span class=\"line\">extensions = [</span><br><span class=\"line\">    <span class=\"string\">&#x27;recommonmark&#x27;</span></span><br><span class=\"line\">]</span><br></pre></td></tr></table></figure>\n</li>\n<li>\n<p>github (略)</p>\n</li>\n<li>\n<p>项目托管</p>\n<p>若需要项目托管的话，需要在 github 中添加 <code>.readthedocs.yaml</code></p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Read the Docs configuration file for Sphinx projects</span></span><br><span class=\"line\"><span class=\"comment\"># See https://docs.readthedocs.io/en/stable/config-file/v2.html for details</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Required</span></span><br><span class=\"line\"><span class=\"attr\">version:</span> <span class=\"number\">2</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Set the OS, Python version and other tools you might need</span></span><br><span class=\"line\"><span class=\"attr\">build:</span></span><br><span class=\"line\">  <span class=\"attr\">os:</span> <span class=\"string\">ubuntu-22.04</span> <span class=\"comment\"># 不用管</span></span><br><span class=\"line\">  <span class=\"attr\">tools:</span></span><br><span class=\"line\">    <span class=\"attr\">python:</span> <span class=\"string\">&quot;3.12&quot;</span></span><br><span class=\"line\">    <span class=\"comment\"># You can also specify other tool versions:</span></span><br><span class=\"line\">    <span class=\"comment\"># nodejs: &quot;20&quot;</span></span><br><span class=\"line\">    <span class=\"comment\"># rust: &quot;1.70&quot;</span></span><br><span class=\"line\">    <span class=\"comment\"># golang: &quot;1.20&quot;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Build documentation in the &quot;docs/&quot; directory with Sphinx</span></span><br><span class=\"line\"><span class=\"attr\">sphinx:</span></span><br><span class=\"line\">  <span class=\"attr\">configuration:</span> <span class=\"string\">source/conf.py</span> <span class=\"comment\"># 更改为自己的路径，有的为docs</span></span><br><span class=\"line\">  <span class=\"comment\"># You can configure Sphinx to use a different builder, for instance use the dirhtml builder for simpler URLs</span></span><br><span class=\"line\">  <span class=\"comment\"># builder: &quot;dirhtml&quot;</span></span><br><span class=\"line\">  <span class=\"comment\"># Fail on all warnings to avoid broken references</span></span><br><span class=\"line\">  <span class=\"comment\"># fail_on_warning: true</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Optionally build your docs in additional formats such as PDF and ePub</span></span><br><span class=\"line\"><span class=\"comment\"># formats:</span></span><br><span class=\"line\"><span class=\"comment\">#   - pdf</span></span><br><span class=\"line\"><span class=\"comment\">#   - epub</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Optional but recommended, declare the Python requirements required</span></span><br><span class=\"line\"><span class=\"comment\"># to build your documentation</span></span><br><span class=\"line\"><span class=\"comment\"># See https://docs.readthedocs.io/en/stable/guides/reproducible-builds.html</span></span><br><span class=\"line\"><span class=\"attr\">python:</span></span><br><span class=\"line\">  <span class=\"attr\">install:</span></span><br><span class=\"line\">    <span class=\"bullet\">-</span> <span class=\"attr\">requirements:</span> <span class=\"string\">requirements.txt</span> <span class=\"comment\"># 需要添加的python包</span></span><br></pre></td></tr></table></figure>\n<p><code>requirements.txt</code>  为必须</p>\n<blockquote>\n<p>sphinx_rtd_theme<br>\nrecommonmark</p>\n</blockquote>\n</li>\n<li>\n<p>更新</p>\n<p>本地更改后 push 到 github 就可以，readthedocs 自动更新</p>\n</li>\n</ul>\n<h2 id=\"参考\"><a class=\"markdownIt-Anchor\" href=\"#参考\">#</a> 参考</h2>\n<p><code>https://readthedocs-demo-zh.readthedocs.io/zh-cn/latest/%E6%96%87%E4%BB%B6%E6%89%98%E7%AE%A1%E7%B3%BB%E7%BB%9F-ReadtheDocs.html#id1</code></p>\n<p><code>https://blog.csdn.net/lu_embedded/article/details/109006380</code></p>\n",
            "tags": [
                "Tips",
                "Tips"
            ]
        },
        {
            "id": "http://example.com/2024/12/24/git/",
            "url": "http://example.com/2024/12/24/git/",
            "title": "git",
            "date_published": "2024-12-24T08:38:49.000Z",
            "content_html": "<h1 id=\"git\"><a class=\"markdownIt-Anchor\" href=\"#git\">#</a> git</h1>\n<h2 id=\"一些常用的git还有踩过的坑\"><a class=\"markdownIt-Anchor\" href=\"#一些常用的git还有踩过的坑\">#</a> 一些常用的 git 还有踩过的坑</h2>\n<ul>\n<li>\n<p>配置用户名与邮箱，用户名与 git 账号相同，邮箱类似。</p>\n<p>在最开始配置即可，后面就不用二次配置，可更改（<s>坑 + 1</s>）</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git config --global user.name &quot;GitHub用户名&quot;</span><br><span class=\"line\">git config --global user.email &quot;注册GitHub用的邮箱&quot;</span><br></pre></td></tr></table></figure>\n</li>\n<li>\n<p>ssh key</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ssh-keygen -t rsa -C &quot;注册GitHub用的邮箱&quot;</span><br></pre></td></tr></table></figure>\n<p>生成 ssh key，需要在账户中的 <code>Settings</code>  的 <code>SSH and GPG keys</code>  添加 <code>SSH keys</code>  随便起个名字就可以</p>\n</li>\n<li>\n<p>远程创建仓库</p>\n<p><code>git@github.com/&lt;username&gt;/&lt;repositeriename&gt;</code></p>\n</li>\n<li>\n<p>链接远程仓库</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git init</span><br><span class=\"line\">git add .</span><br><span class=\"line\">git commit -m &quot;提交信息&quot;</span><br><span class=\"line\">git remote add origin git@github.com/&lt;username&gt;/&lt;repositeriename&gt;</span><br><span class=\"line\">git push -u origin main</span><br></pre></td></tr></table></figure>\n<p><code>这个main即分支，后面的一些对于分支的操作要指定分支名称，网上很多命令使用master，要确定</code></p>\n</li>\n<li>\n<p>后续更新</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">(添加/更改文件文件)</span></span><br><span class=\"line\">git status #(查看状态 是否需要更新)</span><br><span class=\"line\">git add .</span><br><span class=\"line\">git commit -m &quot;add readthedocs.yaml&quot;</span><br><span class=\"line\">git push </span><br></pre></td></tr></table></figure>\n<p>当你的远程仓库出现过其他更新的时候，需要先 fetch (<s>坑 + 1</s>)，之前在网站点了 <code>add Readme.md</code> ，折腾了好久</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git fetch origin main #(当远程git与本地git不同使用)</span><br><span class=\"line\">git merge main #(与本地进行合并)</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<h2 id=\"其他坑欢迎分享\"><a class=\"markdownIt-Anchor\" href=\"#其他坑欢迎分享\">#</a> 其他坑欢迎分享</h2>\n<p>有空会更新，或者直接 pull requset</p>\n<p><code>https://github.com/jkfo002/my_readthedocs/issues</code></p>\n",
            "tags": [
                "Tips",
                "Tips"
            ]
        },
        {
            "id": "http://example.com/2024/12/24/Tau/",
            "url": "http://example.com/2024/12/24/Tau/",
            "title": "Tau",
            "date_published": "2024-12-24T08:36:52.000Z",
            "content_html": "<h1 id=\"tau\"><a class=\"markdownIt-Anchor\" href=\"#tau\">#</a> Tau</h1>\n<p>Evolution of tissue-specific expression of ancestral genes across vertebrates and insects 中计算组织特异表达基因提到了一个参数 <code>Tau</code> ，文中参考文献 <code>Genome-wide midrange transcription profiles reveal expression level relationships in human tissue specification.</code> ，就来瞅一眼到底是个什么。</p>\n<h2 id=\"定义\"><a class=\"markdownIt-Anchor\" href=\"#定义\">#</a> 定义</h2>\n\\tau$$（Tau）定义为：\n\n<p N-1=\"\">\\tau =  \\frac<ruby>\\sum_{n=1}<rp>【</rp><rt>\\N{(1-x_i)</rt><rp>】</rp></ruby>}</p>\n其中，N为组织数量，基因x~i~为归一化后的表达谱。\n\nTAU Index 计算，对于每一个基因基于他在不同组织的表达量，计算出一个0~1的数字。如果是1，那么这个基因就是在某个组织里面特异性表达。如果是接近1，比如0.9，那么就是组织偏好性表达。如果是接近0，那么就是倾向于组成型表达。\n\n## 应用\n\n`Evolution of tissue-specific expression of ancestral genes across vertebrates and insects`\n\n计算$$\\tau$$使用log~2~(TPMs+1)对表达矩阵进行normalized，定义**Tau > 0.75**与**maximum expressuib >= log~2~(5)**（由Tau分布定义）。\n\n为了将基因分配给每个tissue，有\n\n<p N=\"\">expression<sub>proportion</sub>per~tissue = \\frac<ruby>tissue~expr}{all~tissue~expr}\\\\\ntissue~expr = \\frac{\\sum_{r=1}<rp>【</rp><rt>\\R{log_2(TMPs + 1)</rt><rp>】</rp></ruby>}<ruby>R}\\\\\nall~tissue~expr = \\frac{\\sum_{n=1}<rp>【</rp><rt>\\N{tissue~expr)</rt><rp>】</rp></ruby>}</p>\n\n> where ‘tissue_expr’ is the average normalized log2(TPMs + 1) expression of the gene in the target tissue and ‘all_tissue_expr’ is the sum of the average normalized log2(TPMs + 1) expression values across all tissues.\n\n几个标准：\n\n> Specifically, we applied the following steps for each gene in each species (Extended Data Fig. 2c): (1) if the difference in expression proportion between the two most highly expressed tissues was ≥0.10 and their ratio ≥1.7, we associated the gene only with the top tissue. (2) If the above conditions were not fulfilled, but the difference in expression proportion between the second and third most highly expressed tissues was ≥0.15, we associated the gene with the two top tissues (double tissue specificity). (3) Otherwise, the gene was not considered as tissue specific and not associated with any tissue. \n\n## 脚本\n\n随手写一个python的脚本吧，还是比较抽象的，可以直接用TBtools\n\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> pandas <span class=\"keyword\">as</span> pd</span><br><span class=\"line\"><span class=\"keyword\">import</span> sys</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">tau_calu</span>(<span class=\"params\">x</span>):</span><br><span class=\"line\">    max_nor = &#123;i: x[i] / <span class=\"built_in\">max</span>(x) <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> tissue&#125; <span class=\"comment\"># normalized by the maximal component value</span></span><br><span class=\"line\">    <span class=\"comment\">#print(max_nor)</span></span><br><span class=\"line\">    tau = <span class=\"number\">0</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> k <span class=\"keyword\">in</span> max_nor.keys():</span><br><span class=\"line\">        tau += (<span class=\"number\">1</span> - max_nor[k])</span><br><span class=\"line\">    tau = tau / <span class=\"number\">4</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> tau</span><br><span class=\"line\"></span><br><span class=\"line\">exp_profile = sys.argv[<span class=\"number\">1</span>] <span class=\"comment\"># expression profile component </span></span><br><span class=\"line\"><span class=\"comment\"># 多个重复可求平均</span></span><br><span class=\"line\"></span><br><span class=\"line\">exp_df = pd.read_csv(exp_profile, header=<span class=\"number\">0</span>, index_col=<span class=\"literal\">None</span>, sep=<span class=\"string\">&quot;\\t&quot;</span>)</span><br><span class=\"line\">n = exp_df.shape[<span class=\"number\">1</span>]</span><br><span class=\"line\">tissue = exp_df.columns</span><br><span class=\"line\">exp_df[<span class=\"string\">&quot;tau&quot;</span>] = exp_df.apply(<span class=\"keyword\">lambda</span> x: tau_calu(x), axis = <span class=\"number\">1</span>)</span><br></pre></td></tr></table></figure>\n\n## 参考\n\nhttps://www.jianshu.com/p/8de865a420ad 参考CJ\n",
            "tags": [
                "Bioinformatics",
                "Algorithm",
                "Bioinformatics",
                "Algorithm"
            ]
        },
        {
            "id": "http://example.com/2024/12/24/sPLS-DA/",
            "url": "http://example.com/2024/12/24/sPLS-DA/",
            "title": "sPLS-DA",
            "date_published": "2024-12-24T08:35:42.000Z",
            "content_html": "<h1 id=\"稀疏偏最小二乘判别分析spls-da\"><a class=\"markdownIt-Anchor\" href=\"#稀疏偏最小二乘判别分析spls-da\">#</a> 稀疏偏最小二乘判别分析（sPLS-DA）</h1>\n<p>阅读文章 Evolution of tissue-specific expression of ancestral genes across vertebrates and insects 看到这么一个分析，用来找到组织特异性的表达模块，立马就想学习一下（<s>CSDN 开抄</s>）</p>\n<h2 id=\"pls-da\"><a class=\"markdownIt-Anchor\" href=\"#pls-da\">#</a> PLS-DA</h2>\n<p>PLS-DA (Partial Least Squares Discriminant Analysis)，即偏最小二乘法判别分析，是多变量数据分析技术中的判别分析法，经常用来处理<strong>分类和判别</strong>问题。通过对主成分适当的<strong>旋转</strong>，PLS-DA 可以有效的对组间观察值进行区分，并且能够找到导致组间区别的影响变量。</p>\n<p>PLS-DA 采用了经典的偏最小二乘回归模型，其响应变量是一组反应统计单元间类别关系的分类信息，是一种有监督的判别分析方法。</p>\n<blockquote>\n<p><strong>偏最小二乘回归模型</strong></p>\n<p>在实际问题中，经常遇到需要研究两组多重相关变量间的相互依赖关系，并研究用一组变量（常称为自变量或预测变量）去预测另一组变量（常称为因变量或响应变量），除了最小二乘准则下的经典多元线性回归分析（MLR），提取自变量组主成分的主成分回归分析（PCR）等方法外，还有近年发展起来的偏最小二乘（PLS）回归方法。</p>\n<p>偏最小二乘回归提供一种<strong>多对多线性回归建模</strong>的方法，特别当<strong>两组变量的个数很多，且都存在多重相关性，而观测数据的数量（样本量）又较少</strong>时，用偏最小二乘回归建立的模型具有传统的经典回归分析等方法所没有的优点。</p>\n<p>基本过程为：对自变量进行主成分分解，从第一个自变量开始与因变量进行回归，直到满意为止（无所不在的拉格朗日）</p>\n</blockquote>\n<blockquote>\n<p><strong>why PLS-DA</strong></p>\n<p>因无监督的分析方法（PCA）对所有样本不加以区分，即每个样本对模型有着同样的贡献，因此，当<strong>样本的组间差异较大，而组内差异较小时，无监督分析方法可以明显区分组间差异</strong>；而当<strong>样本的组间差异不明晰，而组内差异较大时，无监督分析方法难以发现和区分组间差异</strong>。另外，如果<strong>组间的差异较小，各组的样本量相差较大，样本量大的那组将会主导模型（组间样本量不均衡）</strong>。有监督的分析（PLS-DA）能够很好的解决无监督分析中遇到的这些问题。</p>\n</blockquote>\n<p>与 PCA 分析的原理相同，PLS 利用<strong>偏最小二乘法</strong>对数据结构进行投影分析。但 PLS 与 PCA 数据有本质的不同，PCA 分析方法中只有<strong>一个数据集 X</strong>，所有分析都只是基于这个的数据集，对应于一个多维空间。而 PLS 分析是建立在 ** 两个数据集 X 和 Y（自变量与因变量？）** 基础上的，因此也就对应地存在两个多维空间，在利用投影方法计算 PLS 个主成分后，分别得到 X 和 Y 空间的两条轴线以及各个样本点在 X 和 Y 空间周上的得分 t1、u1。</p>\n<p>对 X 和 Y 数据的关联分析就是将所有样本在 X 和 Y 空间个主成分轴上的得分 t1、u1 分别作相关分析，可以表示为 ui1 = ti1+ri1，i 表示不同样本，ri1 表示残差。对应的，经过第二个主成分计算可以得到 t2、u2, 有关系式 ui2 = ti2+ri2 。</p>\n<blockquote>\n<p>如果用 t1 、t2 作图，表示数据集 X 的 PCA 得分图，而如果用 t1、u1 作图就表示个主成分下数据集 X 与数据集 Y 相关性。</p>\n</blockquote>\n<p>PLS-DA 只需要一个数据集 X，但在分析时必须对样本进行<strong>指定分组（分组作为因变量）</strong>，这样分组后模型自动加上另外一个隐含的数据集 Y，该数据集变量数等于组别数，赋值时把指定的那一组规定为 1，其他所有值均为 0。其他计算方法与上述 PLS 方法相同。这种模型计算的方法强行把各组分门别类，有利于发现组间的异同点。</p>\n<h2 id=\"spls-da\"><a class=\"markdownIt-Anchor\" href=\"#spls-da\">#</a> sPLS-DA</h2>\n<p>sPLS-DA（Sparse PLS discriminant analysis）是 PLS-DA 的一种特殊情况，同时包含<strong>变量选择和分类</strong>的过程。sPLS-DA 允许变量选择，可以选择数据中最具预测性或判别性的特征，并帮助对样本进行分类。</p>\n<blockquote>\n<p>PLS-DA 模型建立在 X 中的所有基因上，其中许多可能无法提供信息来表征不同的类别。</p>\n<p>sPLS-DA 分析的目的是识别出最能区分这两类的一小部分基因。</p>\n</blockquote>\n<blockquote>\n<p>可用 mixOmics 包实现 http://mixomics.org/methods/spls-da/</p>\n<p>在样本不均衡的情况下，可使用 sPLS-DA 代替 PCA，</p>\n<p>SNP 分析也可以 https://bmcbioinformatics.biomedcentral.com/articles/10.1186/1471-2105-12-253</p>\n</blockquote>\n<h2 id=\"参考\"><a class=\"markdownIt-Anchor\" href=\"#参考\">#</a> 参考</h2>\n<p><span class=\"exturl\" data-url=\"aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2dlZWtmb2N1cy9hcnRpY2xlL2RldGFpbHMvMTE4NTIxMjg3\">PLS-DA-CSDN 博客</span></p>\n<p><span class=\"exturl\" data-url=\"aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzI5ODMxMTYzL2FydGljbGUvZGV0YWlscy84OTY0NzAzMw==\">偏最小二乘回归（一）：模型介绍_交叉有效性检验 - CSDN 博客</span></p>\n<p><span class=\"exturl\" data-url=\"aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTgyMjAwNy9hcnRpY2xlL2RldGFpbHMvMTE3MjY4Nzgz\">单组学的多变量分析 | 2. 稀疏偏最小二乘判别分析（sPLS-DA）-CSDN 博客</span></p>\n",
            "tags": [
                "Bioinformatics",
                "Evolution",
                "Bioinformatics",
                "Evolution"
            ]
        },
        {
            "id": "http://example.com/2024/12/24/PCMs/",
            "url": "http://example.com/2024/12/24/PCMs/",
            "title": "PCMs",
            "date_published": "2024-12-24T08:33:24.000Z",
            "content_html": "<h1 id=\"pcms-phylogenetic-comparative-methods\"><a class=\"markdownIt-Anchor\" href=\"#pcms-phylogenetic-comparative-methods\">#</a> PCMs (Phylogenetic comparative methods)</h1>\n<p>系统发育比较方法（PCM）旨在分析系统发育框架中物种性状的数据集。它们用于各种目的，包括检测选择，测量性状进化的速率，估计祖先性状，控制多物种数据的系统发育相互依赖性，估计协变量对特征的影响。</p>\n<h2 id=\"手写mcmc\"><a class=\"markdownIt-Anchor\" href=\"#手写mcmc\">#</a> 手写 MCMC</h2>\n<p>MCMC 用于 https://lukejharmon.github.io/pcm/chapter2_stats / 中的 2.4b 参数推断（为什么手写呢，我也觉得很奇怪）</p>\n<p><strong>Metropolis-Hastings 采样算法</strong></p>\n<ul>\n<li>初始化时间 t=1</li>\n<li>设置𝑢的值，并初始化初始状态 u𝜃(𝑡)=𝑢</li>\n<li>重复以下的过程\n<ul>\n<li>令 t=t+1</li>\n<li>从已知分布𝑞(𝜃∣𝜃<sup>(𝑡−1)</sup>) 中生成一个候选状态 θ<sup>(∗)</sup></li>\n<li>计算接受概率 $$\\alpha = min (1, \\frac<ruby>p<rt>)</rt>(<rt>)</rt>\\<rt>)</rt>t<rt>)</rt>h<rt>)</rt>e<rt>)</rt>t<rt>)</rt>a<rt>)</rt></ruby><ruby>(p\\theta<rp>【</rp><rt>{t-1</rt><rp>】</rp></ruby>))}\\frac<ruby>q(\\theta<rp>【</rp><rt>{t-1</rt><rp>】</rp></ruby>|\\theta^*)}<ruby>q<rt>|\\theta^{t-1</rt>(<rt>|\\theta^{t-1</rt>\\<rt>|\\theta^{t-1</rt>t<rt>|\\theta^{t-1</rt>h<rt>|\\theta^{t-1</rt>e<rt>|\\theta^{t-1</rt>t<rt>|\\theta^{t-1</rt>a<rt>|\\theta^{t-1</rt></ruby>)})$$</li>\n<li>从均匀分布 Uniform (0,1) 生成一个随机值 a</li>\n<li>如果 a⩽α𝑎⩽𝛼，接受新生成的值：θ(t)=θ(∗)𝜃(𝑡)=𝜃(∗)；否则：θ(t)=θ(t−1)</li>\n</ul>\n</li>\n<li>直到 t=T</li>\n</ul>\n<p>基于扔硬币的角度（使用 2.4b 参数推断的例子）</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#!/usr/bin/env /public/home/daijichen/anaconda3/envs/base-analysis/bin/python</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> random</span><br><span class=\"line\"><span class=\"keyword\">import</span> math</span><br><span class=\"line\"><span class=\"keyword\">from</span> scipy.stats <span class=\"keyword\">import</span> binom</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\">T = <span class=\"number\">10000</span> <span class=\"comment\"># MCMC times</span></span><br><span class=\"line\"><span class=\"comment\"># 初始化</span></span><br><span class=\"line\">i = <span class=\"number\">0</span></span><br><span class=\"line\">sigma = <span class=\"number\">0.01</span> <span class=\"comment\"># proposal distribution</span></span><br><span class=\"line\">p_list = [<span class=\"number\">0.0</span>] * (T + <span class=\"number\">1</span>) <span class=\"comment\"># 储存链</span></span><br><span class=\"line\">p0 = random.uniform(<span class=\"number\">0</span>, <span class=\"number\">1</span>) <span class=\"comment\"># 均一分布抽样</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">while</span> i &lt; T:</span><br><span class=\"line\">    i += <span class=\"number\">1</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> i == <span class=\"number\">0</span>:</span><br><span class=\"line\">        pi = p0</span><br><span class=\"line\">    pj = random.uniform(pi - sigma, pi + sigma) <span class=\"comment\"># 均已分布再次抽样</span></span><br><span class=\"line\">    prior_odds_ration = <span class=\"number\">1</span>/<span class=\"number\">1</span> <span class=\"comment\"># 均匀分布的性质，P曲线下面积为1</span></span><br><span class=\"line\">    proposal_density_ration = <span class=\"number\">1</span> <span class=\"comment\"># 提议分布的对称性</span></span><br><span class=\"line\">    likelihood_ration = binom.pmf(k=<span class=\"number\">63</span>, n=<span class=\"number\">100</span>, p=pi)/binom.pmf(k=<span class=\"number\">63</span>, n=<span class=\"number\">100</span>, p=pj) <span class=\"comment\"># 似然值</span></span><br><span class=\"line\">    accept = prior_odds_ration * proposal_density_ration * likelihood_ration</span><br><span class=\"line\"></span><br><span class=\"line\">    alpha = random.uniform(<span class=\"number\">0</span>, <span class=\"number\">1</span>) <span class=\"comment\"># 随机采样</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> accept &gt; alpha:</span><br><span class=\"line\">        <span class=\"keyword\">pass</span> <span class=\"comment\"># reject</span></span><br><span class=\"line\">    <span class=\"keyword\">else</span>:</span><br><span class=\"line\">        pi = pj</span><br><span class=\"line\">    p_list[i] = pi <span class=\"comment\"># chain</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"brownian-motion-bm\"><a class=\"markdownIt-Anchor\" href=\"#brownian-motion-bm\">#</a> Brownian motion (BM)</h2>\n<p>布朗运动是 “随机游走” 模型的一个例子，因为特征值在任何时间间隔内，在方向和距离上都是随机变化的。最开始用于描述粒子在空间中的随机运动。</p>\n<p>布朗运动作为一种模型占据主导地位的主要原因可能是它具有一些非常方便的统计特性，可以对树进行相对简单的分析和计算。</p>\n<p>令群体中性状（trait）的平均值为 $$z$$, 或为<strong>随时间 $$t$$ 变化的函数 $$z (t)$$</strong>。可以用布朗运动过程来模拟平均性状值随时间的变化。布朗运动可以描述为，总体平均<strong>特征起始值 $$z (0)$$</strong>，在任何性状变化发生之前，在祖先种群中看到的平均性状值。<strong>演化速率 $$\\sigma<sup>2$$**，决定了性状在时间中随机行走的速度。布朗运动符合正态分布，因此具有均值（Mean）0 与方差 $$variance=\\sigma</sup>2t$$，即</strong>性状值在任意时间间隔内的变化都是由均值为 0 的正态分布得出的，方差与进化速率和时间长度成正 ** 比。</p>\n<p>布朗运动的三个性质，</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mn>1.</mn><mi>E</mi><mo stretchy=\"false\">[</mo><mi>z</mi><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">]</mo><mo>=</mo><mi>z</mi><mo stretchy=\"false\">(</mo><mn>0</mn><mo stretchy=\"false\">)</mo><mspace linebreak=\"newline\"></mspace><mn>2.</mn><mtext>“行走”的每个连续间隔都是独立的</mtext><mspace linebreak=\"newline\"></mspace><mn>3.</mn><mi>z</mi><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo><mo>:</mo><mi>N</mi><mo stretchy=\"false\">(</mo><mi>z</mi><mo stretchy=\"false\">(</mo><mn>0</mn><mo stretchy=\"false\">)</mo><mo separator=\"true\">,</mo><msup><mi>σ</mi><mn>2</mn></msup><mi>t</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">1. E[z(t)] = z(0)\\\\\n2. “行走”的每个连续间隔都是独立的\\\\\n3. z(t):N(z(0), \\sigma^2t)\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\">1</span><span class=\"mord\">.</span><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">E</span><span class=\"mopen\">[</span><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">t</span><span class=\"mclose\">)</span><span class=\"mclose\">]</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"mopen\">(</span><span class=\"mord\">0</span><span class=\"mclose\">)</span></span><span class=\"mspace newline\"></span><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord\">2</span><span class=\"mord\">.</span><span class=\"mord\">“</span><span class=\"mord cjk_fallback\">行</span><span class=\"mord cjk_fallback\">走</span><span class=\"mord\">”</span><span class=\"mord cjk_fallback\">的</span><span class=\"mord cjk_fallback\">每</span><span class=\"mord cjk_fallback\">个</span><span class=\"mord cjk_fallback\">连</span><span class=\"mord cjk_fallback\">续</span><span class=\"mord cjk_fallback\">间</span><span class=\"mord cjk_fallback\">隔</span><span class=\"mord cjk_fallback\">都</span><span class=\"mord cjk_fallback\">是</span><span class=\"mord cjk_fallback\">独</span><span class=\"mord cjk_fallback\">立</span><span class=\"mord cjk_fallback\">的</span></span><span class=\"mspace newline\"></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\">3</span><span class=\"mord\">.</span><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">t</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">:</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.1141079999999999em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"mopen\">(</span><span class=\"mord\">0</span><span class=\"mclose\">)</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">σ</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8641079999999999em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span></span></span></span></span><span class=\"mord mathnormal\">t</span><span class=\"mclose\">)</span></span></span></span></span></p>\n<ol>\n<li>说明性状在任何时间 t 的期望值等于该性状在时间 0 的值。这里的期望值是指在 $$z (t)$$ 许多重复上的平均值，直观含义是布朗运动没有 “趋势”，在正负方向上都是相等的。</li>\n<li>布朗运动是一个连续时间的过程，所以时间没有离散的 “步骤”。</li>\n<li>\nz(t)$$是从均值$$z(0)$$和方差$$\\sigma^2$$t的正态分布中得出的，过程的总体方差是该速率乘以经过的时间。\n\n\n</li>\n</ol>\n<h4 id=\"遗传漂变下的布朗运动\"><a class=\"markdownIt-Anchor\" href=\"#遗传漂变下的布朗运动\">#</a> 遗传漂变下的布朗运动</h4>\n<p>当中性进化时，性状变化仅取决于遗传漂变。</p>\n<p>我们假设 **（1）一个性状受到许多基因的影响，每个基因的影响都很小，并且性状的值不影响适应度（明显与抗病不符）<strong>。</strong>（2）突变是随机的，对字符的影响很小 **。考虑性状平均值为 $$z$$，群体有效种群大小为 $$Ne$$，由于没有选择，表型性状只会由于突变和遗传漂变而改变。</p>\n<p>考虑最简单的 **“infinite alleles” model**，在这个模型下，突变是随机发生的，具有随机的表型效应。<strong>假设突变率符合均值为 0，方差为 $$\\sigma_m^2$$ 的正态分布随机而得，$$mutations:N (0, \\sigma_m^2)$$</strong>。模型<strong>假设等位基因的数量是如此之大，以至于同一等位基因实际上不可能发生多次突变</strong>。随着时间的推移，由于遗传漂变，种群中的等位基因的频率会发生变化。漂变和突变一起决定了平均性状随时间的动态变化。在此模型下，模拟多次后，多个种群之间具有相同的性状均值（性质一），表型不影响生存或生殖，且突变率被假设为随机与对称。</p>\n<p>紧接着考虑模型的表型方差，$$\\sigma_B<sup>2$$，在一段时间内，在许多独立的进化变化 “运行” 中，平均性状值的方差。由于模型的假设，我们可以仅仅聚焦于加性遗传方差在时间 t 的每个群体内，$$\\sigma_a</sup>2$$。加性遗传方差衡量加性作用的遗传变异的总量 (即每个等位基因的贡献加在一起来预测最终表型，每个等位位点仅一次的突变与遗传漂变)。排除了显性效应与上位性效应。由于遗传漂变 (倾向于降低 $$\\sigma_a<sup>2$$) 和突变 (倾向于增加 $$\\sigma_a</sup>2$$)，种群中的加性遗传方差会随着时间而变化。我们可以将 $$\\sigma_a^2$$ 从一代到下一代的期望值建模为：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>E</mi><mo stretchy=\"false\">[</mo><msubsup><mi>σ</mi><mi>a</mi><mn>2</mn></msubsup><mo stretchy=\"false\">(</mo><mi>t</mi><mo>+</mo><mn>1</mn><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">]</mo><mo>=</mo><mo stretchy=\"false\">(</mo><mn>1</mn><mo>−</mo><mfrac><mn>1</mn><mrow><mn>2</mn><msub><mi>N</mi><mi>e</mi></msub></mrow></mfrac><mo stretchy=\"false\">)</mo><mi>E</mi><mo stretchy=\"false\">[</mo><msubsup><mi>σ</mi><mi>a</mi><mn>2</mn></msubsup><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">]</mo><mo>+</mo><msubsup><mi>σ</mi><mi>m</mi><mn>2</mn></msubsup></mrow><annotation encoding=\"application/x-tex\">E[\\sigma_a^2(t+1)] = (1 - \\frac{1}{2N_e})E[\\sigma_a^2(t)]+\\sigma_m^2\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.1141079999999999em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">E</span><span class=\"mopen\">[</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">σ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8641079999999999em;\"><span style=\"top:-2.4530000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">a</span></span></span><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.247em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">t</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\">1</span><span class=\"mclose\">)</span><span class=\"mclose\">]</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.1574400000000002em;vertical-align:-0.8360000000000001em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.32144em;\"><span style=\"top:-2.3139999999999996em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">2</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">e</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8360000000000001em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mclose\">)</span><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">E</span><span class=\"mopen\">[</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">σ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8641079999999999em;\"><span style=\"top:-2.4530000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">a</span></span></span><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.247em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">t</span><span class=\"mclose\">)</span><span class=\"mclose\">]</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.1111079999999998em;vertical-align:-0.247em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">σ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8641079999999999em;\"><span style=\"top:-2.4530000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">m</span></span></span><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.247em;\"><span></span></span></span></span></span></span></span></span></span></span></p>\n<p>其中 t 为每代的时间间隔，$$N_e$$ 为有效种群大小，$$\\sigma_m^2$$ 为突变方差。$$(1 - \\frac {1}{2N_e}) E [\\sigma_a<sup>2 (t)]$$ 表示由于遗传漂变导致每一代 ** 加性遗传变异的减少 **，第二部分描述了由于每一代新的突变 ($$\\sigma_a</sup>2$$)，加性遗传方差是如何增加的。</p>\n<p>当假设 0 时间点的其实值为 $$\\sigma_{st}^2$$，则任意时间点的期望加性方差为：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>E</mi><mo stretchy=\"false\">[</mo><msubsup><mi>σ</mi><mi>a</mi><mn>2</mn></msubsup><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">]</mo><mo>=</mo><mo stretchy=\"false\">(</mo><mn>1</mn><mo>−</mo><mfrac><mn>1</mn><mrow><mn>2</mn><msub><mi>N</mi><mi>e</mi></msub></mrow></mfrac><msup><mo stretchy=\"false\">)</mo><mi>t</mi></msup><mo stretchy=\"false\">[</mo><msubsup><mi>σ</mi><mrow><mi>s</mi><mi>t</mi></mrow><mn>2</mn></msubsup><mo>−</mo><mn>2</mn><msub><mi>N</mi><mi>e</mi></msub><msubsup><mi>σ</mi><mi>m</mi><mn>2</mn></msubsup><mo stretchy=\"false\">]</mo><mo>+</mo><mn>2</mn><msub><mi>N</mi><mi>e</mi></msub><msubsup><mi>σ</mi><mi>m</mi><mn>2</mn></msubsup></mrow><annotation encoding=\"application/x-tex\">E[\\sigma_a^2(t)] = (1 - \\frac{1}{2N_e})^t[\\sigma_{st}^2-2N_e\\sigma_m^2]+2N_e\\sigma_m^2\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.1141079999999999em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">E</span><span class=\"mopen\">[</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">σ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8641079999999999em;\"><span style=\"top:-2.4530000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">a</span></span></span><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.247em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">t</span><span class=\"mclose\">)</span><span class=\"mclose\">]</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.1574400000000002em;vertical-align:-0.8360000000000001em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.32144em;\"><span style=\"top:-2.3139999999999996em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">2</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">e</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8360000000000001em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mclose\"><span class=\"mclose\">)</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.843556em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span></span></span></span></span><span class=\"mopen\">[</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">σ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8641079999999999em;\"><span style=\"top:-2.4530000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">s</span><span class=\"mord mathnormal mtight\">t</span></span></span></span><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.247em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.1141079999999999em;vertical-align:-0.25em;\"></span><span class=\"mord\">2</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">e</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">σ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8641079999999999em;\"><span style=\"top:-2.4530000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">m</span></span></span><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.247em;\"><span></span></span></span></span></span></span><span class=\"mclose\">]</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.1111079999999998em;vertical-align:-0.247em;\"></span><span class=\"mord\">2</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">e</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">σ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8641079999999999em;\"><span style=\"top:-2.4530000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">m</span></span></span><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.247em;\"><span></span></span></span></span></span></span></span></span></span></span></p>\n<p>t 非常大时 $$(1 - \\frac {1}{2N_e})^t$$ 趋近于 0，这意味着在进化的种群中，累加性遗传变异最终会在遗传漂变和新突变之间达到平衡，这样累加性遗传变异就会从一代到下一代开始停止变化，则有</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><munder><mo><mi>lim</mi><mo>⁡</mo></mo><mrow><mi>t</mi><mo>→</mo><mi mathvariant=\"normal\">∞</mi></mrow></munder><mi>E</mi><mo stretchy=\"false\">[</mo><msubsup><mi>σ</mi><mi>a</mi><mn>2</mn></msubsup><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">]</mo><mo>=</mo><mn>2</mn><msub><mi>N</mi><mi>e</mi></msub><msubsup><mi>σ</mi><mi>m</mi><mn>2</mn></msubsup></mrow><annotation encoding=\"application/x-tex\">\\lim\\limits_{t\\rightarrow\\infty}E[\\sigma_a^2(t)]=2N_e\\sigma_m^2\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.5641079999999998em;vertical-align:-0.7em;\"></span><span class=\"mop op-limits\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.69444em;\"><span style=\"top:-2.4em;margin-left:0em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">t</span><span class=\"mrel mtight\">→</span><span class=\"mord mtight\">∞</span></span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span><span class=\"mop\">lim</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7em;\"><span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">E</span><span class=\"mopen\">[</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">σ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8641079999999999em;\"><span style=\"top:-2.4530000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">a</span></span></span><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.247em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">t</span><span class=\"mclose\">)</span><span class=\"mclose\">]</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.1111079999999998em;vertical-align:-0.247em;\"></span><span class=\"mord\">2</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">e</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">σ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8641079999999999em;\"><span style=\"top:-2.4530000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">m</span></span></span><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.247em;\"><span></span></span></span></span></span></span></span></span></span></span></p>\n<p>因此，平衡遗传变异取决于种群大小和自发突变。</p>\n<p>我们现在可以推导出时间 t 的<strong>群体间</strong>表型方差，$$\\sigma_B<sup>2 (t)$$。假定加性方差 $$\\sigma_a</sup>2 (t)$$ 不变且处于稳定的状态。在独立进化的种群中，平均性状值会彼此偏离。在时间 t 后经过一段时间后，总体间方差的期望值为：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><msubsup><mi>σ</mi><mi>B</mi><mn>2</mn></msubsup><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mi>t</mi><mfrac><msubsup><mi>σ</mi><mi>a</mi><mn>2</mn></msubsup><msub><mi>N</mi><mi>e</mi></msub></mfrac></mrow><annotation encoding=\"application/x-tex\">\\sigma_B^2(t)=t\\frac{\\sigma_a^2}{N_e}\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.1141079999999999em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">σ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8641079999999999em;\"><span style=\"top:-2.4530000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.05017em;\">B</span></span></span><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.247em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">t</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.327108em;vertical-align:-0.8360000000000001em;\"></span><span class=\"mord mathnormal\">t</span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.491108em;\"><span style=\"top:-2.3139999999999996em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">e</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">σ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-2.4530000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">a</span></span></span><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.247em;\"><span></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8360000000000001em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span></span></p>\n<p>带入上式后有：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><msubsup><mi>σ</mi><mi>B</mi><mn>2</mn></msubsup><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mi>t</mi><mfrac><msubsup><mi>σ</mi><mi>a</mi><mn>2</mn></msubsup><msub><mi>N</mi><mi>e</mi></msub></mfrac><mo>=</mo><mi>t</mi><mfrac><mrow><mn>2</mn><msub><mi>N</mi><mi>e</mi></msub><msubsup><mi>σ</mi><mi>m</mi><mn>2</mn></msubsup></mrow><msub><mi>N</mi><mi>e</mi></msub></mfrac><mo>=</mo><mn>2</mn><mi>t</mi><msubsup><mi>σ</mi><mi>m</mi><mn>2</mn></msubsup></mrow><annotation encoding=\"application/x-tex\">\\sigma_B^2(t)=t\\frac{\\sigma_a^2}{N_e}=t\\frac{2N_e\\sigma_m^2}{N_e}=2t\\sigma_m^2\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.1141079999999999em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">σ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8641079999999999em;\"><span style=\"top:-2.4530000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.05017em;\">B</span></span></span><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.247em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">t</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.327108em;vertical-align:-0.8360000000000001em;\"></span><span class=\"mord mathnormal\">t</span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.491108em;\"><span style=\"top:-2.3139999999999996em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">e</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">σ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-2.4530000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">a</span></span></span><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.247em;\"><span></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8360000000000001em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.327108em;vertical-align:-0.8360000000000001em;\"></span><span class=\"mord mathnormal\">t</span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.491108em;\"><span style=\"top:-2.3139999999999996em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">e</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">2</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">e</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">σ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-2.4530000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">m</span></span></span><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.247em;\"><span></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8360000000000001em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.1111079999999998em;vertical-align:-0.247em;\"></span><span class=\"mord\">2</span><span class=\"mord mathnormal\">t</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">σ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8641079999999999em;\"><span style=\"top:-2.4530000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">m</span></span></span><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.247em;\"><span></span></span></span></span></span></span></span></span></span></span></p>\n<p>该方程表明，两个分化种群之间的变异取决于它们分化后的两倍时间和突变输入的速率。注意，对于这个模型，种群之间的变异量与种群的起始状态和有效种群大小无关。因此，这个模型预测，长期的进化速度是由种群中新突变的供应所决定的。</p>\n<p>尽管我们必须为这个推导做出特定的假设，Lynch 和 Hill (1986) 表明，方程 3.6 是一个普遍的结果，适用于一系列模型，甚至包括优势、连锁、非随机交配和其他过程。尽管方程 3.6 有些用处，但我们不能经常测量任何自然种群的突变方差 $$\\sigma_m^2$$(但见 Turelli 1984)。相比之下，我们有时确实知道<strong>某一特定性状的遗传力</strong>。遗传力描述了一个群体中由于加性遗传效应 $$\\sigma_a<sup>2 (t)$$ 引起的 ** 群体内 ** 总表型变异 $$\\sigma_b</sup>2$$ 的比例（这里指狭义遗传力）。</p>\n<p>带入则有：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><munder><mo><mi>lim</mi><mo>⁡</mo></mo><mrow><mi>t</mi><mo>→</mo><mi mathvariant=\"normal\">∞</mi></mrow></munder><mi>E</mi><mo stretchy=\"false\">[</mo><msubsup><mi>σ</mi><mi>a</mi><mn>2</mn></msubsup><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">]</mo><mo>=</mo><mn>2</mn><msub><mi>N</mi><mi>e</mi></msub><msubsup><mi>σ</mi><mi>m</mi><mn>2</mn></msubsup><mspace linebreak=\"newline\"></mspace><msup><mi>h</mi><mn>2</mn></msup><mo>=</mo><mfrac><mrow><msubsup><mi>σ</mi><mi>a</mi><mn>2</mn></msubsup><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow><msubsup><mi>σ</mi><mi>b</mi><mn>2</mn></msubsup></mfrac><mo>=</mo><mfrac><mrow><mn>2</mn><msub><mi>N</mi><mi>e</mi></msub><msubsup><mi>σ</mi><mi>m</mi><mn>2</mn></msubsup></mrow><msubsup><mi>σ</mi><mi>b</mi><mn>2</mn></msubsup></mfrac></mrow><annotation encoding=\"application/x-tex\">\\lim\\limits_{t\\rightarrow\\infty}E[\\sigma_a^2(t)]=2N_e\\sigma_m^2\\\\\nh^2=\\frac{\\sigma_a^2(t)}{\\sigma_b^2}=\\frac{2N_e\\sigma_m^2}{\\sigma_b^2}\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.5641079999999998em;vertical-align:-0.7em;\"></span><span class=\"mop op-limits\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.69444em;\"><span style=\"top:-2.4em;margin-left:0em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">t</span><span class=\"mrel mtight\">→</span><span class=\"mord mtight\">∞</span></span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span><span class=\"mop\">lim</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7em;\"><span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">E</span><span class=\"mopen\">[</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">σ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8641079999999999em;\"><span style=\"top:-2.4530000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">a</span></span></span><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.247em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">t</span><span class=\"mclose\">)</span><span class=\"mclose\">]</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.1111079999999998em;vertical-align:-0.247em;\"></span><span class=\"mord\">2</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">e</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">σ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8641079999999999em;\"><span style=\"top:-2.4530000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">m</span></span></span><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.247em;\"><span></span></span></span></span></span></span></span><span class=\"mspace newline\"></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8641079999999999em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">h</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8641079999999999em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.478416em;vertical-align:-0.9873080000000001em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.491108em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">σ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7959079999999998em;\"><span style=\"top:-2.398692em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">b</span></span></span><span style=\"top:-3.0448em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30130799999999996em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">σ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-2.4530000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">a</span></span></span><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.247em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">t</span><span class=\"mclose\">)</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9873080000000001em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.478416em;vertical-align:-0.9873080000000001em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.491108em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">σ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7959079999999998em;\"><span style=\"top:-2.398692em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">b</span></span></span><span style=\"top:-3.0448em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30130799999999996em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">2</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">e</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">σ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-2.4530000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">m</span></span></span><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.247em;\"><span></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9873080000000001em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span></span></p>\n<p>则有：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><msubsup><mi>σ</mi><mi>m</mi><mn>2</mn></msubsup><mo>=</mo><mfrac><mrow><msup><mi>h</mi><mn>2</mn></msup><msubsup><mi>σ</mi><mi>b</mi><mn>2</mn></msubsup></mrow><mrow><mn>2</mn><msub><mi>N</mi><mi>e</mi></msub></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">\\sigma_m^2=\\frac{h^2\\sigma_b^2}{2N_e}\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.1111079999999998em;vertical-align:-0.247em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">σ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8641079999999999em;\"><span style=\"top:-2.4530000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">m</span></span></span><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.247em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.327108em;vertical-align:-0.8360000000000001em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.491108em;\"><span style=\"top:-2.3139999999999996em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">2</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">e</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathnormal\">h</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">σ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-2.4168920000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">b</span></span></span><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2831079999999999em;\"><span></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8360000000000001em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span></span></p>\n<p>此处 h<sup>2</sup> 为遗传力，$$\\sigma_b^2$$<strong> 群体内</strong>总表型变异（包括种群内的所有变异来源，包括非加性遗传效应和环境效应）</p>\n<p>则有：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><msubsup><mi>σ</mi><mi>B</mi><mn>2</mn></msubsup><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mn>2</mn><mi>t</mi><msubsup><mi>σ</mi><mi>m</mi><mn>2</mn></msubsup><mo>=</mo><mfrac><mrow><mi>t</mi><mo>∗</mo><msup><mi>h</mi><mn>2</mn></msup><msubsup><mi>σ</mi><mi>b</mi><mn>2</mn></msubsup></mrow><msub><mi>N</mi><mi>e</mi></msub></mfrac></mrow><annotation encoding=\"application/x-tex\">\\sigma_B^2(t)=2t\\sigma_m^2=\\frac{t*h^2\\sigma_b^2}{N_e}\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.1141079999999999em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">σ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8641079999999999em;\"><span style=\"top:-2.4530000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.05017em;\">B</span></span></span><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.247em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">t</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.1111079999999998em;vertical-align:-0.247em;\"></span><span class=\"mord\">2</span><span class=\"mord mathnormal\">t</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">σ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8641079999999999em;\"><span style=\"top:-2.4530000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">m</span></span></span><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.247em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.327108em;vertical-align:-0.8360000000000001em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.491108em;\"><span style=\"top:-2.3139999999999996em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">e</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">t</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">∗</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">h</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">σ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-2.4168920000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">b</span></span></span><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2831079999999999em;\"><span></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8360000000000001em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span></span></p>\n<p>在经过时间 t 后，种群平均表型的期望值等于初始值（布朗运动的性质），方差与时间、遗传力和性状方差呈正相关，与有效种群大小呈负相关。</p>\n<p>为了得出这个结果，我们不得不对新突变的正常性做出特殊的假设，这似乎是不现实的。值得注意的是，如果表型受到足够多突变的影响，中心极限定理保证种群内表型的分布将是正态的 —— 无论这些突变的潜在分布是什么。我们还必须假设性状是中性的，这是一个更可疑的假设。</p>\n<h4 id=\"选择下的布朗运动\"><a class=\"markdownIt-Anchor\" href=\"#选择下的布朗运动\">#</a> 选择下的布朗运动</h4>\n<p>Hansen-Martins models 三个模型</p>\n<p>模型都要求选择的强度相对较弱，否则随着时间的推移，性状的遗传变异将被选择耗尽，性状进化的动态将发生变化。</p>\n<p><strong>模型一</strong>假设种群的进化是由于直接选择，但选择的强度和方向在一代到下一代之间随机变化。将每代选择的模型建模为均值为 0，方差为 $$\\sigma_s^2$$ 的正态分布。</p>\n<p>此时的布朗运动模型为，</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><msubsup><mi>σ</mi><mi>B</mi><mn>2</mn></msubsup><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mi>t</mi><mo stretchy=\"false\">(</mo><mfrac><mrow><msup><mi>h</mi><mn>2</mn></msup><msubsup><mi>σ</mi><mi>b</mi><mn>2</mn></msubsup></mrow><msub><mi>N</mi><mi>e</mi></msub></mfrac><mo>+</mo><msubsup><mi>σ</mi><mi>s</mi><mn>2</mn></msubsup><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">\\sigma_B^2(t)=t(\\frac{h^2\\sigma_b^2}{N_e} +\\sigma_s^2)\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.1141079999999999em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">σ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8641079999999999em;\"><span style=\"top:-2.4530000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.05017em;\">B</span></span></span><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.247em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">t</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.327108em;vertical-align:-0.8360000000000001em;\"></span><span class=\"mord mathnormal\">t</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.491108em;\"><span style=\"top:-2.3139999999999996em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">e</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathnormal\">h</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">σ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-2.4168920000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">b</span></span></span><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2831079999999999em;\"><span></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8360000000000001em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.1141079999999999em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">σ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8641079999999999em;\"><span style=\"top:-2.4530000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">s</span></span></span><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.247em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></span></p>\n<p>在特殊情况下，选择的变异比漂移的变异大得多:</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><msubsup><mi>σ</mi><mi>B</mi><mn>2</mn></msubsup><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo><mo>=</mo><msubsup><mi>σ</mi><mi>s</mi><mn>2</mn></msubsup></mrow><annotation encoding=\"application/x-tex\">\\sigma_B^2(t)=\\sigma_s^2\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.1141079999999999em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">σ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8641079999999999em;\"><span style=\"top:-2.4530000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.05017em;\">B</span></span></span><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.247em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">t</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.1111079999999998em;vertical-align:-0.247em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">σ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8641079999999999em;\"><span style=\"top:-2.4530000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">s</span></span></span><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.247em;\"><span></span></span></span></span></span></span></span></span></span></span></p>\n<p>也就是说，<strong>当选择 (平均而言) 比漂变强得多时，进化的速度完全由选择决定</strong>。这并不是那么牵强，因为许多研究表明，自然选择比漂移更强大，而且一代一代地在方向和幅度上都发生了变化。</p>\n<h2 id=\"参考\"><a class=\"markdownIt-Anchor\" href=\"#参考\">#</a> 参考</h2>\n<p><strong>Bayesian Analyses of Comparative Data with the Ornstein–Uhlenbeck Model: Potential Pitfalls</strong></p>\n<p><span class=\"exturl\" data-url=\"aHR0cHM6Ly9sdWtlamhhcm1vbi5naXRodWIuaW8v\">https://lukejharmon.github.io/</span></p>\n",
            "tags": [
                "Bioinformatics",
                "Evolution",
                "Bioinformatics",
                "Evolution"
            ]
        },
        {
            "id": "http://example.com/2024/12/24/DeepBSA-install/",
            "url": "http://example.com/2024/12/24/DeepBSA-install/",
            "title": "DeepBSA-install",
            "date_published": "2024-12-24T08:30:59.000Z",
            "content_html": "<h1 id=\"deepbsa流程\"><a class=\"markdownIt-Anchor\" href=\"#deepbsa流程\">#</a> DeepBSA 流程</h1>\n<p>记录一下我装 DeepBSA 的流程。</p>\n<p>首先想尝试使用 singularity 镜像，就还是使用了 miniconda3_base.sif 的镜像。</p>\n<p>使用 yaml 去装：</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">name:</span> <span class=\"string\">deepbsa</span></span><br><span class=\"line\"><span class=\"attr\">channels:</span></span><br><span class=\"line\"> <span class=\"bullet\">-</span> <span class=\"string\">https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge</span></span><br><span class=\"line\"> <span class=\"bullet\">-</span> <span class=\"string\">https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main</span></span><br><span class=\"line\"> <span class=\"bullet\">-</span> <span class=\"string\">https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/bioconda</span></span><br><span class=\"line\"> <span class=\"bullet\">-</span> <span class=\"string\">https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/r</span></span><br><span class=\"line\"> <span class=\"bullet\">-</span> <span class=\"string\">defaults</span></span><br><span class=\"line\"><span class=\"attr\">dependencies:</span></span><br><span class=\"line\"> <span class=\"bullet\">-</span> <span class=\"string\">python=3.10</span></span><br><span class=\"line\"> <span class=\"bullet\">-</span> <span class=\"string\">R=4.2.0</span></span><br><span class=\"line\"> <span class=\"bullet\">-</span> <span class=\"string\">pandas</span></span><br><span class=\"line\"> <span class=\"bullet\">-</span> <span class=\"string\">matplotlib</span></span><br><span class=\"line\"> <span class=\"bullet\">-</span> <span class=\"string\">statsmodels==0.13.2</span></span><br><span class=\"line\"> <span class=\"bullet\">-</span> <span class=\"string\">tensorflow==2.10.0</span></span><br><span class=\"line\"> <span class=\"bullet\">-</span> <span class=\"string\">tqdm</span></span><br></pre></td></tr></table></figure>\n<p>装上了，封装镜像，可以跑，就上传 HPC，但是！tensorflow 不能识别 GPU！！！</p>\n<p>尝试使用 singularity --nv 选项，在 HPC 的 GPU 节点试一试。</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">singularity shell --nv deepbsa.sif</span><br></pre></td></tr></table></figure>\n<p>还是不行！后来差点就直接用 CPU 跑了，这个速度实在感人。</p>\n<p>过了一晚上，炸裂的心态得到了回复。想着直接用 conda 装好了，正常配置环节，cudatoolkit，cudnn，tensorflow-gpu 一通安装。</p>\n<p>结果 tensorflow-gpu 不能识别 cuda。这时候就很懵逼了，毕竟刚用 conda 装的。直到我看到了这样一个帖子，<span class=\"exturl\" data-url=\"aHR0cHM6Ly9jb25kYS1mb3JnZS5vcmcvYmxvZy8yMDIxLzExLzAzL3RlbnNvcmZsb3ctZ3B1Lw==\">GPU enabled TensorFlow builds on conda-forge | conda-forge | community-driven packaging for conda</span></p>\n<blockquote>\n<p>When installing the  <code>tensorflow</code>  package, the package resolution will now default to the GPU-enabled builds of tensorflow if the local machine has a GPU (these builds can be identified by “cuda” at the beginning of the version number). Note that GPU-enabled packages can also work on CPU-only machines, but one would need to override the enviornment variable  <code>CONDA_OVERRIDE_CUDA</code>  like below. This could be handy if you are in a situation where your current node (e.g. login node) on an HPC does not have GPUs, but the compute nodes with GPUs do not have internet access.</p>\n</blockquote>\n<p>这… 就很神奇了，按照方法改了一下环境变量。</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">CONDA_OVERRIDE_CUDA=&quot;11.2&quot; mamba install -c https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge \\</span><br><span class=\"line\">-c https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main \\</span><br><span class=\"line\">-c https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/bioconda \\</span><br><span class=\"line\">-c https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/r tensorflower-gpu</span><br></pre></td></tr></table></figure>\n<p>然后就成了，后面再手动安装每个包。</p>\n<p>然后就可以用了。</p>\n<p>现在怀疑：</p>\n<ol>\n<li>singularity 没有按照这个流程装，所以镜像里面的 tf2 不能识别 GPU</li>\n</ol>\n<p>下次有空再试一试。</p>\n",
            "tags": [
                "Bioinformatics",
                "BSA",
                "Bioinformatics",
                "BSA"
            ]
        },
        {
            "id": "http://example.com/2024/12/24/GWAS/",
            "url": "http://example.com/2024/12/24/GWAS/",
            "title": "GWAS-1",
            "date_published": "2024-12-24T08:16:28.000Z",
            "content_html": "<h1 id=\"gwas\"><a class=\"markdownIt-Anchor\" href=\"#gwas\">#</a> GWAS</h1>\n<p>这两天开始折腾 GWAS，又翻了翻 GWAS 的原理，好多都不懂，记录一下自己的心路历程。</p>\n<p>这次参考了 Zhou (2022) 番茄图泛基因组的 GWAS 流程<span class=\"exturl\" data-url=\"aHR0cHM6Ly9naXRodWIuY29tL1lhb1pob3U4OS9UR0c=\"> YaoZhou89/TGG: tomato graph pangenome</span>，使用了 <code>MLM模型</code> 与 LOCO (Leava one choromosome out) 的方法。流程主要是 <code>LDAK计算亲缘关系矩阵</code>  + <code>gcta进行GWAS分析</code> ，一上来直接给我干懵了，这里记录一下我这两天折腾的过程，对这次的分析流程的部分原理进行介绍。</p>\n<h2 id=\"mlm\"><a class=\"markdownIt-Anchor\" href=\"#mlm\">#</a> MLM</h2>\n<p>Yu 等在玉米中使用 MLM 的模型，向 GWAS 模型中纳入了 <code>亲缘关系矩阵</code> 与 <code>群体结构矩阵</code> ，Yang 等在 gcta 中实现了这一方法。根据 Yang 等文章中的描述。</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>y</mi><mo>=</mo><mi>X</mi><mi>β</mi><mo>+</mo><mi>S</mi><mi>α</mi><mo>+</mo><mi>Q</mi><mi>v</mi><mo>+</mo><mi>Z</mi><mi>u</mi><mo>+</mo><mi>e</mi></mrow><annotation encoding=\"application/x-tex\">y=X\\beta+S\\alpha+Qv+Zu+e\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07847em;\">X</span><span class=\"mord mathnormal\" style=\"margin-right:0.05278em;\">β</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.76666em;vertical-align:-0.08333em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">S</span><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8777699999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\">Q</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">v</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.76666em;vertical-align:-0.08333em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">Z</span><span class=\"mord mathnormal\">u</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">e</span></span></span></span></span></p>\n<p>其中<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>y</mi></mrow><annotation encoding=\"application/x-tex\">y</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span></span></span></span> (n,1) 为表型向量；</p>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>X</mi><mi>β</mi></mrow><annotation encoding=\"application/x-tex\">X\\beta</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07847em;\">X</span><span class=\"mord mathnormal\" style=\"margin-right:0.05278em;\">β</span></span></span></span> 为除 SNP 与群体结构以外的固定效应，<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>β</mi></mrow><annotation encoding=\"application/x-tex\">\\beta</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05278em;\">β</span></span></span></span> (p,1) 为除了 SNP 或群体结构效应之外的其他固定效应的向量；</p>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>S</mi><mi>α</mi></mrow><annotation encoding=\"application/x-tex\">S\\alpha</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">S</span><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span></span></span></span> 为 SNP 固定效应，<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>α</mi></mrow><annotation encoding=\"application/x-tex\">\\alpha</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span></span></span></span> 是一个 SNP 固定效应的向量；</p>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>Q</mi><mi>v</mi></mrow><annotation encoding=\"application/x-tex\">Qv</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8777699999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\">Q</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">v</span></span></span></span> 为群体结构固定效应，<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>v</mi></mrow><annotation encoding=\"application/x-tex\">v</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">v</span></span></span></span> 为群体结构向量 (eg. PCA)；</p>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>Z</mi><mi>u</mi></mrow><annotation encoding=\"application/x-tex\">Zu</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">Z</span><span class=\"mord mathnormal\">u</span></span></span></span> 代表亲缘关系效应，<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>u</mi></mrow><annotation encoding=\"application/x-tex\">u</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">u</span></span></span></span> 为随机多基因背景效应的向量；<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>V</mi><mi>a</mi><mi>r</mi><mo stretchy=\"false\">(</mo><mi>u</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mn>2</mn><mi>K</mi><msub><mi>V</mi><mi>g</mi></msub></mrow><annotation encoding=\"application/x-tex\">Var(u)=2KV_g</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">V</span><span class=\"mord mathnormal\">a</span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">r</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">u</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.969438em;vertical-align:-0.286108em;\"></span><span class=\"mord\">2</span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">V</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15139200000000003em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\">g</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span></span></span></span>，K 为 (n,n) 的亲缘关系矩阵，定义个体之间遗传协方差；<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>V</mi><mi>g</mi></msub></mrow><annotation encoding=\"application/x-tex\">V_g</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.969438em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">V</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15139200000000003em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\">g</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span></span></span></span> 为遗传方差；</p>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>X</mi><mo separator=\"true\">,</mo><mi>S</mi><mo separator=\"true\">,</mo><mi>Q</mi><mo separator=\"true\">,</mo><mi>Z</mi></mrow><annotation encoding=\"application/x-tex\">X,S,Q,Z</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8777699999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07847em;\">X</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">S</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\">Q</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">Z</span></span></span></span> 分别为<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>β</mi><mo separator=\"true\">,</mo><mi>α</mi><mo separator=\"true\">,</mo><mi>v</mi><mo separator=\"true\">,</mo><mi>u</mi></mrow><annotation encoding=\"application/x-tex\">\\beta,\\alpha,v,u</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05278em;\">β</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">v</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\">u</span></span></span></span> 的关联矩阵；</p>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>e</mi></mrow><annotation encoding=\"application/x-tex\">e</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">e</span></span></span></span> 是一个残差效应的向量；<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>V</mi><mi>a</mi><mi>r</mi><mo stretchy=\"false\">(</mo><mi>e</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mi>R</mi><msub><mi>V</mi><mi>R</mi></msub></mrow><annotation encoding=\"application/x-tex\">Var(e)=RV_R</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">V</span><span class=\"mord mathnormal\">a</span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">r</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">e</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.00773em;\">R</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">V</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.32833099999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.00773em;\">R</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>，R (n,n) 非对角线元素为 0，对角线元素是获得每个表型数据点的观测数的倒数；<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>V</mi><mi>R</mi></msub></mrow><annotation encoding=\"application/x-tex\">V_R</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">V</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.32833099999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.00773em;\">R</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 为残差；</p>\n<h2 id=\"blue\"><a class=\"markdownIt-Anchor\" href=\"#blue\">#</a> BLUE</h2>\n<p>上述模型中，对<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>β</mi></mrow><annotation encoding=\"application/x-tex\">\\beta</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05278em;\">β</span></span></span></span> 的估计使用 BLUE 的方法，即利用 GLS (最小二乘法) 找到<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>β</mi></mrow><annotation encoding=\"application/x-tex\">\\beta</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05278em;\">β</span></span></span></span> 使得<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>V</mi><mi>a</mi><mi>r</mi><mo stretchy=\"false\">(</mo><mi>y</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">Var(y)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">V</span><span class=\"mord mathnormal\">a</span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">r</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"mclose\">)</span></span></span></span> 最小。</p>\n<p>详见 <code>Livro-Applications-of-Linear-Models-in-Animal-Breeding.</code>  第三章，拉格朗日算子求条件极值，<span class=\"exturl\" data-url=\"aHR0cHM6Ly9tYXRoLnN0YWNrZXhjaGFuZ2UuY29tL3F1ZXN0aW9ucy8xMTA0Mzc2L2hvdy10by1zZXQtdXAtbGFncmFuZ2lhbi1mb3ItbWF0cml4LWNvbnN0cmFpbnRz\">https://math.stackexchange.com/questions/1104376/how-to-set-up-lagrangian-for-matrix-constraints</span></p>\n<p>或者可使用 <code>EM算法</code> 迭代求得模型最优参数<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>β</mi></mrow><annotation encoding=\"application/x-tex\">\\beta</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05278em;\">β</span></span></span></span> (文中的<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>Y</mi><mo>=</mo><mi>X</mi><mi>β</mi><mo>+</mo><mi>Z</mi><mi>u</mi><mo>+</mo><mi>ϵ</mi></mrow><annotation encoding=\"application/x-tex\">Y = X\\beta + Zu + \\epsilon</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">Y</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07847em;\">X</span><span class=\"mord mathnormal\" style=\"margin-right:0.05278em;\">β</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.76666em;vertical-align:-0.08333em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">Z</span><span class=\"mord mathnormal\">u</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">ϵ</span></span></span></span> 的<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>X</mi><mi>β</mi></mrow><annotation encoding=\"application/x-tex\">X\\beta</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07847em;\">X</span><span class=\"mord mathnormal\" style=\"margin-right:0.05278em;\">β</span></span></span></span> 可展开为<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>X</mi><mi>β</mi><mo>+</mo><mi>S</mi><mi>α</mi><mo>+</mo><mi>Q</mi><mi>v</mi></mrow><annotation encoding=\"application/x-tex\">X\\beta+S\\alpha+Qv</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07847em;\">X</span><span class=\"mord mathnormal\" style=\"margin-right:0.05278em;\">β</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.76666em;vertical-align:-0.08333em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">S</span><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8777699999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\">Q</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">v</span></span></span></span>，可见 <code>Livro-Applications-of-Linear-Models-in-Animal-Breeding</code> , 第二章)</p>\n<h2 id=\"p\"><a class=\"markdownIt-Anchor\" href=\"#p\">#</a> P</h2>\n<p><span class=\"exturl\" data-url=\"aHR0cHM6Ly93d3cubXYuaGVsc2lua2kuZmkvaG9tZS9tanhwaXJpbi9HV0FTX2NvdXJzZS9tYXRlcmlhbC9HV0FTMi5odG1s\">https://www.mv.helsinki.fi/home/mjxpirin/GWAS_course/material/GWAS2.html</span></p>\n<p>有了估计模型，则可以对每个变异位点进行差异检验，上述文中使用 t 测对 SNP 的显著性进行检验。</p>\n<h2 id=\"qq-plot\"><a class=\"markdownIt-Anchor\" href=\"#qq-plot\">#</a> QQ plot</h2>\n<p>QQ plot 反应了期望 P 值与观测 P 值之间的关系，如下图所示（<span class=\"exturl\" data-url=\"aHR0cHM6Ly93d3cuZ2VuZWRlbm92by5jb20vbmV3cy8zOTEuaHRtbA==\">QQ plot 图 —— 评价你的统计模型是否合理 - 基迪奥生物</span>）</p>\n<p>图 a 中，Pvalue 观察值和期望值相同，说明分析模型是合理的。但所有的 P value 观测值都没有明显超过期望值，说明分析结果没有找到（与性状）显著关联的位点，可能原因包括：性状由微效多基因控制，效应太弱；群体大小不够等，这里先不展开详述。</p>\n<p>图 b 是我们最期望看到的结果类型。在散点图的左下角是显著性低的位点，即确定与性状不关联的位点，这些位点的 P value 观测值应该与期望值一致。而图中这些点的确位于对角线上，说明分析模型是合理的。而在图形的右上角则是显著性较高的位点，是潜在与性状相关的候选位点。这些点位于对角线的上方，即位点的 P value 观测值超过了期望值，说明这些位点的效应超过了随机效应，进而说明这些位点是与性状显著相关的。小结了一下：这个图形的左下角说明了模型的合理性，右上角则说明找了关联位点，所以这是最理想的结果。（备注：在有显著关联位点的情况下，结合曼哈顿图进行展示，会更加醒目）</p>\n<p>图 c 是大部分点位于对角线的下方，则说明大部分位点的 P value 观察值小于期望值。主要原因包括两种情况：（1）模型不合理，P value 被过度校正，导致 P value 显著性过低；（2）群体中大量 SNP 位点间存在连锁不平衡，有效位点数（相互间不存在连锁不平衡的位点）明显低于实际位点数，所以 P value 的期望值被低估了（即期望值的 - log10（P value）被高估了），也会出现这种情况。（3）模型中过度拟合，没有亲缘关系的群体在拟合过程中添加了亲缘关系矩阵。（4）个体过少。</p>\n<p>图 d，则相反：大部分点位于对角线的上方，则说明大部分位点的 P value 观察值超过期望值。按照统计学的逻辑推导，就是大部分位点与某个性状显著相关。这显然是不符合生物学逻辑的，那么这只有一种可能：分析模型不合理，数据的假阳性过大，P value 观测值的显著性被高估了。</p>\n<h2 id=\"reference\"><a class=\"markdownIt-Anchor\" href=\"#reference\">#</a> Reference</h2>\n<p><span class=\"exturl\" data-url=\"aHR0cHM6Ly93d3cubmF0dXJlLmNvbS9hcnRpY2xlcy9uZzE3MDIjTU9FU00x\">A unified mixed-model method for association mapping that accounts for multiple levels of relatedness | Nature Genetics</span></p>\n<p><span class=\"exturl\" data-url=\"aHR0cHM6Ly93d3cubmF0dXJlLmNvbS9hcnRpY2xlcy9uZy4yODc2\">Advantages and pitfalls in the application of mixed-model association methods | Nature Genetics</span></p>\n<p><span class=\"exturl\" data-url=\"aHR0cHM6Ly93d3cubmF0dXJlLmNvbS9hcnRpY2xlcy9uZy41NDYjU2VjNg==\">https://www.nature.com/articles/ng.546#Sec6</span></p>\n",
            "tags": [
                "Bioinformatics",
                "GWAS",
                "Bioinformatics",
                "GWAS"
            ]
        },
        {
            "id": "http://example.com/2024/12/24/VAE/",
            "url": "http://example.com/2024/12/24/VAE/",
            "title": "VAE",
            "date_published": "2024-12-24T02:39:33.000Z",
            "content_html": "<h1 id=\"vae\"><a class=\"markdownIt-Anchor\" href=\"#vae\">#</a> VAE</h1>\n<p>VAE（变分自编码器， Variational Autoencoders），生成式模型</p>\n<p>看明白 VAE 需要了解降维的概念，以 PCA 作为例子，并展示 VAE 与 PCA 之间的关系。</p>\n<h2 id=\"降维\"><a class=\"markdownIt-Anchor\" href=\"#降维\">#</a> 降维</h2>\n<h3 id=\"什么是降维\"><a class=\"markdownIt-Anchor\" href=\"#什么是降维\">#</a> <strong>什么是降维？</strong></h3>\n<blockquote>\n<p>在机器学习中，<strong>降维是减少描述数据的特征数量的过程</strong>。可以通过<strong>选择</strong>（仅保留一些现有特征）或通过<strong>提取</strong>（基于旧特征组合来生成数量更少的新特征）来进行降维。降维在许多需要低维数据的场景中很有用。尽管有许多不同的降维方法，但是我们可以构建一个适用于大多数方法的总体框架。</p>\n</blockquote>\n<p>首先，我们称<strong>编码器（Encoder）<strong>为从 “旧特征” 表示中产生 “新特征” 表示（通过选择或提取）的过程，然后将其逆过程称为</strong>解码（Decoder）</strong>。降维可以被理解为数据压缩，其中编码器压缩数据（从初始空间到<strong>编码空间</strong>，也称为<strong>隐空间</strong>，latent sapce），而解码器则用于解压缩。当然，根据初始数据分布、隐空间大小和编码器的选择，压缩可能是有损的，即<strong>一部分信息会在编码过程中丢失，并且在解码时无法恢复</strong>，产生的损失为<strong>重构误差</strong>。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">graph LR;</span><br><span class=\"line\">pro1(Initial data)</span><br><span class=\"line\">pro2&#123;Encoder&#125;</span><br><span class=\"line\">pro3(encoded data隐空间)</span><br><span class=\"line\">pro4&#123;Decoder&#125;</span><br><span class=\"line\">pro5(encoded-decoded data)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">pro1 --&gt; pro2</span><br><span class=\"line\">pro2 --&gt; pro3</span><br><span class=\"line\">pro3 --&gt; pro4</span><br><span class=\"line\">pro4 --&gt; pro5</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">classDef default fill: #EEE8AA, stroke: #333, stroke-width: 4px;</span><br><span class=\"line\">classDef en-decoder fill:#FF6347,  stroke: #333, stroke-width: 4px;</span><br><span class=\"line\"></span><br><span class=\"line\">class pro2 en-decoder</span><br><span class=\"line\">class pro4 en-decoder</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<p>优化目标：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mo stretchy=\"false\">(</mo><mi>e</mi><mo separator=\"true\">,</mo><mi>d</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mi>a</mi><mi>r</mi><mi>g</mi><mi>m</mi><mi>i</mi><mi>n</mi><mo stretchy=\"false\">(</mo><mi>ϵ</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo separator=\"true\">,</mo><mi>d</mi><mo stretchy=\"false\">(</mo><mi>e</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">(e, d)=argmin(\\epsilon(x, d(e(x))))\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">e</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\">d</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\">a</span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">r</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">g</span><span class=\"mord mathnormal\">m</span><span class=\"mord mathnormal\">i</span><span class=\"mord mathnormal\">n</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">ϵ</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\">d</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">e</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span><span class=\"mclose\">)</span><span class=\"mclose\">)</span><span class=\"mclose\">)</span></span></span></span></span></p>\n<p>其中 x 为输入数据，d (e (x)) 为降维数据，(e, d) 为重构误差</p>\n<h2 id=\"pca\"><a class=\"markdownIt-Anchor\" href=\"#pca\">#</a> <strong>PCA</strong></h2>\n<p>PCA 是构建 n<sub>e</sub> 个新的<strong>独立</strong>特征，这些特征是 n<sub>d</sub> 个<strong>旧特征的线性组合</strong>，并使得这些新特征所定义的子空间上的数据投影尽可能接近初始数据（就欧几里得距离而言）。换句话说，PCA 寻找初始空间的最佳线性子空间（由新特征的正交基定义），以使投影到该子空间上的近似数据的误差尽可能小。</p>\n<p>SVD 求解（略）</p>\n<h2 id=\"自编码器\"><a class=\"markdownIt-Anchor\" href=\"#自编码器\">#</a> <strong>自编码器</strong></h2>\n<p><strong>自编码器</strong>总体思路非常简单，主要包括用<strong>神经网络来作为编码器和解码器</strong>，并使用迭代优化学习最佳的<strong>编码 - 解码方案</strong>。因此，在每次迭代中，我们向自编码器结构（编码器后跟解码器）提供一些数据，我们将编码再解码后的输出与初始数据进行比较，并通过<strong>反向传播误差</strong>来更新网络的权重。</p>\n<p>因此，直观地讲，整个自编码器结构（编码器 + 解码器）会构造出<strong>数据瓶颈（bottleneck）</strong>，从而确保只有信息的主要部分可以通过瓶颈并进行重构。</p>\n<p>从我们的总体框架来看，考虑的<strong>编码器 E</strong> 由编码器网络结构定义，<strong>解码器族 D</strong> 由解码器网络结构定义，而<strong>重构误差</strong>的减小则通过对编码器和解码器参数进行梯度下降来进行。</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>l</mi><mi>o</mi><mi>s</mi><mi>s</mi><mo>=</mo><mi mathvariant=\"normal\">∣</mi><mi mathvariant=\"normal\">∣</mi><mi>x</mi><mo>−</mo><mi>d</mi><mo stretchy=\"false\">(</mo><mi>e</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">)</mo><mi mathvariant=\"normal\">∣</mi><msup><mi mathvariant=\"normal\">∣</mi><mn>2</mn></msup></mrow><annotation encoding=\"application/x-tex\">loss = ||x-d(e(x))||^2\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.01968em;\">l</span><span class=\"mord mathnormal\">o</span><span class=\"mord mathnormal\">s</span><span class=\"mord mathnormal\">s</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\">∣</span><span class=\"mord\">∣</span><span class=\"mord mathnormal\">x</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.1141079999999999em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\">d</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">e</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span><span class=\"mclose\">)</span><span class=\"mord\">∣</span><span class=\"mord\"><span class=\"mord\">∣</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8641079999999999em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span></span></span></span></span></span></span></span></span></p>\n<p>让我们<strong>首先假设编码器和解码器网络结构都只有一层且没有非线性</strong>（即考虑的是线性自编码器）。</p>\n<p>这样的编码器和解码器是简单的线性变换，可以用矩阵表示。</p>\n<p>在这种情况下，某种意义上，我们可以看到与 PCA 的明显的关联，就像 PCA 中一样，我们正在寻找<strong>最佳的线性子空间</strong>来投影数据，并且使信息损失尽可能少。</p>\n<p>用 PCA 获得的编码和解码矩阵自然地也是梯度下降所能得到的一种解决方案，但是我们应该指出，这不是唯一的解决方案。实际上，<strong>可以选择几组不同的基向量来描述相同的最佳子空间</strong>，因此，几个不同的编码器 / 解码器对都可以提供最小的重构误差。此外，与 PCA 不同，对于线性自编码器，我们最终获得的新特征不必是独立的（<strong>神经网络中没有正交性约束，VAE 得出的基也不必是正交的</strong>）</p>\n<p>现在，让我们进一步假设编码器和解码器都是<strong>深度非线性网络</strong>的。在这种情况下，网络结构越复杂，自编码器就可以进行更多的降维，同时保持较低的重构损失。</p>\n<p>但是我们应该牢记两点。首先，在没有重建损失的情况下进行重要的降维通常会带来一个代价：隐空间中缺乏可解释和可利用的结构（<strong>缺乏规则性，lack of regularity</strong>）。其次，大多数时候，降维的最终目的不仅是减少数据的维数，而是要在减少维数的同时将数据主要的结构信息保留在简化的表示中。出于这两个原因，必须根据降维的最终目的来仔细控制和调整隐空间的大小和自编码器的 “深度”（深度定义压缩的程度和质量）。</p>\n<h2 id=\"变分自编码器vae\"><a class=\"markdownIt-Anchor\" href=\"#变分自编码器vae\">#</a> 变分自编码器（VAE）</h2>\n<p><strong>自编码器用于内容生成的局限性</strong></p>\n<p>此时，自然会想到一个问题：“自编码器和内容生成之间的联系是什么？”。确实，一旦对自编码器进行了训练，我们既有编码器又有解码器，但是仍然没有办法来产生任何新内容。乍一看，我们可能会认为，如果隐空间足够规则（在训练过程中被编码器很好地 “组织” 了），我们可以从该隐空间中随机取一个点并将其解码以获得新的内容，就像生成对抗网络中的生成器一样。但是！自编码器的隐空间的规则性是一个难点，它取决于初始空间中数据的分布、隐空间的大小和编码器的结构。因此，很难先验地确保编码器以与我们刚刚描述的生成过程兼容的方式智能地组织隐空间。</p>\n<p><strong>自编码器仅以尽可能少的损失为目标进行训练，而不管隐空间如何组织</strong>。因此，如果我们对架构的定义不小心，那么在训练过程中，网络很自然地会利用任何过拟合的可能性来尽可能地完成其任务…… 除非我们明确对其进行规范化！</p>\n<blockquote>\n<p>潜在空间值形成不规则的、无界的分布，会使随机点采样变得困难。</p>\n<p>不同图像类别的潜在表示可能在大小上有所不同，导致模型生成某些类别的频率比其他类别高得多。</p>\n<p>传统的自编码器学习的潜在空间不是连续的。</p>\n<p>使用传统自编码器作为生成模型存在三个问题：不知道如何从一个不规则的、无界的空间中采样，一些类可能在潜空间中被过度表示，学习空间是不连续的，这使得很难找到一个点将解码成一个良好的图像。所以这时候变分自编码器出现了。</p>\n</blockquote>\n<p><strong>变分自编码器的定义</strong></p>\n<p>隐空间足够规则。获得这种规律性的一种可能方案是在训练过程中引入显式的<strong>正规化（regularisation）</strong>。</p>\n<p>因此，变分自编码器可以定义为一种自编码器，其训练经过<strong>正规化以避免过度拟合</strong>，并确保隐空间具有能够进行数据生成过程的良好属性。</p>\n<p><strong>不是将输入编码为隐空间中的单个点，而是将其编码为隐空间中的概率分布（连续性与规则性）</strong></p>\n<blockquote>\n<ul>\n<li>首先，将输入编码为在隐空间上的分布；</li>\n<li>第二，从该分布中采样隐空间中的一个点；</li>\n<li>第三，对采样点进行解码并计算出重建误差；</li>\n<li>最后，重建误差通过网络反向传播。</li>\n</ul>\n</blockquote>\n<p><strong>变分自编码器把原始数据编码为隐空间中的分布，在解码时是从该分布中采样一个点来进行解码</strong></p>\n<p>实践中，选择正态分布作为编码的分布，使得我们可以训练编码器来返回描述高斯分布的均值和协方差矩阵。将输入编码为具有一定方差而不是单个点的分布的原因是这样可以非常自然地表达隐空间规则化：<strong>编码器返回的分布被强制接近标准正态分布</strong>。</p>\n<p>此时的 Loss 为</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>l</mi><mi>o</mi><mi>s</mi><mi>s</mi><mo>=</mo><mi mathvariant=\"normal\">∣</mi><mi mathvariant=\"normal\">∣</mi><mi>x</mi><mo>−</mo><mi>d</mi><mo stretchy=\"false\">(</mo><mi>e</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">)</mo><mi mathvariant=\"normal\">∣</mi><msup><mi mathvariant=\"normal\">∣</mi><mn>2</mn></msup><mo>+</mo><mi>K</mi><mi>L</mi><mo stretchy=\"false\">(</mo><mi>N</mi><mo stretchy=\"false\">(</mo><mi>μ</mi><mo separator=\"true\">,</mo><mi>σ</mi><mo stretchy=\"false\">)</mo><mo separator=\"true\">,</mo><mi>N</mi><mo stretchy=\"false\">(</mo><mn>0</mn><mo separator=\"true\">,</mo><mn>1</mn><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">loss = ||x-d(e(x))||^2 + KL(N(\\mu, \\sigma), N(0,1))\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.01968em;\">l</span><span class=\"mord mathnormal\">o</span><span class=\"mord mathnormal\">s</span><span class=\"mord mathnormal\">s</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\">∣</span><span class=\"mord\">∣</span><span class=\"mord mathnormal\">x</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.1141079999999999em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\">d</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">e</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span><span class=\"mclose\">)</span><span class=\"mord\">∣</span><span class=\"mord\"><span class=\"mord\">∣</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8641079999999999em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span><span class=\"mord mathnormal\">L</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">μ</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">σ</span><span class=\"mclose\">)</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span><span class=\"mopen\">(</span><span class=\"mord\">0</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\">1</span><span class=\"mclose\">)</span><span class=\"mclose\">)</span></span></span></span></span></p>\n<p>KL 散度又称为相对熵，两个概率分布 P 和 Q 差别的非对称性的度量。 KL 散度是用来度量使用基于 Q 的分布来编码服从 P 的分布的样本所需的额外的平均比特数。典型情况下，P 表示数据的真实分布，Q 表示数据的理论分布、估计的模型分布、或 P 的近似分布，其定义为</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>K</mi><mi>L</mi><mo stretchy=\"false\">(</mo><mi>p</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo><mo separator=\"true\">,</mo><mi>q</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">)</mo><mo>=</mo><mo>∑</mo><mrow><mi>p</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo><mi>l</mi><mi>o</mi><mi>g</mi><mfrac><mrow><mi>p</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow><mrow><mi>q</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow></mfrac></mrow></mrow><annotation encoding=\"application/x-tex\">KL(p(x), q(x)) = \\sum{p(x)log\\frac{p(x)}{q(x)}}\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span><span class=\"mord mathnormal\">L</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">p</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">q</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.363em;vertical-align:-0.936em;\"></span><span class=\"mop op-symbol large-op\" style=\"position:relative;top:-0.000004999999999977245em;\">∑</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">p</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span><span class=\"mord mathnormal\" style=\"margin-right:0.01968em;\">l</span><span class=\"mord mathnormal\">o</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">g</span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.427em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">q</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">p</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.936em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span></span></span></p>\n<p><strong>关于正则化的直观解释</strong></p>\n<p>我们期望隐空间具有规则性，这可以通过两个主要属性表示：<strong>连续性</strong>（continuity，隐空间中的两个相邻点解码后不应呈现两个完全不同的内容）和<strong>完整性</strong>（completeness，针对给定的分布，从隐空间采样的点在解码后应提供 “有意义” 的内容）。</p>\n<p>VAE 将输入编码为<strong>分布</strong>而不是点不足以确保连续性和完整性。如果没有明确定义的正则化项，则模型可以学习最小化其重构误差，从而 “忽略” 要返回一个分布，最终表现得几乎像普通自编码器一样（导致过度拟合）。具体地说，编码器可以返回具有微小方差的分布（往往是点分布，punctual distributions），或者返回具有巨大均值差异的分布（数据在隐空间中彼此相距很远）。在这两种情况下，返回分布的限制都没有取得效果，并且不满足连续性和 / 或完整性。</p>\n<h2 id=\"vae-数学细节\"><a class=\"markdownIt-Anchor\" href=\"#vae-数学细节\">#</a> VAE 数学细节</h2>\n<p>x 为数据变量，z 为潜变量，由 encoder 生成，则有</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mo stretchy=\"false\">(</mo><mn>1</mn><mo stretchy=\"false\">)</mo><mtext>从先验分布</mtext><mi>p</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo><mtext>采样隐空间</mtext><mi>z</mi><mtext>；</mtext><mo stretchy=\"false\">(</mo><mn>2</mn><mo stretchy=\"false\">)</mo><mtext>由条件概率</mtext><mi>p</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mi mathvariant=\"normal\">∣</mi><mi>z</mi><mo stretchy=\"false\">)</mo><mtext>采样</mtext><mi>x</mi></mrow><annotation encoding=\"application/x-tex\">(1) 从先验分布p(x)采样隐空间z；\n(2) 由条件概率p(x|z)采样x\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord\">1</span><span class=\"mclose\">)</span><span class=\"mord cjk_fallback\">从</span><span class=\"mord cjk_fallback\">先</span><span class=\"mord cjk_fallback\">验</span><span class=\"mord cjk_fallback\">分</span><span class=\"mord cjk_fallback\">布</span><span class=\"mord mathnormal\">p</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span><span class=\"mord cjk_fallback\">采</span><span class=\"mord cjk_fallback\">样</span><span class=\"mord cjk_fallback\">隐</span><span class=\"mord cjk_fallback\">空</span><span class=\"mord cjk_fallback\">间</span><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"mord cjk_fallback\">；</span><span class=\"mopen\">(</span><span class=\"mord\">2</span><span class=\"mclose\">)</span><span class=\"mord cjk_fallback\">由</span><span class=\"mord cjk_fallback\">条</span><span class=\"mord cjk_fallback\">件</span><span class=\"mord cjk_fallback\">概</span><span class=\"mord cjk_fallback\">率</span><span class=\"mord mathnormal\">p</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mord\">∣</span><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"mclose\">)</span><span class=\"mord cjk_fallback\">采</span><span class=\"mord cjk_fallback\">样</span><span class=\"mord mathnormal\">x</span></span></span></span></span></p>\n<p>在这种概率模型下，我们可以重新定义编码器和解码器的概念。实际上，与考虑使用确定性编码器和解码器的简单自编码器不同，我们现在将考虑这两个对象的概率版本。</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mtext>概率解码器</mtext><mo>:</mo><mi>p</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mi mathvariant=\"normal\">∣</mi><mi>z</mi><mo stretchy=\"false\">)</mo><mtext>描述由给定已经编码的变量到解码变量的分布</mtext><mo stretchy=\"false\">(</mo><mtext>由</mtext><mi>z</mi><mtext>到</mtext><mi>x</mi><mo stretchy=\"false\">)</mo><mtext>由潜变量空间到原始数据空间（解码）的映射</mtext></mrow><annotation encoding=\"application/x-tex\">概率解码器:p(x|z) 描述由给定已经编码的变量到解码变量的分布 (由z到x) 由潜变量空间到原始数据空间（解码）的映射\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord cjk_fallback\">概</span><span class=\"mord cjk_fallback\">率</span><span class=\"mord cjk_fallback\">解</span><span class=\"mord cjk_fallback\">码</span><span class=\"mord cjk_fallback\">器</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">:</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\">p</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mord\">∣</span><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"mclose\">)</span><span class=\"mord cjk_fallback\">描</span><span class=\"mord cjk_fallback\">述</span><span class=\"mord cjk_fallback\">由</span><span class=\"mord cjk_fallback\">给</span><span class=\"mord cjk_fallback\">定</span><span class=\"mord cjk_fallback\">已</span><span class=\"mord cjk_fallback\">经</span><span class=\"mord cjk_fallback\">编</span><span class=\"mord cjk_fallback\">码</span><span class=\"mord cjk_fallback\">的</span><span class=\"mord cjk_fallback\">变</span><span class=\"mord cjk_fallback\">量</span><span class=\"mord cjk_fallback\">到</span><span class=\"mord cjk_fallback\">解</span><span class=\"mord cjk_fallback\">码</span><span class=\"mord cjk_fallback\">变</span><span class=\"mord cjk_fallback\">量</span><span class=\"mord cjk_fallback\">的</span><span class=\"mord cjk_fallback\">分</span><span class=\"mord cjk_fallback\">布</span><span class=\"mopen\">(</span><span class=\"mord cjk_fallback\">由</span><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"mord cjk_fallback\">到</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span><span class=\"mord cjk_fallback\">由</span><span class=\"mord cjk_fallback\">潜</span><span class=\"mord cjk_fallback\">变</span><span class=\"mord cjk_fallback\">量</span><span class=\"mord cjk_fallback\">空</span><span class=\"mord cjk_fallback\">间</span><span class=\"mord cjk_fallback\">到</span><span class=\"mord cjk_fallback\">原</span><span class=\"mord cjk_fallback\">始</span><span class=\"mord cjk_fallback\">数</span><span class=\"mord cjk_fallback\">据</span><span class=\"mord cjk_fallback\">空</span><span class=\"mord cjk_fallback\">间</span><span class=\"mord cjk_fallback\">（</span><span class=\"mord cjk_fallback\">解</span><span class=\"mord cjk_fallback\">码</span><span class=\"mord cjk_fallback\">）</span><span class=\"mord cjk_fallback\">的</span><span class=\"mord cjk_fallback\">映</span><span class=\"mord cjk_fallback\">射</span></span></span></span></span></p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mtext>概率编码器</mtext><mo>:</mo><mi>p</mi><mo stretchy=\"false\">(</mo><mi>z</mi><mi mathvariant=\"normal\">∣</mi><mi>x</mi><mo stretchy=\"false\">)</mo><mtext>描述由给定数据变量（原始）到编码变量的分布</mtext><mo stretchy=\"false\">(</mo><mtext>由</mtext><mi>x</mi><mtext>到</mtext><mi>z</mi><mo stretchy=\"false\">)</mo><mtext>由原始数据空间到潜变量空间的映射</mtext></mrow><annotation encoding=\"application/x-tex\">概率编码器:p(z|x) 描述由给定数据变量（原始）到编码变量的分布 (由x到z) 由原始数据空间到潜变量空间的映射\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord cjk_fallback\">概</span><span class=\"mord cjk_fallback\">率</span><span class=\"mord cjk_fallback\">编</span><span class=\"mord cjk_fallback\">码</span><span class=\"mord cjk_fallback\">器</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">:</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\">p</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"mord\">∣</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span><span class=\"mord cjk_fallback\">描</span><span class=\"mord cjk_fallback\">述</span><span class=\"mord cjk_fallback\">由</span><span class=\"mord cjk_fallback\">给</span><span class=\"mord cjk_fallback\">定</span><span class=\"mord cjk_fallback\">数</span><span class=\"mord cjk_fallback\">据</span><span class=\"mord cjk_fallback\">变</span><span class=\"mord cjk_fallback\">量</span><span class=\"mord cjk_fallback\">（</span><span class=\"mord cjk_fallback\">原</span><span class=\"mord cjk_fallback\">始</span><span class=\"mord cjk_fallback\">）</span><span class=\"mord cjk_fallback\">到</span><span class=\"mord cjk_fallback\">编</span><span class=\"mord cjk_fallback\">码</span><span class=\"mord cjk_fallback\">变</span><span class=\"mord cjk_fallback\">量</span><span class=\"mord cjk_fallback\">的</span><span class=\"mord cjk_fallback\">分</span><span class=\"mord cjk_fallback\">布</span><span class=\"mopen\">(</span><span class=\"mord cjk_fallback\">由</span><span class=\"mord mathnormal\">x</span><span class=\"mord cjk_fallback\">到</span><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"mclose\">)</span><span class=\"mord cjk_fallback\">由</span><span class=\"mord cjk_fallback\">原</span><span class=\"mord cjk_fallback\">始</span><span class=\"mord cjk_fallback\">数</span><span class=\"mord cjk_fallback\">据</span><span class=\"mord cjk_fallback\">空</span><span class=\"mord cjk_fallback\">间</span><span class=\"mord cjk_fallback\">到</span><span class=\"mord cjk_fallback\">潜</span><span class=\"mord cjk_fallback\">变</span><span class=\"mord cjk_fallback\">量</span><span class=\"mord cjk_fallback\">空</span><span class=\"mord cjk_fallback\">间</span><span class=\"mord cjk_fallback\">的</span><span class=\"mord cjk_fallback\">映</span><span class=\"mord cjk_fallback\">射</span></span></span></span></span></p>\n<p>在简单的自编码器中所缺乏的对隐空间的正则化自然出现在数据生成过程的定义中（贝叶斯）：我们假设隐空间中的编码表示 z，遵循先验分布 p (z)。由<strong>贝叶斯推理问题</strong>：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>p</mi><mo stretchy=\"false\">(</mo><mi>z</mi><mi mathvariant=\"normal\">∣</mi><mi>x</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mfrac><mrow><mi>p</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mi mathvariant=\"normal\">∣</mi><mi>z</mi><mo stretchy=\"false\">)</mo><mi>p</mi><mo stretchy=\"false\">(</mo><mi>z</mi><mo stretchy=\"false\">)</mo></mrow><mrow><mi>q</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow></mfrac><mo>=</mo><mfrac><mrow><mi>p</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mi mathvariant=\"normal\">∣</mi><mi>z</mi><mo stretchy=\"false\">)</mo><mi>p</mi><mo stretchy=\"false\">(</mo><mi>z</mi><mo stretchy=\"false\">)</mo></mrow><mrow><mo>∫</mo><mrow><mi>p</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mi mathvariant=\"normal\">∣</mi><mi>u</mi><mo stretchy=\"false\">)</mo><mi>p</mi><mo stretchy=\"false\">(</mo><mi>u</mi><mo stretchy=\"false\">)</mo><mi>d</mi><mi>u</mi></mrow></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">p(z|x)=\\frac{p(x|z)p(z)}{q(x)}=\\frac{p(x|z)p(z)}{\\int{p(x|u)p(u)du}}\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\">p</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"mord\">∣</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.363em;vertical-align:-0.936em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.427em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">q</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">p</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mord\">∣</span><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"mclose\">)</span><span class=\"mord mathnormal\">p</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"mclose\">)</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.936em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.42812em;vertical-align:-1.00112em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.427em;\"><span style=\"top:-2.305em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mop op-symbol small-op\" style=\"margin-right:0.19445em;position:relative;top:-0.0005599999999999772em;\">∫</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">p</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mord\">∣</span><span class=\"mord mathnormal\">u</span><span class=\"mclose\">)</span><span class=\"mord mathnormal\">p</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">u</span><span class=\"mclose\">)</span><span class=\"mord mathnormal\">d</span><span class=\"mord mathnormal\">u</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">p</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mord\">∣</span><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"mclose\">)</span><span class=\"mord mathnormal\">p</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"mclose\">)</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.00112em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span></span></p>\n<p>其中 p (z) 标准高斯分布；p (x|z) 高斯分布，均值由变量 z 的确定性函数 f 定义 (f 属于记为 F 的函数族)，协方差矩阵形式为正常数 c*I，I 为单位矩阵</p>\n<p>则有：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>p</mi><mo stretchy=\"false\">(</mo><mi>z</mi><mo stretchy=\"false\">)</mo><mo>∼</mo><mi>N</mi><mo stretchy=\"false\">(</mo><mn>0</mn><mo separator=\"true\">,</mo><mi>I</mi><mo stretchy=\"false\">)</mo><mo separator=\"true\">;</mo><mspace linebreak=\"newline\"></mspace><mi>p</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mi mathvariant=\"normal\">∣</mi><mi>z</mi><mo stretchy=\"false\">)</mo><mo>∼</mo><mi>N</mi><mo stretchy=\"false\">(</mo><mi>f</mi><mo stretchy=\"false\">(</mo><mi>z</mi><mo stretchy=\"false\">)</mo><mo separator=\"true\">,</mo><mi>c</mi><mi>I</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">p(z)\\sim N(0,I);\\\\\np(x|z)\\sim N(f(z),cI)\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\">p</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∼</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span><span class=\"mopen\">(</span><span class=\"mord\">0</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07847em;\">I</span><span class=\"mclose\">)</span><span class=\"mpunct\">;</span></span><span class=\"mspace newline\"></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\">p</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mord\">∣</span><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∼</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.10764em;\">f</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"mclose\">)</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\">c</span><span class=\"mord mathnormal\" style=\"margin-right:0.07847em;\">I</span><span class=\"mclose\">)</span></span></span></span></span></p>\n<p>而对于高维度的” 证据 “（归一化因子），常规计算方法比较困难，因此采用<strong>变分推理</strong>的方法进行近似计算。<s>直接由贝叶斯难以计算，就换个方法</s>。</p>\n<p><strong>变分推理公式</strong></p>\n<p>变分推论（VI）是一种近似复杂分布的技术。这个想法是要设置一个参数化的分布族（例如高斯族，其参数是均值和协方差），并在该族中寻找目标分布的最佳近似。该族中最好的对象是使给定的近似误差测量值最小化的元素（大多数情况下是近似分布与目标分布之间的<strong> Kullback-Leibler 散度</strong>），并通过对该族的参数进行梯度下降来发现。</p>\n<p>此处，通过高斯分布 q<sub>x</sub> (z) 近似 p (z|x)，其均值与方差由 g 与 h 定义，分别属于函数族 G 与 H。</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><msub><mi>q</mi><mi>x</mi></msub><mo stretchy=\"false\">(</mo><mi>z</mi><mo stretchy=\"false\">)</mo><mo>∼</mo><mi>N</mi><mo stretchy=\"false\">(</mo><mi>g</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo><mo separator=\"true\">,</mo><mi>h</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">q_x(z)\\sim N(g(x), h(x))\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">q</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">x</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∼</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">g</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\">h</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span><span class=\"mclose\">)</span></span></span></span></span></p>\n<p>现在则需要通过优化 g 与 h 最小化 q<sub>x</sub> (z) 与 p (z|x) 之间的 KL 散度，从而找到该族中的最佳近似。</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mtable rowspacing=\"0.24999999999999992em\" columnalign=\"right left\" columnspacing=\"0em\"><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"true\"><mrow><mo stretchy=\"false\">(</mo><msup><mi>g</mi><mo>∗</mo></msup><mo separator=\"true\">,</mo><msup><mi>h</mi><mo>∗</mo></msup><mo stretchy=\"false\">)</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel=\"0\" displaystyle=\"true\"><mrow><mrow></mrow><mo>=</mo><mi>a</mi><mi>r</mi><mi>g</mi><mi>m</mi><mi>i</mi><mi>n</mi><mtext> </mtext><mi>K</mi><mi>L</mi><mo stretchy=\"false\">(</mo><msub><mi>q</mi><mi>x</mi></msub><mo stretchy=\"false\">(</mo><mi>z</mi><mo stretchy=\"false\">)</mo><mo separator=\"true\">,</mo><mi>p</mi><mo stretchy=\"false\">(</mo><mi>z</mi><mi mathvariant=\"normal\">∣</mi><mi>x</mi><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">)</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"true\"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel=\"0\" displaystyle=\"true\"><mrow><mrow></mrow><mo>=</mo><mi>a</mi><mi>r</mi><mi>g</mi><mi>m</mi><mi>a</mi><mi>x</mi><mtext> </mtext><mo stretchy=\"false\">(</mo><msub><mi>E</mi><mrow><mi>z</mi><mtext> </mtext><mi>q</mi><mi>x</mi></mrow></msub><mo stretchy=\"false\">(</mo><mi>l</mi><mi>o</mi><mi>g</mi><mo stretchy=\"false\">(</mo><mi>p</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mi mathvariant=\"normal\">∣</mi><mi>z</mi><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">)</mo><mo>−</mo><mi>K</mi><mi>L</mi><mo stretchy=\"false\">(</mo><msub><mi>q</mi><mi>x</mi></msub><mo stretchy=\"false\">(</mo><mi>z</mi><mo stretchy=\"false\">)</mo><mo separator=\"true\">,</mo><mi>p</mi><mo stretchy=\"false\">(</mo><mi>z</mi><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">)</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"true\"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel=\"0\" displaystyle=\"true\"><mrow><mrow></mrow><mo>=</mo><mi>a</mi><mi>r</mi><mi>g</mi><mi>m</mi><mi>a</mi><mi>x</mi><mtext> </mtext><msub><mi>E</mi><mrow><mi>z</mi><mtext> </mtext><mi>q</mi><mi>x</mi></mrow></msub><mo stretchy=\"false\">(</mo><mo>−</mo><mfrac><mrow><mi mathvariant=\"normal\">∣</mi><mi>x</mi><mo>−</mo><mi>f</mi><mo stretchy=\"false\">(</mo><mi>z</mi><msup><mo stretchy=\"false\">)</mo><mn>2</mn></msup><mi mathvariant=\"normal\">∣</mi></mrow><mrow><mn>2</mn><mi>c</mi></mrow></mfrac><mo>−</mo><mi>K</mi><mi>L</mi><mo stretchy=\"false\">(</mo><msub><mi>q</mi><mi>x</mi></msub><mo stretchy=\"false\">(</mo><mi>z</mi><mo stretchy=\"false\">)</mo><mo separator=\"true\">,</mo><mi>p</mi><mo stretchy=\"false\">(</mo><mi>z</mi><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">)</mo></mrow></mstyle></mtd></mtr></mtable><annotation encoding=\"application/x-tex\">\\begin{aligned}\n(g^*, h^*)&amp;=argmin~KL(q_x(z),p(z|x))\\\\\n&amp;=argmax~(E_{z~qx}(log(p(x|z))-KL(q_x(z),p(z))))\\\\\n&amp;= argmax~E_{z~qx}(-\\frac{|x-f(z)^2|}{2c}-KL(q_x(z),p(z)))\n\\end{aligned}\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:5.477108em;vertical-align:-2.4885540000000006em;\"></span><span class=\"mord\"><span class=\"mtable\"><span class=\"col-align-r\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:2.9885539999999997em;\"><span style=\"top:-5.6396619999999995em;\"><span class=\"pstrut\" style=\"height:3.491108em;\"></span><span class=\"mord\"><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">g</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.738696em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mbin mtight\">∗</span></span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">h</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.738696em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mbin mtight\">∗</span></span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span><span style=\"top:-4.1396619999999995em;\"><span class=\"pstrut\" style=\"height:3.491108em;\"></span><span class=\"mord\"></span></span><span style=\"top:-1.9885539999999997em;\"><span class=\"pstrut\" style=\"height:3.491108em;\"></span><span class=\"mord\"></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:2.4885540000000006em;\"><span></span></span></span></span></span><span class=\"col-align-l\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:2.9885539999999997em;\"><span style=\"top:-5.6396619999999995em;\"><span class=\"pstrut\" style=\"height:3.491108em;\"></span><span class=\"mord\"><span class=\"mord\"></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mord mathnormal\">a</span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">r</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">g</span><span class=\"mord mathnormal\">m</span><span class=\"mord mathnormal\">i</span><span class=\"mord mathnormal\">n</span><span class=\"mspace nobreak\"> </span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span><span class=\"mord mathnormal\">L</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">q</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">x</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"mclose\">)</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\">p</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"mord\">∣</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span><span class=\"mclose\">)</span></span></span><span style=\"top:-4.1396619999999995em;\"><span class=\"pstrut\" style=\"height:3.491108em;\"></span><span class=\"mord\"><span class=\"mord\"></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mord mathnormal\">a</span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">r</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">g</span><span class=\"mord mathnormal\">m</span><span class=\"mord mathnormal\">a</span><span class=\"mord mathnormal\">x</span><span class=\"mspace nobreak\"> </span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">E</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15139200000000003em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.04398em;\">z</span><span class=\"mspace nobreak mtight\"><span class=\"mtight\"> </span></span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\">q</span><span class=\"mord mathnormal mtight\">x</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.01968em;\">l</span><span class=\"mord mathnormal\">o</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">g</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">p</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mord\">∣</span><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"mclose\">)</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span><span class=\"mord mathnormal\">L</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">q</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">x</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"mclose\">)</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\">p</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"mclose\">)</span><span class=\"mclose\">)</span><span class=\"mclose\">)</span><span class=\"mclose\">)</span></span></span><span style=\"top:-1.9885539999999997em;\"><span class=\"pstrut\" style=\"height:3.491108em;\"></span><span class=\"mord\"><span class=\"mord\"></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mord mathnormal\">a</span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">r</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">g</span><span class=\"mord mathnormal\">m</span><span class=\"mord mathnormal\">a</span><span class=\"mord mathnormal\">x</span><span class=\"mspace nobreak\"> </span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">E</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15139200000000003em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.04398em;\">z</span><span class=\"mspace nobreak mtight\"><span class=\"mtight\"> </span></span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\">q</span><span class=\"mord mathnormal mtight\">x</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord\">−</span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.491108em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">2</span><span class=\"mord mathnormal\">c</span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">∣</span><span class=\"mord mathnormal\">x</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10764em;\">f</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"mclose\"><span class=\"mclose\">)</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span></span></span></span></span><span class=\"mord\">∣</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.686em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span><span class=\"mord mathnormal\">L</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">q</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">x</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"mclose\">)</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\">p</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"mclose\">)</span><span class=\"mclose\">)</span><span class=\"mclose\">)</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:2.4885540000000006em;\"><span></span></span></span></span></span></span></span></span></span></span></span></p>\n<p>等价过程略</p>\n<p>等价过程倒数第二个方程中，存在一个权衡点 —— 最大化 “观测” 的可能性（第一项，【重构出的样本的】预期对数似然概率的最大）与接近先验分布（第二项 q<sub>x</sub> (z) 与 p (z) 之间 KL 散度最小）。</p>\n<p>由上 (<strong>p (x|z) 高斯分布，均值由变量 z 的确定性函数 f 定义 (f 属于记为 F 的函数族)，协方差矩阵形式为正常数 c*I</strong>)，当由确定 f 时，可以近似 p (z|x)。</p>\n<blockquote>\n<p>感觉变分推理的意义在于绕过贝叶斯，使用近似的方法求解 p (z|x)。q<sub>x</sub> (z) 已知。</p>\n</blockquote>\n<p>但是实际上，定义解码器的函数 f 是未知的，而且也需要求解。但我们最初的目标是找到一种性能良好的编码 / 解码方案，其隐空间又足够规则，可以用于生成目的。如果规则性主要由在隐空间上假定的先验分布所决定，则整个编码 - 解码方案的性能高度取决于函数 f 的选择。</p>\n<p><strong>p (z|x) 可以从 p (z) 与 p (x|z) 近似（上述数学推理），而 p (z) 为简单的标准高斯模型，优化 c（协方差）与 f（分布均值）</strong>，</p>\n<p>则对于属于 F 函数族的任一函数 f（定义一个解码器 p (x|z))，都可以得到编码器 p (x|z) 的最佳近似 q<sub>x</sub><sup>*</sup>(z)。无论他的特性如何，但我们正在寻找一种尽可能高效的编码 - 解码方案，然后，当给定从 q<sub>x</sub><sup>*</sup>(z) 采样的 z 时，希望选择函数 f 使得 x 的期望对数似然最大（<strong>变分推理的权衡</strong>）</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mo stretchy=\"false\">(</mo><msup><mi>f</mi><mo>∗</mo></msup><mo separator=\"true\">,</mo><msup><mi>g</mi><mo>∗</mo></msup><mo separator=\"true\">,</mo><msup><mi>h</mi><mo>∗</mo></msup><mo stretchy=\"false\">)</mo><mo>=</mo><mi>a</mi><mi>r</mi><mi>g</mi><mi>m</mi><mi>a</mi><mi>x</mi><mtext> </mtext><msub><mi>E</mi><mrow><mi>z</mi><mtext> </mtext><mi>q</mi><mi>x</mi></mrow></msub><mo stretchy=\"false\">(</mo><mo>−</mo><mfrac><mrow><mi mathvariant=\"normal\">∣</mi><mi>x</mi><mo>−</mo><mi>f</mi><mo stretchy=\"false\">(</mo><mi>z</mi><msup><mo stretchy=\"false\">)</mo><mn>2</mn></msup><mi mathvariant=\"normal\">∣</mi></mrow><mrow><mn>2</mn><mi>c</mi></mrow></mfrac><mo>−</mo><mi>K</mi><mi>L</mi><mo stretchy=\"false\">(</mo><msub><mi>q</mi><mi>x</mi></msub><mo stretchy=\"false\">(</mo><mi>z</mi><mo stretchy=\"false\">)</mo><mo separator=\"true\">,</mo><mi>p</mi><mo stretchy=\"false\">(</mo><mi>z</mi><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">(f^*,g^*,h^*) = argmax~E_{z~qx}(-\\frac{|x-f(z)^2|}{2c}-KL(q_x(z),p(z)))\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.10764em;\">f</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.738696em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mbin mtight\">∗</span></span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">g</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.738696em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mbin mtight\">∗</span></span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">h</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.738696em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mbin mtight\">∗</span></span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.177108em;vertical-align:-0.686em;\"></span><span class=\"mord mathnormal\">a</span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">r</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">g</span><span class=\"mord mathnormal\">m</span><span class=\"mord mathnormal\">a</span><span class=\"mord mathnormal\">x</span><span class=\"mspace nobreak\"> </span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">E</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15139200000000003em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.04398em;\">z</span><span class=\"mspace nobreak mtight\"><span class=\"mtight\"> </span></span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\">q</span><span class=\"mord mathnormal mtight\">x</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord\">−</span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.491108em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">2</span><span class=\"mord mathnormal\">c</span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">∣</span><span class=\"mord mathnormal\">x</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10764em;\">f</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"mclose\"><span class=\"mclose\">)</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span></span></span></span></span><span class=\"mord\">∣</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.686em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span><span class=\"mord mathnormal\">L</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">q</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">x</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"mclose\">)</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\">p</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"mclose\">)</span><span class=\"mclose\">)</span><span class=\"mclose\">)</span></span></span></span></span></p>\n<p>目标函数中可得到直观描述的元素：x 与 f (z) 之间的重构误差 以及 q<sub>x</sub> (z) 与 p (z) 之间的 KL 散度的正则项，常数 c 则决定了前两个条件之间的平衡越高，我们对模型中的概率解码器假设 p (x|z) 周围的方差就越大，我们也就越关注正则化项。</p>\n<p><strong>神经网络引入模型</strong></p>\n<p>目前为止，我们已经建立了一个依赖于三个函数 f,g,h 的概率模型，并使用变分推理表示要解决的优化问题，以便获得能够给出最优值的 f<sup>*</sup>,g<sup>*</sup>,h<sup>*</sup></p>\n<p>由于我们无法轻松地在函数的整个空间上进行优化，因此我们限制了优化域，并决定将 f,g,h 用神经网络来定义。</p>\n<p><strong>编码器（p (z|x)）</strong></p>\n<p>因此 F,G,H 分别对应于网络体系结构定义的函数族，并且将对这些网络的参数进行优化。</p>\n<p>实际上，g 与 h 不是两个完全独立的网络定义的，而是共享它们的一部分结构和权重，因此我们可以，</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>g</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo><mo>=</mo><msub><mi>g</mi><mn>2</mn></msub><mo stretchy=\"false\">(</mo><msub><mi>g</mi><mn>1</mn></msub><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">)</mo><mo separator=\"true\">;</mo><mspace linebreak=\"newline\"></mspace><mi>h</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo><mo>=</mo><msub><mi>h</mi><mn>2</mn></msub><mo stretchy=\"false\">(</mo><msub><mi>h</mi><mn>1</mn></msub><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">)</mo><mo separator=\"true\">;</mo><mspace linebreak=\"newline\"></mspace><msub><mi>g</mi><mn>1</mn></msub><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo><mo>=</mo><msub><mi>h</mi><mn>1</mn></msub><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">g(x)=g_2(g_1(x));\\\\\nh(x)=h_2(h_1(x));\\\\\ng_1(x)=h_1(x)\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">g</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">g</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">g</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span><span class=\"mclose\">)</span><span class=\"mpunct\">;</span></span><span class=\"mspace newline\"></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\">h</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">h</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\">h</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span><span class=\"mclose\">)</span><span class=\"mpunct\">;</span></span><span class=\"mspace newline\"></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">g</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">h</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span></span></span></span></span></p>\n<p>因为 h 定义了 q<sub>x</sub> (z) 的协方差矩阵，所以 h (x) 为方阵，但是，为了简化计算并减 g 少参数的数量，我们做出了额外的假设，即 p (z|x) 的近似 q<sub>x</sub><sup>*</sup>(z) 是具有对角协方差矩阵的多维高斯分布（变量独立性假设）。在此假设下，h (x) 只是协方差矩阵对角元素的向量，因此其大小与 g (x) 相同。但是，我们以这种方式减少了我们用于变分推断的分布族，因此，对 p (z|x) 的近似可能不太准确。</p>\n<blockquote>\n<p>第一个重点是<strong>编码器</strong>获得均值和协方差的网络共享了一部分权重。</p>\n<p>第二个重点是<strong>协方差矩阵被简化为对角阵，也就是简化成了一维向量</strong>。这样，均值和方差就都可以用全连接网络来获得了。</p>\n</blockquote>\n<p><strong>解码器（p (x|z)）</strong></p>\n<p>模型假设 p (x|z) 具有固定的高斯协方差。函数 f 定义关于 z 的高斯分布均值，f 由神经网络建模。</p>\n<p>通过将编码器和解码器部分串联在一起，可以获得总体架构。但是，在训练过程中，我们仍然需要对从编码器返回的分布中进行采样非常小心。因为采样过程必须以允许误差通过网络反向传播。优化过程依赖从编码器获得的分布中采样，但其实采样操作是不可导的！(无法梯度下降)</p>\n<p>尽管有随机采样发生在模型的中间，但有一个简单的称为<strong>重参数化技巧（reparametrisation trick）</strong>，使梯度下降成为可能。它利用以下事实：如果 z 有均值 g (x) 与协方差 h (x) 的高斯分布的随机变量，则 z 可表示为：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>z</mi><mo>=</mo><mi>h</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo><mi>ζ</mi><mo>+</mo><mi>g</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo><mo separator=\"true\">,</mo><mi>ζ</mi><mo>∼</mo><mi>N</mi><mo stretchy=\"false\">(</mo><mn>0</mn><mo separator=\"true\">,</mo><mi>I</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">z=h(x)\\zeta + g(x), \\zeta \\sim N(0,I)\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\">h</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span><span class=\"mord mathnormal\" style=\"margin-right:0.07378em;\">ζ</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">g</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07378em;\">ζ</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∼</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span><span class=\"mopen\">(</span><span class=\"mord\">0</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07847em;\">I</span><span class=\"mclose\">)</span></span></span></span></span></p>\n<blockquote>\n<p>从一个标准分布中采样，进而对均值和方差进行反向传播。相比要直接从自然分布中采样，由可导变为了不可导；</p>\n</blockquote>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">graph LR;</span><br><span class=\"line\">pro1(x)</span><br><span class=\"line\">pro2&#123;g&#125;</span><br><span class=\"line\">pro3(h)</span><br><span class=\"line\">pro4&#123;N&#125;</span><br><span class=\"line\">pro5(z)</span><br><span class=\"line\">pro6(f)</span><br><span class=\"line\">pro7(x生成)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">pro1 --编码--&gt; pro2</span><br><span class=\"line\">pro1 --编码--&gt; pro3</span><br><span class=\"line\">pro2 --均值--&gt; pro5</span><br><span class=\"line\">pro3 --方差--&gt; pro5</span><br><span class=\"line\">pro4 --标准正态分布--&gt; pro5</span><br><span class=\"line\">pro5 --解码--&gt; pro6</span><br><span class=\"line\">pro6 --解码--&gt; pro7</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">classDef default fill: #EEE8AA, stroke: #333, stroke-width: 4px;</span><br><span class=\"line\">classDef distribution fill:#FF6347,  stroke: #333, stroke-width: 4px;</span><br><span class=\"line\"></span><br><span class=\"line\">class pro2 distribution</span><br><span class=\"line\">class pro3 distribution</span><br><span class=\"line\">class pro6 distribution</span><br><span class=\"line\">class pro4 distribution</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<p>VAE（<s>抽象版</s>）</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>l</mi><mi>o</mi><mi>s</mi><mi>s</mi><mo>=</mo><mi>C</mi><mi mathvariant=\"normal\">∣</mi><mi>x</mi><mo>−</mo><mi>f</mi><mo stretchy=\"false\">(</mo><mi>z</mi><mo stretchy=\"false\">)</mo><msup><mi mathvariant=\"normal\">∣</mi><mn>2</mn></msup><mo>+</mo><mi>K</mi><mi>L</mi><mo stretchy=\"false\">[</mo><mi>N</mi><mo stretchy=\"false\">(</mo><mi>g</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo><mo separator=\"true\">,</mo><mi>h</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">)</mo><mo separator=\"true\">,</mo><mi>N</mi><mo stretchy=\"false\">(</mo><mn>0</mn><mo separator=\"true\">,</mo><mi>I</mi><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">]</mo></mrow><annotation encoding=\"application/x-tex\">loss=C|x-f(z)|^2 + KL[N(g(x), h(x)), N(0,I)]\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.01968em;\">l</span><span class=\"mord mathnormal\">o</span><span class=\"mord mathnormal\">s</span><span class=\"mord mathnormal\">s</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">C</span><span class=\"mord\">∣</span><span class=\"mord mathnormal\">x</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.1141079999999999em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10764em;\">f</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"mclose\">)</span><span class=\"mord\"><span class=\"mord\">∣</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8641079999999999em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span><span class=\"mord mathnormal\">L</span><span class=\"mopen\">[</span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">g</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\">h</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span><span class=\"mclose\">)</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span><span class=\"mopen\">(</span><span class=\"mord\">0</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07847em;\">I</span><span class=\"mclose\">)</span><span class=\"mclose\">]</span></span></span></span></span></p>\n<h2 id=\"参考\"><a class=\"markdownIt-Anchor\" href=\"#参考\">#</a> 参考</h2>\n<p><span class=\"exturl\" data-url=\"aHR0cHM6Ly90b3dhcmRzZGF0YXNjaWVuY2UuY29tL2JheWVzaWFuLWluZmVyZW5jZS1wcm9ibGVtLW1jbWMtYW5kLXZhcmlhdGlvbmFsLWluZmVyZW5jZS0yNWE4YWE5YmNlMjk=\">https://towardsdatascience.com/bayesian-inference-problem-mcmc-and-variational-inference-25a8aa9bce29</span></p>\n<p><span class=\"exturl\" data-url=\"aHR0cHM6Ly9jbG91ZC50ZW5jZW50LmNvbS9kZXZlbG9wZXIvYXJ0aWNsZS8xNjM3NDM5\">https://cloud.tencent.com/developer/article/1637439</span></p>\n",
            "tags": [
                "Mechine learning",
                "Mechine learning"
            ]
        },
        {
            "id": "http://example.com/2024/12/24/hello-world/",
            "url": "http://example.com/2024/12/24/hello-world/",
            "title": "Hello World",
            "date_published": "2024-12-24T01:48:08.066Z",
            "content_html": "<p>Welcome to <span class=\"exturl\" data-url=\"aHR0cHM6Ly9oZXhvLmlvLw==\">Hexo</span>! This is your very first post. Check <span class=\"exturl\" data-url=\"aHR0cHM6Ly9oZXhvLmlvL2RvY3Mv\">documentation</span> for more info. If you get any problems when using Hexo, you can find the answer in <span class=\"exturl\" data-url=\"aHR0cHM6Ly9oZXhvLmlvL2RvY3MvdHJvdWJsZXNob290aW5nLmh0bWw=\">troubleshooting</span> or you can ask me on <span class=\"exturl\" data-url=\"aHR0cHM6Ly9naXRodWIuY29tL2hleG9qcy9oZXhvL2lzc3Vlcw==\">GitHub</span>.</p>\n<h2 id=\"quick-start\"><a class=\"markdownIt-Anchor\" href=\"#quick-start\">#</a> Quick Start</h2>\n<h3 id=\"create-a-new-post\"><a class=\"markdownIt-Anchor\" href=\"#create-a-new-post\">#</a> Create a new post</h3>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo new <span class=\"string\">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>\n<p>More info: <span class=\"exturl\" data-url=\"aHR0cHM6Ly9oZXhvLmlvL2RvY3Mvd3JpdGluZy5odG1s\">Writing</span></p>\n<h3 id=\"run-server\"><a class=\"markdownIt-Anchor\" href=\"#run-server\">#</a> Run server</h3>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo server</span><br></pre></td></tr></table></figure>\n<p>More info: <span class=\"exturl\" data-url=\"aHR0cHM6Ly9oZXhvLmlvL2RvY3Mvc2VydmVyLmh0bWw=\">Server</span></p>\n<h3 id=\"generate-static-files\"><a class=\"markdownIt-Anchor\" href=\"#generate-static-files\">#</a> Generate static files</h3>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo generate</span><br></pre></td></tr></table></figure>\n<p>More info: <span class=\"exturl\" data-url=\"aHR0cHM6Ly9oZXhvLmlvL2RvY3MvZ2VuZXJhdGluZy5odG1s\">Generating</span></p>\n<h3 id=\"deploy-to-remote-sites\"><a class=\"markdownIt-Anchor\" href=\"#deploy-to-remote-sites\">#</a> Deploy to remote sites</h3>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo deploy</span><br></pre></td></tr></table></figure>\n<p>More info: <span class=\"exturl\" data-url=\"aHR0cHM6Ly9oZXhvLmlvL2RvY3Mvb25lLWNvbW1hbmQtZGVwbG95bWVudC5odG1s\">Deployment</span></p>\n",
            "tags": []
        }
    ]
}