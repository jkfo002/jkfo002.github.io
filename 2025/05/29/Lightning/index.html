



<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#FFF">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">

<link rel="icon" type="image/ico" sizes="32x32" href="/images/favicon.ico">
  <meta http-equiv="Cache-Control" content="no-transform">
  <meta http-equiv="Cache-Control" content="no-siteapp">


<link rel="alternate" type="application/rss+xml" title="jkfo-notebook" href="http://example.com/rss.xml" />
<link rel="alternate" type="application/atom+xml" title="jkfo-notebook" href="http://example.com/atom.xml" />
<link rel="alternate" type="application/json" title="jkfo-notebook" href="http://example.com/feed.json" />

<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Mulish:300,300italic,400,400italic,700,700italic%7CFredericka%20the%20Great:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20JP:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20SC:300,300italic,400,400italic,700,700italic%7CInconsolata:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">

<link rel="stylesheet" href="/css/app.css?v=0.2.5">

  
  <meta name="keywords" content="Mechine learning,Lightning" />


<link rel="canonical" href="http://example.com/2025/05/29/Lightning/">



  <title>
Lightning - Mechine learning |
JKFO001 = jkfo-notebook</title>
<meta name="generator" content="Hexo 7.3.0"></head>
<body itemscope itemtype="http://schema.org/WebPage">
  <div id="loading">
    <div class="cat">
      <div class="body"></div>
      <div class="head">
        <div class="face"></div>
      </div>
      <div class="foot">
        <div class="tummy-end"></div>
        <div class="bottom"></div>
        <div class="legs left"></div>
        <div class="legs right"></div>
      </div>
      <div class="paw">
        <div class="hands left"></div>
        <div class="hands right"></div>
      </div>
    </div>
  </div>
  <div id="container">
    <header id="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="inner">
        <div id="brand">
          <div class="pjax">
          
  <h1 itemprop="name headline">Lightning
  </h1>
  
<div class="meta">
  <span class="item" title="Created: 2025-05-29 13:33:50">
    <span class="icon">
      <i class="ic i-calendar"></i>
    </span>
    <span class="text">Posted on</span>
    <time itemprop="dateCreated datePublished" datetime="2025-05-29T13:33:50+08:00">2025-05-29</time>
  </span>
</div>


          </div>
        </div>
        <nav id="nav">
  <div class="inner">
    <div class="toggle">
      <div class="lines" aria-label="Toggle navigation bar">
        <span class="line"></span>
        <span class="line"></span>
        <span class="line"></span>
      </div>
    </div>
    <ul class="menu">
      <li class="item title"><a href="/" rel="start">JKFO001</a></li>
    </ul>
    <ul class="right">
      <li class="item theme">
        <i class="ic i-sun"></i>
      </li>
      <li class="item search">
        <i class="ic i-search"></i>
      </li>
    </ul>
  </div>
</nav>

      </div>
      <div id="imgs" class="pjax">
        <ul>
          <li class="item" data-background-image="https://www.loliapi.com/acg/pc/?807206"></li>
          <li class="item" data-background-image="https://www.loliapi.com/acg/pc/?797815"></li>
          <li class="item" data-background-image="https://www.loliapi.com/acg/pc/?138099"></li>
          <li class="item" data-background-image="https://www.loliapi.com/acg/pc/?183058"></li>
          <li class="item" data-background-image="https://www.loliapi.com/acg/pc/?574145"></li>
          <li class="item" data-background-image="https://www.loliapi.com/acg/pc/?587788"></li>
        </ul>
      </div>
    </header>
    <div id="waves">
      <svg class="waves" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto">
        <defs>
          <path id="gentle-wave" d="M-160 44c30 0 58-18 88-18s 58 18 88 18 58-18 88-18 58 18 88 18 v44h-352z" />
        </defs>
        <g class="parallax">
          <use xlink:href="#gentle-wave" x="48" y="0" />
          <use xlink:href="#gentle-wave" x="48" y="3" />
          <use xlink:href="#gentle-wave" x="48" y="5" />
          <use xlink:href="#gentle-wave" x="48" y="7" />
        </g>
      </svg>
    </div>
    <main>
      <div class="inner">
        <div id="main" class="pjax">
          
  <div class="article wrap">
    
<div class="breadcrumb" itemscope itemtype="https://schema.org/BreadcrumbList">
<i class="ic i-home"></i>
<span><a href="/">Home</a></span><i class="ic i-angle-right"></i>
<span  class="current" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="/categories/Mechine-learning/" itemprop="item" rel="index" title="In Mechine learning"><span itemprop="name">Mechine learning</span></a>
<meta itemprop="position" content="1" /></span>
</div>

    <article itemscope itemtype="http://schema.org/Article" class="post block" lang="en">
  <link itemprop="mainEntityOfPage" href="http://example.com/2025/05/29/Lightning/">

  <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="image" content="/images/avatar.jpg">
    <meta itemprop="name" content="jkfo">
    <meta itemprop="description" content=", ">
  </span>

  <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="jkfo-notebook">
  </span>

  <div class="body md" itemprop="articleBody">
    

    <h1 id="lightning-模板"><a class="markdownIt-Anchor" href="#lightning-模板">#</a> Lightning 模板</h1>
<h2 id="load-data"><a class="markdownIt-Anchor" href="#load-data">#</a> Load Data</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn, optim</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader, random_split</span><br><span class="line"><span class="keyword">from</span> torch.optim.lr_scheduler <span class="keyword">import</span> CosineAnnealingLR, ReduceLROnPlateau, LambdaLR</span><br><span class="line"><span class="keyword">import</span> pytorch_lightning <span class="keyword">as</span> pl</span><br><span class="line"><span class="keyword">from</span> pytorch_lightning <span class="keyword">import</span> Trainer, seed_everything</span><br><span class="line"><span class="keyword">from</span> pytorch_lightning.callbacks.early_stopping <span class="keyword">import</span> EarlyStopping</span><br><span class="line"><span class="keyword">from</span> pytorch_lightning.callbacks <span class="keyword">import</span> ModelCheckpoint</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> logging</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> f1_score</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> KFold, train_test_split</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> models.models <span class="keyword">import</span> Enformer, EnformerConfig</span><br><span class="line"><span class="keyword">from</span> models.dataset <span class="keyword">import</span> CREembeddingDataset, get_class</span><br><span class="line"></span><br><span class="line"><span class="comment"># setting</span></span><br><span class="line">seed_everything(<span class="number">42</span>, workers=<span class="literal">True</span>)</span><br><span class="line">input_length = <span class="number">40000</span></span><br><span class="line">num_epochs = <span class="number">50</span>  <span class="comment"># 训练轮数</span></span><br><span class="line">batch_size = <span class="number">36</span>  <span class="comment"># 批次大小</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># logging</span></span><br><span class="line">log_pfx=<span class="string">&#x27;enformer_SL4long_20k_class_all&#x27;</span></span><br><span class="line">logging.basicConfig(</span><br><span class="line">    filename=<span class="string">f&#x27;./logs/<span class="subst">&#123;log_pfx&#125;</span>.log&#x27;</span>,  <span class="comment"># 日志文件名</span></span><br><span class="line">    filemode=<span class="string">&#x27;w&#x27;</span>,             <span class="comment"># 覆盖模式</span></span><br><span class="line">    <span class="built_in">format</span>=<span class="string">&#x27;%(asctime)s - %(levelname)s - %(message)s&#x27;</span>,  <span class="comment"># 日志格式</span></span><br><span class="line">    level=logging.INFO        <span class="comment"># 日志级别</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># load model</span></span><br><span class="line">device = <span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">init_enformer_model</span>():</span><br><span class="line">    model = Enformer.from_hparams(</span><br><span class="line">        dim = <span class="number">1536</span>//<span class="number">2</span>,</span><br><span class="line">        depth = <span class="number">11</span>,</span><br><span class="line">        heads = <span class="number">4</span>,</span><br><span class="line">        num_downsamples = <span class="number">7</span>,</span><br><span class="line">        dim_divisible_by = <span class="number">128</span></span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"><span class="comment"># 随机抽取3000个样本的索引</span></span><br><span class="line"><span class="comment"># 使用 train_test_split 函数将 data_df 的索引随机划分为训练集和测试集，比例为 9:1</span></span><br><span class="line"><span class="comment"># load data</span></span><br><span class="line">data_df = pd.read_pickle(<span class="string">&#x27;./data/tpm_embedding_SL4long_20k.pkl&#x27;</span>)</span><br><span class="line">data_df[<span class="string">&#x27;class&#x27;</span>] = get_class([np.log(x + <span class="number">1</span>) <span class="keyword">for</span> x <span class="keyword">in</span> data_df[<span class="string">&#x27;max&#x27;</span>].to_list()])</span><br><span class="line">class_weights = data_df[<span class="string">&#x27;class&#x27;</span>].value_counts().reindex([<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>], fill_value=<span class="number">0</span>)</span><br><span class="line">class_weights = class_weights / class_weights.<span class="built_in">max</span>()</span><br><span class="line">test_pickle = <span class="string">&quot;./data/tpm_embedding_SL4long_20k_test_cv5.pkl&quot;</span> <span class="comment"># 用于后续测试</span></span><br><span class="line">embeddings = np.load(<span class="string">&#x27;./data/tpm_seq_embedding_SL4long_20k.npz&#x27;</span>)[<span class="string">&#x27;embeddings&#x27;</span>]</span><br><span class="line">train_indices, test_indices = train_test_split(<span class="built_in">range</span>(<span class="built_in">len</span>(data_df)), test_size=<span class="number">0.1</span>, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 五折交叉验证</span></span><br><span class="line">kf = KFold(n_splits=<span class="number">5</span>, shuffle=<span class="literal">True</span>, random_state=<span class="number">42</span>)</span><br><span class="line">fold_indices = []</span><br><span class="line"><span class="keyword">for</span> fold, (train_index, val_index) <span class="keyword">in</span> <span class="built_in">enumerate</span>(kf.split(train_indices)):</span><br><span class="line">    <span class="comment"># 划分训练集和验证集的索引</span></span><br><span class="line">    train_fold_indices = [train_indices[i] <span class="keyword">for</span> i <span class="keyword">in</span> train_index]</span><br><span class="line">    val_fold_indices = [train_indices[i] <span class="keyword">for</span> i <span class="keyword">in</span> val_index]</span><br><span class="line">    fold_indices.append((train_fold_indices, val_fold_indices))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试集的数据加载器</span></span><br><span class="line">test_df = data_df.iloc[test_indices]</span><br><span class="line">test_df.to_pickle(test_pickle)</span><br></pre></td></tr></table></figure>
<h2 id="lightning-模板-2"><a class="markdownIt-Anchor" href="#lightning-模板-2">#</a> Lightning 模板</h2>
<blockquote>
<p>Lightning 需要</p>
<ul>
<li>
<p><code>pl.LightningDataModule</code> ，实现 dataloader 模块</p>
</li>
<li>
<p><code>pl.LightningModule</code> ，加载模型</p>
</li>
</ul>
<p>最少需要</p>
<ul>
<li>forward 定义前向传播</li>
<li>configure_optimizers optimizer 与 scheduler</li>
<li>training_step</li>
<li>training_step</li>
<li>validation_step</li>
<li>test_step</li>
</ul>
<p>额外的实现，每个 epoch 开始与结束的行为</p>
<ul>
<li>on_train_epoch_start</li>
<li>on_train_epoch_end</li>
<li>on_validation_epoch_start</li>
<li>on_validation_epoch_end</li>
<li>on_test_epoch_start</li>
<li>on_test_epoch_end</li>
</ul>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MyDataModule</span>(pl.LightningDataModule):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, train_indices, val_indices, test_indices, batch_size</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.batch_size = batch_size</span><br><span class="line">        <span class="variable language_">self</span>.train_indices = train_indices</span><br><span class="line">        <span class="variable language_">self</span>.val_indices = val_indices</span><br><span class="line">        <span class="variable language_">self</span>.test_indices = test_indices</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">train_dataloader</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="variable language_">self</span>.train_dataset = CREembeddingDataset(data_df.iloc[<span class="variable language_">self</span>.train_indices], embeddings, target=<span class="string">&#x27;class&#x27;</span>)</span><br><span class="line">        <span class="keyword">return</span> DataLoader(<span class="variable language_">self</span>.train_dataset, batch_size=<span class="variable language_">self</span>.batch_size)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">val_dataloader</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="variable language_">self</span>.val_dataset = CREembeddingDataset(data_df.iloc[<span class="variable language_">self</span>.val_indices], embeddings, target=<span class="string">&#x27;class&#x27;</span>)</span><br><span class="line">        <span class="keyword">return</span> DataLoader(<span class="variable language_">self</span>.val_dataset, batch_size=<span class="variable language_">self</span>.batch_size)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">test_dataloader</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="variable language_">self</span>.test_dataset = CREembeddingDataset(data_df.iloc[<span class="variable language_">self</span>.test_indices], embeddings, target=<span class="string">&#x27;class&#x27;</span>)</span><br><span class="line">        <span class="keyword">return</span> DataLoader(<span class="variable language_">self</span>.test_dataset, batch_size=<span class="variable language_">self</span>.batch_size)</span><br><span class="line"></span><br><span class="line"><span class="comment"># pytorch_lightning</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MyModule</span>(pl.LightningModule):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, foldnum, model, num_epochs, batch_size=batch_size, class_weights=class_weights</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        foldnum: 第几折</span></span><br><span class="line"><span class="string">        model: 模型</span></span><br><span class="line"><span class="string">        batch_size: 批次大小</span></span><br><span class="line"><span class="string">        class_weights: 类别权重</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.mymodel = model</span><br><span class="line">        <span class="variable language_">self</span>.batch_size = batch_size</span><br><span class="line">        <span class="variable language_">self</span>.class_weights = class_weights</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># metrics function</span></span><br><span class="line">        <span class="variable language_">self</span>.loss_fn = nn.CrossEntropyLoss(weight=torch.tensor(class_weights, dtype=torch.bfloat16))</span><br><span class="line">        <span class="variable language_">self</span>.f1 = f1_score</span><br><span class="line"></span><br><span class="line">        <span class="comment"># init metric target</span></span><br><span class="line">        <span class="variable language_">self</span>.init_metric_target(foldnum, num_epochs)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">init_metric_target</span>(<span class="params">self, foldnum, num_epochs</span>):</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># metrics</span></span><br><span class="line">        <span class="variable language_">self</span>.val_outputs = []</span><br><span class="line">        <span class="variable language_">self</span>.val_targets = []</span><br><span class="line">        <span class="variable language_">self</span>.test_outputs = []</span><br><span class="line">        <span class="variable language_">self</span>.test_targets = []</span><br><span class="line"></span><br><span class="line">        <span class="comment"># logging</span></span><br><span class="line">        <span class="variable language_">self</span>.running_loss = <span class="number">0</span></span><br><span class="line">        <span class="variable language_">self</span>.val_loss = <span class="number">0</span></span><br><span class="line">        <span class="variable language_">self</span>.test_loss = <span class="number">0</span></span><br><span class="line">        <span class="variable language_">self</span>.epoch = <span class="number">0</span></span><br><span class="line">        <span class="variable language_">self</span>.fold = foldnum</span><br><span class="line">        <span class="variable language_">self</span>.num_epochs = num_epochs</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.mymodel(x)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">configure_optimizers</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="comment"># 定义损失函数和优化器</span></span><br><span class="line">        optimizer = optim.AdamW(<span class="variable language_">self</span>.mymodel.parameters(), lr=<span class="number">0.0001</span>, weight_decay=<span class="number">1e-3</span>)</span><br><span class="line"></span><br><span class="line">        warm_up_iter = <span class="number">5</span></span><br><span class="line">        T_max = <span class="number">50</span>	<span class="comment"># 周期</span></span><br><span class="line">        lr_max = <span class="number">1e-4</span>	<span class="comment"># 最大值</span></span><br><span class="line">        lr_min = <span class="number">0</span>	<span class="comment"># 最小值</span></span><br><span class="line">        lambda0 = <span class="keyword">lambda</span> cur_iter: (lr_max - lr_min)/warm_up_iter * cur_iter / <span class="number">0.0001</span> <span class="keyword">if</span> cur_iter &lt;= warm_up_iter <span class="keyword">else</span> \</span><br><span class="line">            (lr_min + <span class="number">0.5</span>*(lr_max-lr_min)*(<span class="number">1.0</span>+math.cos((cur_iter-warm_up_iter)/(T_max-warm_up_iter)*math.pi))) / <span class="number">0.0001</span></span><br><span class="line">        scheduler = LambdaLR(optimizer, lr_lambda=lambda0)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> &#123;<span class="string">&quot;optimizer&quot;</span>: optimizer, <span class="string">&quot;lr_scheduler&quot;</span>: scheduler&#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">training_step</span>(<span class="params">self, batch, batch_idx</span>):</span><br><span class="line"></span><br><span class="line">        embeddings, targets = batch</span><br><span class="line">        outputs = <span class="variable language_">self</span>(embeddings)</span><br><span class="line">        loss = <span class="variable language_">self</span>.loss_fn(outputs, targets)</span><br><span class="line">        </span><br><span class="line">        <span class="variable language_">self</span>.running_loss += loss.item()</span><br><span class="line">        <span class="keyword">if</span> batch_idx % <span class="number">2</span> == <span class="number">1</span>:  <span class="comment"># 每2个batch记录一次训练损失和F1</span></span><br><span class="line">            avg_train_batch_loss = <span class="variable language_">self</span>.running_loss / (batch_idx + <span class="number">1</span>)</span><br><span class="line">            logging.info(<span class="string">f&#x27;Fold <span class="subst">&#123;self.fold+<span class="number">1</span>&#125;</span>, Epoch <span class="subst">&#123;self.epoch + <span class="number">1</span>&#125;</span>/<span class="subst">&#123;self.num_epochs&#125;</span>, Batch <span class="subst">&#123;batch_idx + <span class="number">1</span>&#125;</span>, Train Loss(CrossEntropy): <span class="subst">&#123;avg_train_batch_loss:<span class="number">.4</span>f&#125;</span>&#x27;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> loss</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">validation_step</span>(<span class="params">self, batch, batch_idx</span>):</span><br><span class="line"></span><br><span class="line">        embeddings, targets = batch</span><br><span class="line">        outputs = <span class="variable language_">self</span>(embeddings)</span><br><span class="line">        loss = <span class="variable language_">self</span>.loss_fn(outputs, targets)</span><br><span class="line">        <span class="variable language_">self</span>.val_loss += loss.item()</span><br><span class="line"></span><br><span class="line">        _, preds = torch.<span class="built_in">max</span>(outputs, <span class="number">1</span>)</span><br><span class="line">        _, decode_target = torch.<span class="built_in">max</span>(targets, <span class="number">1</span>) <span class="comment"># 真实结果</span></span><br><span class="line">        <span class="variable language_">self</span>.val_outputs.extend(preds.cpu().numpy())</span><br><span class="line">        <span class="variable language_">self</span>.val_targets.extend(decode_target.cpu().numpy())</span><br><span class="line">        <span class="keyword">return</span> loss</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">test_step</span>(<span class="params">self, batch, batch_idx</span>):</span><br><span class="line"></span><br><span class="line">        embeddings, targets = batch</span><br><span class="line">        outputs = <span class="variable language_">self</span>(embeddings)</span><br><span class="line">        loss = <span class="variable language_">self</span>.loss_fn(outputs, targets)</span><br><span class="line">        <span class="variable language_">self</span>.test_loss += loss.item()</span><br><span class="line"></span><br><span class="line">        _, preds = torch.<span class="built_in">max</span>(outputs, <span class="number">1</span>)</span><br><span class="line">        _, decode_target = torch.<span class="built_in">max</span>(targets, <span class="number">1</span>) <span class="comment"># 真实结果</span></span><br><span class="line">        <span class="variable language_">self</span>.test_outputs.extend(preds.cpu().numpy())</span><br><span class="line">        <span class="variable language_">self</span>.test_targets.extend(decode_target.cpu().numpy())</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> loss</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">on_train_epoch_start</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="variable language_">self</span>.running_loss = <span class="number">0</span></span><br><span class="line">        <span class="comment"># 获取优化器</span></span><br><span class="line">        current_lr = <span class="variable language_">self</span>.configure_optimizers()[<span class="string">&quot;optimizer&quot;</span>].param_groups[<span class="number">0</span>][<span class="string">&#x27;lr&#x27;</span>]</span><br><span class="line">        logging.info(<span class="string">f&#x27;Epoch <span class="subst">&#123;self.epoch + <span class="number">1</span>&#125;</span>/<span class="subst">&#123;self.num_epochs&#125;</span>, Learning Rate: <span class="subst">&#123;current_lr:<span class="number">.5</span>f&#125;</span>&#x27;</span>)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">on_train_epoch_end</span>(<span class="params">self</span>):</span><br><span class="line">        avg_train_loss = <span class="variable language_">self</span>.running_loss / <span class="built_in">len</span>(<span class="variable language_">self</span>.train_dataloader())</span><br><span class="line">        logging.info(<span class="string">f&#x27;Fold <span class="subst">&#123;self.fold+<span class="number">1</span>&#125;</span>, Epoch <span class="subst">&#123;self.epoch+<span class="number">1</span>&#125;</span>/<span class="subst">&#123;self.num_epochs&#125;</span>, Train Loss(CrossEntropy): <span class="subst">&#123;avg_train_loss:<span class="number">.4</span>f&#125;</span>&#x27;</span>)</span><br><span class="line">        <span class="variable language_">self</span>.log(<span class="string">&#x27;train_loss&#x27;</span>, avg_train_loss, prog_bar=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">on_validation_epoch_start</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="variable language_">self</span>.val_loss = <span class="number">0</span></span><br><span class="line">        <span class="variable language_">self</span>.val_outputs = []</span><br><span class="line">        <span class="variable language_">self</span>.val_targets = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">on_validation_epoch_end</span>(<span class="params">self</span>):</span><br><span class="line">        val_f1 = <span class="variable language_">self</span>.f1(<span class="variable language_">self</span>.val_targets, <span class="variable language_">self</span>.val_outputs, average=<span class="string">&#x27;macro&#x27;</span>)</span><br><span class="line">        avg_val_loss = <span class="variable language_">self</span>.val_loss / <span class="built_in">len</span>(<span class="variable language_">self</span>.val_targets)</span><br><span class="line">        logging.info(<span class="string">f&#x27;Fold <span class="subst">&#123;self.fold+<span class="number">1</span>&#125;</span>, Epoch <span class="subst">&#123;self.epoch+<span class="number">1</span>&#125;</span>/<span class="subst">&#123;self.num_epochs&#125;</span>, Val Loss(CrossEntropy): <span class="subst">&#123;avg_val_loss:<span class="number">.4</span>f&#125;</span>, Val F1: <span class="subst">&#123;val_f1:<span class="number">.4</span>f&#125;</span>&#x27;</span>)</span><br><span class="line">        <span class="variable language_">self</span>.log(<span class="string">&#x27;val_f1&#x27;</span>, val_f1, prog_bar=<span class="literal">True</span>)</span><br><span class="line">        <span class="variable language_">self</span>.log(<span class="string">&#x27;val_loss&#x27;</span>, avg_val_loss, prog_bar=<span class="literal">True</span>)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">on_test_epoch_start</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="variable language_">self</span>.test_loss = <span class="number">0</span></span><br><span class="line">        <span class="variable language_">self</span>.test_outputs = []</span><br><span class="line">        <span class="variable language_">self</span>.test_targets = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">on_test_epoch_end</span>(<span class="params">self</span>):</span><br><span class="line">        test_f1 = <span class="variable language_">self</span>.f1(<span class="variable language_">self</span>.test_targets, <span class="variable language_">self</span>.test_outputs, average=<span class="string">&#x27;macro&#x27;</span>)</span><br><span class="line">        avg_test_loss = <span class="variable language_">self</span>.test_loss / <span class="built_in">len</span>(<span class="variable language_">self</span>.test_targets)</span><br><span class="line">        logging.info(<span class="string">f&#x27;Fold <span class="subst">&#123;self.fold+<span class="number">1</span>&#125;</span>, Epoch <span class="subst">&#123;self.epoch+<span class="number">1</span>&#125;</span>/<span class="subst">&#123;self.num_epochs&#125;</span>, Test Loss(CrossEntropy): <span class="subst">&#123;avg_test_loss:<span class="number">.4</span>f&#125;</span>, Val F1: <span class="subst">&#123;test_f1:<span class="number">.4</span>f&#125;</span>&#x27;</span>)</span><br><span class="line">        <span class="variable language_">self</span>.log(<span class="string">&#x27;test_f1&#x27;</span>, test_f1, prog_bar=<span class="literal">True</span>)</span><br><span class="line">        <span class="variable language_">self</span>.log(<span class="string">&#x27;test_loss&#x27;</span>, avg_test_loss, prog_bar=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.epoch += <span class="number">1</span></span><br></pre></td></tr></table></figure>
<h2 id="lightning-training-normal"><a class="markdownIt-Anchor" href="#lightning-training-normal">#</a> Lightning training normal</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 初始化模型</span></span><br><span class="line">pl_model = MyModule(</span><br><span class="line">    model = init_enformer_model(),</span><br><span class="line">    num_epochs=num_epochs,</span><br><span class="line">    class_weights=class_weights,</span><br><span class="line">    batch_size=batch_size</span><br><span class="line">)</span><br><span class="line"><span class="comment"># 创建数据模块</span></span><br><span class="line">dm = MyDataModule(</span><br><span class="line">    train_indices=train_indices,</span><br><span class="line">    val_indices=val_indices,</span><br><span class="line">    test_indices=test_indices,</span><br><span class="line">    batch_size=batch_size</span><br><span class="line">)</span><br><span class="line"><span class="comment"># callback</span></span><br><span class="line"><span class="comment"># early_stop_callback = EarlyStopping(monitor=&quot;val_f1&quot;, min_delta=0.00, patience=10, verbose=False, mode=&quot;max&quot;)</span></span><br><span class="line">checkpoint_callback = ModelCheckpoint(</span><br><span class="line">    monitor=<span class="string">&quot;val_f1&quot;</span>,          <span class="comment"># 监控指标</span></span><br><span class="line">    mode=<span class="string">&quot;max&quot;</span>,                 <span class="comment"># 寻找最大值</span></span><br><span class="line">    save_top_k=<span class="number">3</span>,              <span class="comment"># 只保存最好的一个模型</span></span><br><span class="line">    filename=<span class="string">f&quot;<span class="subst">&#123;log_pfx&#125;</span>_&quot;</span>+<span class="string">&quot;-&#123;epoch&#125;-&#123;val_f1:.2f&#125;&quot;</span>,</span><br><span class="line">    dirpath=<span class="string">&quot;./checkpoints&quot;</span>          <span class="comment"># 保存路径</span></span><br><span class="line">)</span><br><span class="line"><span class="comment"># 构建Trainer</span></span><br><span class="line">trainer = Trainer(</span><br><span class="line">    precision=<span class="string">&quot;bf16-mixed&quot;</span>, </span><br><span class="line">    accelerator=<span class="string">&quot;gpu&quot;</span>, </span><br><span class="line">    devices=<span class="number">1</span>,</span><br><span class="line">    max_epochs=num_epochs,</span><br><span class="line">    logger=pl.loggers.TensorBoardLogger(save_dir=<span class="string">&#x27;./logs&#x27;</span>, name=log_pfx),</span><br><span class="line">    num_sanity_val_steps=<span class="number">0</span>,</span><br><span class="line">    callbacks=[checkpoint_callback]</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Training.....</span></span><br><span class="line">trainer.fit(pl_model, datamodule=dm) <span class="comment"># 训练模型</span></span><br><span class="line">trainer.test(pl_model, datamodule=dm) <span class="comment"># 测试模型</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存最终模型</span></span><br><span class="line">torch.save(pl_model.mymodel.state_dict(), <span class="string">f&quot;./weights/<span class="subst">&#123;log_pfx&#125;</span>_final.pth&quot;</span>)</span><br></pre></td></tr></table></figure>
<h2 id="lightning-training-k-fold"><a class="markdownIt-Anchor" href="#lightning-training-k-fold">#</a> Lightning training k-fold</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># training process</span></span><br><span class="line"><span class="keyword">for</span> fold, (train_idx, val_idx) <span class="keyword">in</span> <span class="built_in">enumerate</span>(fold_indices):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;\n----------- Training Fold <span class="subst">&#123;fold + <span class="number">1</span>&#125;</span>/5 -----------&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    model = init_enformer_model()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 初始化模型</span></span><br><span class="line">    pl_model = MyModule(</span><br><span class="line">        foldnum = fold,</span><br><span class="line">        model = model,</span><br><span class="line">        num_epochs=num_epochs,</span><br><span class="line">        class_weights=class_weights,</span><br><span class="line">        batch_size=batch_size</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 创建数据模块</span></span><br><span class="line">    dm = MyDataModule(</span><br><span class="line">        train_indices=train_idx,</span><br><span class="line">        val_indices=val_idx,</span><br><span class="line">        test_indices=test_indices,</span><br><span class="line">        batch_size=batch_size</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># callback</span></span><br><span class="line">    early_stop_callback = EarlyStopping(</span><br><span class="line">        monitor=<span class="string">&quot;val_f1&quot;</span>, min_delta=<span class="number">0.00</span>, </span><br><span class="line">        patience=<span class="number">10</span>, verbose=<span class="literal">False</span>, mode=<span class="string">&quot;max&quot;</span></span><br><span class="line">    )</span><br><span class="line">    checkpoint_callback = ModelCheckpoint(</span><br><span class="line">        monitor=<span class="string">&quot;val_f1&quot;</span>,          <span class="comment"># 监控指标</span></span><br><span class="line">        mode=<span class="string">&quot;max&quot;</span>,                 <span class="comment"># 寻找最大值</span></span><br><span class="line">        save_top_k=<span class="number">1</span>,              <span class="comment"># 只保存最好的一个模型</span></span><br><span class="line">        filename=<span class="string">f&quot;<span class="subst">&#123;log_pfx&#125;</span>_fold<span class="subst">&#123;fold&#125;</span>&quot;</span>+<span class="string">&quot;-&#123;epoch&#125;-&#123;val_f1:.2f&#125;&quot;</span>,</span><br><span class="line">        dirpath=<span class="string">&quot;./checkpoints()&quot;</span>          <span class="comment"># 保存路径</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 构建Trainer</span></span><br><span class="line">    trainer = Trainer(</span><br><span class="line">        precision=<span class="string">&quot;bf16-mixed&quot;</span>, </span><br><span class="line">        accelerator=<span class="string">&quot;gpu&quot;</span>, </span><br><span class="line">        devices=<span class="number">1</span>,</span><br><span class="line">        max_epochs=num_epochs,</span><br><span class="line">        logger=pl.loggers.TensorBoardLogger(</span><br><span class="line">            save_dir=<span class="string">&#x27;./logs&#x27;</span>, </span><br><span class="line">            name=log_pfx</span><br><span class="line">            ), <span class="comment"># 根据 self.log记录tensorboard的结果</span></span><br><span class="line">        num_sanity_val_steps=<span class="number">0</span>,</span><br><span class="line">        callbacks=[</span><br><span class="line">            early_stop_callback,</span><br><span class="line">            checkpoint_callback</span><br><span class="line">            ] <span class="comment"># 早停机制根据self.log记录tensorboard的结果</span></span><br><span class="line">    )</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Training.....</span></span><br><span class="line">    trainer.fit(pl_model, datamodule=dm) <span class="comment"># 训练模型</span></span><br><span class="line">    trainer.test(pl_model, datamodule=dm) <span class="comment"># 测试模型</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> fold + <span class="number">1</span> == <span class="number">5</span>:</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">del</span> pl_model</span><br><span class="line">        <span class="comment"># 保存最佳模型</span></span><br><span class="line">        torch.save(</span><br><span class="line">            pl_model.mymodel.state_dict(), </span><br><span class="line">            <span class="string">f&quot;./weights/<span class="subst">&#123;log_pfx&#125;</span>_best_fold<span class="subst">&#123;fold&#125;</span>.pth&quot;</span></span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存最终模型</span></span><br><span class="line">torch.save(pl_model.state_dict(), <span class="string">f&quot;./weights/<span class="subst">&#123;log_pfx&#125;</span>_final.pth&quot;</span>)</span><br></pre></td></tr></table></figure>

      <div class="tags">
          <a href="/tags/Mechine-learning/" rel="tag"><i class="ic i-tag"></i> Mechine learning</a>
      </div>
  </div>

   <footer>

    <div class="meta">
  <span class="item">
    <span class="icon">
      <i class="ic i-calendar-check"></i>
    </span>
    <span class="text">Edited on</span>
    <time title="Modified: 2025-05-30 11:30:33" itemprop="dateModified" datetime="2025-05-30T11:30:33+08:00">2025-05-30</time>
  </span>
</div>

      

<div id="copyright">
<ul>
  <li class="author">
    <strong>Post author:  </strong>jkfo <i class="ic i-at"><em>@</em></i>jkfo-notebook
  </li>
  <li class="link">
    <strong>Post link: </strong>
    <a href="http://example.com/2025/05/29/Lightning/" title="Lightning">http://example.com/2025/05/29/Lightning/</a>
  </li>
  <li class="license">
    <strong>Copyright Notice:  </strong>All articles in this blog are licensed under <span class="exturl" data-url="aHR0cHM6Ly9jcmVhdGl2ZWNvbW1vbnMub3JnL2xpY2Vuc2VzL2J5LW5jLXNhLzQuMC9kZWVkLnpo"><i class="ic i-creative-commons"><em>(CC)</em></i>BY-NC-SA</span> unless stating additionally.
  </li>
</ul>
</div>

  </footer>

</article>

  </div>
  

<div class="post-nav">
    <div class="item left">
      

  <a href="/2024/12/26/Transformers1/" itemprop="url" rel="prev" data-background-image="https:&#x2F;&#x2F;www.loliapi.com&#x2F;acg&#x2F;pc&#x2F;?171484" title="Transformers1">
  <span class="type">Previous Post</span>
  <span class="category"><i class="ic i-flag"></i> Transformers</span>
  <h3>Transformers1</h3>
  </a>

    </div>
    <div class="item right">
    </div>
</div>

  
  <div class="wrap" id="comments"></div>


        </div>
        <div id="sidebar">
          

<div class="inner">

  <div class="panels">
    <div class="inner">
      <div class="contents panel pjax" data-title="Contents">
          <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#lightning-%E6%A8%A1%E6%9D%BF"><span class="toc-number">1.</span> <span class="toc-text"> Lightning 模板</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#load-data"><span class="toc-number">1.1.</span> <span class="toc-text"> Load Data</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#lightning-%E6%A8%A1%E6%9D%BF-2"><span class="toc-number">1.2.</span> <span class="toc-text"> Lightning 模板</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#lightning-training-normal"><span class="toc-number">1.3.</span> <span class="toc-text"> Lightning training normal</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#lightning-training-k-fold"><span class="toc-number">1.4.</span> <span class="toc-text"> Lightning training k-fold</span></a></li></ol></li></ol>
      </div>
      <div class="related panel pjax" data-title="Related">
        <ul>
          <li><a href="/2024/12/24/VAE/" rel="bookmark" title="VAE">VAE</a></li><li><a href="/2024/12/26/Transformers1/" rel="bookmark" title="Transformers1">Transformers1</a></li><li class="active"><a href="/2025/05/29/Lightning/" rel="bookmark" title="Lightning">Lightning</a></li>
        </ul>
      </div>
      <div class="overview panel" data-title="Overview">
        <div class="author" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <img class="image" itemprop="image" alt="jkfo"
      data-src="/images/avatar.jpg">
  <p class="name" itemprop="name">jkfo</p>
  <div class="description" itemprop="description"></div>
</div>

<nav class="state">
    <div class="item posts">
      <a href="/archives/">
        <span class="count">12</span>
        <span class="name">posts</span>
      </a>
    </div>
    <div class="item categories">
      <a href="/categories/">
        <span class="count">8</span>
        <span class="name">categories</span>
      </a>
    </div>
    <div class="item tags">
      <a href="/tags/">
        <span class="count">8</span>
        <span class="name">tags</span>
      </a>
    </div>
</nav>

<div class="social">
      <span class="exturl item github" data-url="aHR0cHM6Ly9naXRodWIuY29tL2prZm8wMDI=" title="https:&#x2F;&#x2F;github.com&#x2F;jkfo002"><i class="ic i-github"></i></span>
</div>

<ul class="menu">
  
    
  <li class="item">
    <a href="/" rel="section"><i class="ic i-home"></i>Home</a>
  </li>

        
  <li class="item dropdown">
      <a href="javascript:void(0);"><i class="ic i-feather"></i>Posts</a>
    <ul class="submenu">

        
  <li class="item">
    <a href="/archives/" rel="section"><i class="ic i-list-alt"></i>Archives</a>
  </li>

        
  <li class="item">
    <a href="/categories/" rel="section"><i class="ic i-th"></i>Categories</a>
  </li>

        
  <li class="item">
    <a href="/tags/" rel="section"><i class="ic i-tags"></i>Tags</a>
  </li>

  </ul>

</ul>

      </div>
    </div>
  </div>

  <ul id="quick">
    <li class="prev pjax">
    </li>
    <li class="up"><i class="ic i-arrow-up"></i></li>
    <li class="down"><i class="ic i-arrow-down"></i></li>
    <li class="next pjax">
    </li>
    <li class="percent"></li>
  </ul>
</div>


        </div>
        <div class="dimmer"></div>
      </div>
    </main>
    <footer id="footer">
      <div class="inner">
        <div class="widgets">
          
<div class="rpost pjax">
  <h2>Random Posts</h2>
  <ul>
      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/Tips/" title="In Tips">Tips</a>
</div>

    <span><a href="/2024/12/24/readthedocs/" title="readthedocs">readthedocs</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/Tips/" title="In Tips">Tips</a>
</div>

    <span><a href="/2024/12/24/hexo-config/" title="hexo-config">hexo-config</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/Bioinformatics/" title="In Bioinformatics">Bioinformatics</a>
<i class="ic i-angle-right"></i>
<a href="/categories/Bioinformatics/BSA/" title="In BSA">BSA</a>
</div>

    <span><a href="/2024/12/24/DeepBSA-install/" title="DeepBSA-install">DeepBSA-install</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/Mechine-learning/" title="In Mechine learning">Mechine learning</a>
</div>

    <span><a href="/2024/12/24/VAE/" title="VAE">VAE</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/Mechine-learning/" title="In Mechine learning">Mechine learning</a>
</div>

    <span><a href="/2025/05/29/Lightning/" title="Lightning">Lightning</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/Mechine-learning/" title="In Mechine learning">Mechine learning</a>
<i class="ic i-angle-right"></i>
<a href="/categories/Mechine-learning/Transformers/" title="In Transformers">Transformers</a>
</div>

    <span><a href="/2024/12/26/Transformers1/" title="Transformers1">Transformers1</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/Tips/" title="In Tips">Tips</a>
</div>

    <span><a href="/2024/12/24/git/" title="git">git</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/Bioinformatics/" title="In Bioinformatics">Bioinformatics</a>
<i class="ic i-angle-right"></i>
<a href="/categories/Bioinformatics/GWAS/" title="In GWAS">GWAS</a>
</div>

    <span><a href="/2024/12/24/GWAS/" title="GWAS-1">GWAS-1</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/Bioinformatics/" title="In Bioinformatics">Bioinformatics</a>
<i class="ic i-angle-right"></i>
<a href="/categories/Bioinformatics/Evolution/" title="In Evolution">Evolution</a>
</div>

    <span><a href="/2024/12/24/sPLS-DA/" title="sPLS-DA">sPLS-DA</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
</div>

    <span><a href="/2024/12/24/hello-world/" title="Hello World">Hello World</a></span>
  </li>

  </ul>
</div>
<div>
  <h2>Recent Comments</h2>
  <ul class="leancloud-recent-comment"></ul>
</div>

        </div>
        <div class="status">
  <div class="copyright">
    
    &copy; 2010 – 
    <span itemprop="copyrightYear">2025</span>
    <span class="with-love">
      <i class="ic i-sakura rotate"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">jkfo @ JKFO001</span>
  </div>
  <div class="powered-by">
    Powered by <span class="exturl" data-url="aHR0cHM6Ly9oZXhvLmlv">Hexo</span> & Theme.<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2FtZWhpbWUvaGV4by10aGVtZS1zaG9rYQ==">Shoka</span>
  </div>
</div>

      </div>
    </footer>
  </div>
<script data-config type="text/javascript">
  var LOCAL = {
    path: '2025/05/29/Lightning/',
    favicon: {
      show: "（●´3｀●）Goooood",
      hide: "(´Д｀)Booooom"
    },
    search : {
      placeholder: "Search for Posts",
      empty: "We didn't find any results for the search: ${query}",
      stats: "${hits} results found in ${time} ms"
    },
    valine: true,fancybox: true,
    copyright: 'Copied to clipboard successfully! <br> All articles in this blog are licensed under <i class="ic i-creative-commons"></i>BY-NC-SA.',
    ignores : [
      function(uri) {
        return uri.includes('#');
      },
      function(uri) {
        return new RegExp(LOCAL.path+"$").test(uri);
      }
    ]
  };
</script>

<script src="https://cdn.polyfill.io/v2/polyfill.js"></script>

<script src="//cdn.jsdelivr.net/combine/npm/pace-js@1.0.2/pace.min.js,npm/pjax@0.2.8/pjax.min.js,npm/whatwg-fetch@3.4.0/dist/fetch.umd.min.js,npm/animejs@3.2.0/lib/anime.min.js,npm/algoliasearch@4/dist/algoliasearch-lite.umd.js,npm/instantsearch.js@4/dist/instantsearch.production.min.js,npm/lozad@1/dist/lozad.min.js,npm/quicklink@2/dist/quicklink.umd.js"></script>

<script src="/js/app.js?v=0.2.5"></script>




</body>
</html>
